[2025-08-12 20:48:04,288][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:04,288][__main__][INFO] - PID: 2059493
[2025-08-12 20:48:04,288][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:04,288][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:04,288][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:04,288][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:04,288][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:04,288][__main__][INFO] - SLURM_NODEID: 0
[2025-08-12 20:48:04,288][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:04,288][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:04,288][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:04,288][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:04,288][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:04,288][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:04,288][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:04,288][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:04,288][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:04,289][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:04,289][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:04,289][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:04,289][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:04,289][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:04,289][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:04,289][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:04,289][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:04,289][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:04,289][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,289][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:04,289][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:04,289][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:04,289][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:04,289][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:04,289][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:04,289][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:04,289][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:04,289][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:04,290][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:04,290][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:04,290][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:04,290][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:04,290][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:04,290][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:04,290][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:04,290][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:04,305][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:04,306][__main__][INFO] - PID: 2059494
[2025-08-12 20:48:04,306][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:04,306][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:04,306][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:04,306][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:04,306][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:04,306][__main__][INFO] - SLURM_NODEID: 0
[2025-08-12 20:48:04,306][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:04,306][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:04,306][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:04,306][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:04,306][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:04,306][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:04,306][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:04,306][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:04,306][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:04,306][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:04,306][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:04,306][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:04,307][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:04,307][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:04,307][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:04,307][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:04,307][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:04,307][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:04,307][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,307][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:04,307][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:04,307][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:04,307][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:04,307][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:04,307][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:04,307][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:04,307][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:04,307][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:04,307][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:04,307][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:04,308][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:04,308][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:04,308][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:04,308][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:04,308][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:04,308][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:04,308][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:04,308][__main__][INFO] - PID: 2059495
[2025-08-12 20:48:04,308][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:04,308][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:04,308][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:04,308][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:04,308][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:04,308][__main__][INFO] - SLURM_NODEID: 0
[2025-08-12 20:48:04,308][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:04,308][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:04,309][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:04,309][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:04,309][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:04,309][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:04,309][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:04,309][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:04,309][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:04,309][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:04,309][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:04,309][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:04,309][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:04,309][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:04,309][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:04,309][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:04,309][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:04,309][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:04,309][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,309][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:04,309][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:04,310][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:04,310][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:04,310][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:04,310][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:04,310][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:04,310][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:04,310][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:04,310][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:04,310][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:04,310][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:04,310][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:04,310][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:04,310][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:04,310][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:04,310][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:04,310][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:04,311][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:04,311][__main__][INFO] - PID: 2059492
[2025-08-12 20:48:04,311][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:04,311][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:04,311][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:04,311][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:04,311][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:04,311][__main__][INFO] - SLURM_NODEID: 0
[2025-08-12 20:48:04,311][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:04,311][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:04,311][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:04,311][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:04,311][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:04,311][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:04,311][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:04,311][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:04,311][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:04,311][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:04,311][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:04,312][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:04,312][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:04,312][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:04,312][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:04,312][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:04,312][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:04,312][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:04,312][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:04,312][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:04,312][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,312][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:04,312][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:04,312][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:04,312][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:04,312][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:04,312][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:04,312][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:04,312][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:04,312][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:04,312][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:04,312][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:04,313][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:04,313][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:04,313][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:04,313][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:04,313][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:04,313][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:04,313][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:04,313][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:04,313][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:04,313][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:04,313][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:04,314][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:04,314][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:04,315][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:04,315][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:04,315][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:04,315][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:04,316][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:04,316][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:04,323][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:04,323][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:04,323][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:04,324][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:04,324][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:04,415][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:04,415][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:04,415][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:04,415][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:04,416][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:04,416][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:04,416][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:04,416][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:04,422][__main__][INFO] - Saved metadata: {'timestamp': 1755046084.4161084, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:04,422][__main__][INFO] - Saved metadata: {'timestamp': 1755046084.4161203, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:04,423][__main__][INFO] - Saved metadata: {'timestamp': 1755046084.4161367, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:04,424][__main__][INFO] - Saved metadata: {'timestamp': 1755046084.4161434, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:04,585][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:04,585][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:04,585][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:04,585][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:04,585][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:04,585][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:05,218][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:05,218][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:05,218][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:05,218][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:05,220][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:05,220][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:06,833][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:06,833][__main__][INFO] - PID: 2248485
[2025-08-12 20:48:06,833][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:06,833][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:06,833][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:06,833][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:06,833][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:06,833][__main__][INFO] - SLURM_NODEID: 1
[2025-08-12 20:48:06,833][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:06,833][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:06,833][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:06,834][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:06,834][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:06,834][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:06,834][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:06,834][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:06,834][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:06,834][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:06,834][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:06,834][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:06,834][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:06,834][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:06,835][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:06,835][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:06,835][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:06,835][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:06,835][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,835][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:06,835][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:06,835][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:06,835][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:06,835][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:06,835][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:06,836][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:06,836][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:06,836][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:06,836][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:06,836][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:06,836][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:06,836][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:06,836][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:06,836][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:06,836][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:06,836][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:06,853][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:06,853][__main__][INFO] - PID: 2248486
[2025-08-12 20:48:06,853][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:06,853][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:06,854][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:06,854][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:06,854][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:06,854][__main__][INFO] - SLURM_NODEID: 1
[2025-08-12 20:48:06,854][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:06,854][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:06,854][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:06,854][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:06,854][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:06,854][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:06,854][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:06,854][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:06,854][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:06,854][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:06,855][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:06,855][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:06,855][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:06,855][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:06,855][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:06,855][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:06,855][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:06,855][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:06,855][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,855][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:06,856][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:06,856][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:06,856][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:06,856][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:06,856][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:06,856][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:06,856][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:06,856][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:06,856][__main__][INFO] - PID: 2248488
[2025-08-12 20:48:06,856][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:06,856][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:06,856][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:06,856][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:06,856][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:06,856][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:06,856][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:06,856][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:06,856][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:06,856][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:06,856][__main__][INFO] - SLURM_NODEID: 1
[2025-08-12 20:48:06,857][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:06,857][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:06,857][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:06,857][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:06,857][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:06,857][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:06,857][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:06,857][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:06,857][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:06,857][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:06,857][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:06,857][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:06,857][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:06,857][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:06,857][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:06,857][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:06,858][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:06,858][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:06,858][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:06,858][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:06,858][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:06,858][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:06,858][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,858][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:06,858][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:06,858][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:06,859][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:06,859][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:06,858][__main__][INFO] - === STARTING EXPERIMENT: d19-curriculum2 ===
[2025-08-12 20:48:06,859][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:06,859][__main__][INFO] - PID: 2248487
[2025-08-12 20:48:06,859][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:06,859][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:06,859][__main__][INFO] - SLURM_JOB_ID: 29866114
[2025-08-12 20:48:06,859][__main__][INFO] - NODE_RANK: 0
[2025-08-12 20:48:06,859][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:06,859][__main__][INFO] - WORLD_SIZE: 8
[2025-08-12 20:48:06,859][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:06,859][__main__][INFO] - MASTER_ADDR: holygpu8a10101
[2025-08-12 20:48:06,859][__main__][INFO] - MASTER_PORT: 12355
[2025-08-12 20:48:06,859][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:06,859][__main__][INFO] - SLURM_NODEID: 1
[2025-08-12 20:48:06,859][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:06,859][__main__][INFO] - SLURM_NNODES: 2
[2025-08-12 20:48:06,859][__main__][INFO] - SLURM_NODELIST: holygpu8a[10101,24405]
[2025-08-12 20:48:06,859][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:06,859][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:06,859][__main__][INFO] - Architecture: resnet50
[2025-08-12 20:48:06,859][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:06,859][__main__][INFO] - Embedding Dim: 128
[2025-08-12 20:48:06,859][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:06,860][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 20:48:06,860][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 20:48:06,860][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:06,860][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 20:48:06,860][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 20:48:06,860][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 20:48:06,860][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-12 20:48:06,860][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:06,860][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 20:48:06,860][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 20:48:06,860][__main__][INFO] - Use LSTM: False
[2025-08-12 20:48:06,860][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 20:48:06,860][__main__][INFO] - Dataset: code_type=surface_code, d=19, rounds_max=19, p=2.1
[2025-08-12 20:48:06,860][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-12 20:48:06,861][__main__][INFO] - Stage 1: p=0.75 for 80000 steps
[2025-08-12 20:48:06,861][__main__][INFO] - Stage 2: p=0.75→2.1 over 200000 steps
[2025-08-12 20:48:06,861][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:06,861][__main__][INFO] - Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,861][__main__][INFO] - Total curriculum steps: 780000
[2025-08-12 20:48:06,861][__main__][INFO] - Accelerator: auto
[2025-08-12 20:48:06,861][__main__][INFO] - Devices per node: 4
[2025-08-12 20:48:06,861][__main__][INFO] - Num Nodes: 2
[2025-08-12 20:48:06,861][__main__][INFO] - Total Devices: 8
[2025-08-12 20:48:06,861][__main__][INFO] - Strategy: ddp
[2025-08-12 20:48:06,861][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 20:48:06,861][__main__][INFO] - MWPM filtering: False
[2025-08-12 20:48:06,862][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 20:48:06,862][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 20:48:06,862][__main__][INFO] - Max Steps: 780000 (curriculum override)
[2025-08-12 20:48:06,862][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 20:48:06,862][__main__][INFO] - Log every 100 steps
[2025-08-12 20:48:06,862][__main__][INFO] - Num Workers: 8
[2025-08-12 20:48:06,862][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 20:48:06,862][__main__][INFO] - Persistent Workers: True
[2025-08-12 20:48:06,862][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2
[2025-08-12 20:48:06,863][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:06,863][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:06,863][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:06,863][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:06,863][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:06,863][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:06,864][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:06,864][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:06,864][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:06,864][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:06,864][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:06,865][__main__][INFO] - Loaded W&B run ID from file: l36yasyj
[2025-08-12 20:48:06,866][__main__][INFO] - Setting up W&B logger with existing run ID: l36yasyj
[2025-08-12 20:48:06,866][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 20:48:06,886][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:06,886][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:06,886][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:06,886][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:06,886][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:06,886][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-12 20:48:06,886][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:06,886][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,886][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 1: p=0.8 for 80000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 2: p=0.8→2.1 over 200000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Stage 3: p=2.1 for 500000 steps
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:06,887][stage_manager][INFO] -   Total steps: 780000
[2025-08-12 20:48:06,971][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:06,971][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:06,971][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:06,971][__main__][INFO] - Loaded batch size 80 from file
[2025-08-12 20:48:06,972][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:06,972][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:06,972][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:06,972][__main__][INFO] - Effective total batch size across 4 device(s) on 2 node(s) with 1 accumulation steps: 640
[2025-08-12 20:48:06,977][__main__][INFO] - Saved metadata: {'timestamp': 1755046086.9721954, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:06,979][__main__][INFO] - Saved metadata: {'timestamp': 1755046086.9722295, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:06,979][__main__][INFO] - Saved metadata: {'timestamp': 1755046086.9722116, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:06,979][__main__][INFO] - Saved metadata: {'timestamp': 1755046086.9722228, 'slurm_job_id': '29866114', 'batch_size': 80, 'num_devices': 4, 'effective_batch_size': 640}
[2025-08-12 20:48:07,196][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:07,196][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:07,197][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:07,197][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:07,197][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:07,197][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:07,197][data_module][INFO] - Set DataModule global_step_offset to 58646 (will apply when dataset is created)
[2025-08-12 20:48:07,198][__main__][INFO] - Updated DataModule global_step_offset to 58646 for resume
[2025-08-12 20:48:08,032][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:08,033][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:08,033][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:08,033][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:08,033][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:08,033][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
[2025-08-12 20:48:08,033][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 20:48:08,034][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d19-curriculum2/checkpoints/d19-curriculum2-step=58646.ckpt
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2025-08-12 20:48:25,786][__main__][INFO] - Model loaded from checkpoint at global step 58646
[2025-08-12 20:48:25,809][__main__][INFO] - Model loaded from checkpoint at global step 58646
[2025-08-12 20:48:25,810][__main__][INFO] - Model loaded from checkpoint at global step 58646
[2025-08-12 20:48:25,810][__main__][INFO] - Model loaded from checkpoint at global step 58646
[2025-08-12 20:48:26,031][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=19, rounds_max=19, p=2.1, batch_size=80
[2025-08-12 20:48:26,031][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=19, rounds_max=19, p=2.1, batch_size=80
[2025-08-12 20:48:26,031][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-12 20:48:26,031][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-12 20:48:26,031][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=19, rounds_max=19, p=2.1, batch_size=80
[2025-08-12 20:48:26,031][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-12 20:48:26,031][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=19, rounds_max=19, p=2.1, batch_size=80
[2025-08-12 20:48:26,031][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-12 23:40:54,235][__main__][INFO] - === STARTING EXPERIMENT: d13-schedulefree ===
[2025-08-12 23:40:54,235][__main__][INFO] - PID: 2526312
[2025-08-12 23:40:54,236][__main__][INFO] - SLURM_JOB_ID: 29925212
[2025-08-12 23:40:54,236][__main__][INFO] - NODE_RANK: unknown
[2025-08-12 23:40:54,236][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-12 23:40:54,236][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-12 23:40:54,236][__main__][INFO] - MASTER_PORT: unknown
[2025-08-12 23:40:54,236][__main__][INFO] - SLURM_NODEID: 0
[2025-08-12 23:40:54,236][__main__][INFO] - SLURM_NNODES: 1
[2025-08-12 23:40:54,236][__main__][INFO] - SLURM_NODELIST: holygpu8a17602
[2025-08-12 23:40:54,236][__main__][INFO] - Architecture: resnet50
[2025-08-12 23:40:54,236][__main__][INFO] - Embedding Dim: 64
[2025-08-12 23:40:54,236][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 23:40:54,236][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 23:40:54,236][__main__][INFO] - Optimizer: schedulefree
[2025-08-12 23:40:54,236][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 23:40:54,236][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 23:40:54,236][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 23:40:54,236][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-12 23:40:54,236][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 23:40:54,236][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 23:40:54,236][__main__][INFO] - Use LSTM: False
[2025-08-12 23:40:54,236][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 23:40:54,237][__main__][INFO] - Dataset: code_type=surface_code, d=13, rounds_max=13, p=2.1
[2025-08-12 23:40:54,237][__main__][INFO] - Standard training (no curriculum)
[2025-08-12 23:40:54,237][__main__][INFO] - Accelerator: auto
[2025-08-12 23:40:54,237][__main__][INFO] - Devices per node: 1
[2025-08-12 23:40:54,237][__main__][INFO] - Num Nodes: 1
[2025-08-12 23:40:54,237][__main__][INFO] - Total Devices: 1
[2025-08-12 23:40:54,237][__main__][INFO] - Strategy: auto
[2025-08-12 23:40:54,237][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 23:40:54,237][__main__][INFO] - MWPM filtering: False
[2025-08-12 23:40:54,237][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 23:40:54,237][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 23:40:54,237][__main__][INFO] - Max Steps: 50000
[2025-08-12 23:40:54,237][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 23:40:54,237][__main__][INFO] - Log every 100 steps
[2025-08-12 23:40:54,237][__main__][INFO] - Num Workers: 8
[2025-08-12 23:40:54,237][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 23:40:54,237][__main__][INFO] - Persistent Workers: True
[2025-08-12 23:40:54,237][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-schedulefree
[2025-08-12 23:40:54,246][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-12 23:40:54,246][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 23:40:57,012][__main__][INFO] - Saved new W&B run ID to file: j326hyiv
[2025-08-12 23:40:57,108][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-12 23:40:58,046][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=2
[2025-08-12 23:41:00,598][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=4
[2025-08-12 23:41:02,339][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=8
[2025-08-12 23:41:04,161][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=16
[2025-08-12 23:41:06,173][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=32
[2025-08-12 23:41:08,372][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=64
[2025-08-12 23:41:10,884][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=128
[2025-08-12 23:41:13,858][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=256
[2025-08-12 23:41:17,246][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=192
[2025-08-12 23:41:20,915][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=224
[2025-08-12 23:41:23,970][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=208
[2025-08-12 23:41:27,863][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=216
[2025-08-12 23:41:31,750][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=220
[2025-08-12 23:41:35,735][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=222
[2025-08-12 23:41:38,742][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=221
[2025-08-12 23:41:43,068][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=221
[2025-08-12 23:41:44,372][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-12 23:41:44,504][__main__][INFO] - Found optimal batch size 221
[2025-08-12 23:41:44,507][__main__][INFO] - Saved batch size 187 to file
[2025-08-12 23:41:44,507][__main__][INFO] - Optimal per-GPU batch size found: 187
[2025-08-12 23:41:44,507][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 187
[2025-08-12 23:41:44,510][__main__][INFO] - Saved metadata: {'timestamp': 1755056504.5074503, 'slurm_job_id': '29925212', 'batch_size': 187, 'num_devices': 1, 'effective_batch_size': 187}
[2025-08-12 23:41:44,918][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 23:41:44,941][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=187
[2025-08-12 23:42:22,130][__main__][INFO] - === STARTING EXPERIMENT: d13-adamw ===
[2025-08-12 23:42:22,130][__main__][INFO] - PID: 787277
[2025-08-12 23:42:22,130][__main__][INFO] - SLURM_JOB_ID: 29925203
[2025-08-12 23:42:22,130][__main__][INFO] - NODE_RANK: unknown
[2025-08-12 23:42:22,130][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-12 23:42:22,131][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-12 23:42:22,131][__main__][INFO] - MASTER_PORT: unknown
[2025-08-12 23:42:22,131][__main__][INFO] - SLURM_NODEID: 0
[2025-08-12 23:42:22,131][__main__][INFO] - SLURM_NNODES: 1
[2025-08-12 23:42:22,131][__main__][INFO] - SLURM_NODELIST: holygpu8a11603
[2025-08-12 23:42:22,131][__main__][INFO] - Architecture: resnet50
[2025-08-12 23:42:22,131][__main__][INFO] - Embedding Dim: 64
[2025-08-12 23:42:22,131][__main__][INFO] - Learning Rate: 0.0003
[2025-08-12 23:42:22,131][__main__][INFO] - Weight Decay: 0.0
[2025-08-12 23:42:22,131][__main__][INFO] - Optimizer: adamw
[2025-08-12 23:42:22,131][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-12 23:42:22,131][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-12 23:42:22,131][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-12 23:42:22,131][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-12 23:42:22,131][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-12 23:42:22,131][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-12 23:42:22,131][__main__][INFO] - Use LSTM: False
[2025-08-12 23:42:22,131][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-12 23:42:22,131][__main__][INFO] - Dataset: code_type=surface_code, d=13, rounds_max=13, p=2.1
[2025-08-12 23:42:22,131][__main__][INFO] - Standard training (no curriculum)
[2025-08-12 23:42:22,132][__main__][INFO] - Accelerator: auto
[2025-08-12 23:42:22,132][__main__][INFO] - Devices per node: 1
[2025-08-12 23:42:22,132][__main__][INFO] - Num Nodes: 1
[2025-08-12 23:42:22,132][__main__][INFO] - Total Devices: 1
[2025-08-12 23:42:22,132][__main__][INFO] - Strategy: auto
[2025-08-12 23:42:22,132][__main__][INFO] - Sync BatchNorm: True
[2025-08-12 23:42:22,132][__main__][INFO] - MWPM filtering: False
[2025-08-12 23:42:22,132][__main__][INFO] - Batch Size: auto-tuned
[2025-08-12 23:42:22,132][__main__][INFO] - Precision: bf16-mixed
[2025-08-12 23:42:22,132][__main__][INFO] - Max Steps: 50000
[2025-08-12 23:42:22,132][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-12 23:42:22,132][__main__][INFO] - Log every 100 steps
[2025-08-12 23:42:22,132][__main__][INFO] - Num Workers: 8
[2025-08-12 23:42:22,132][__main__][INFO] - Prefetch Factor: 4
[2025-08-12 23:42:22,132][__main__][INFO] - Persistent Workers: True
[2025-08-12 23:42:22,132][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-adamw
[2025-08-12 23:42:22,142][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-12 23:42:22,142][__main__][INFO] - Initializing wandb logger with params
[2025-08-12 23:42:30,837][__main__][INFO] - Saved new W&B run ID to file: epz53cs3
[2025-08-12 23:42:30,945][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-12 23:42:31,905][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=2
[2025-08-12 23:42:35,292][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=4
[2025-08-12 23:42:37,071][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=8
[2025-08-12 23:42:38,893][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=16
[2025-08-12 23:42:40,913][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=32
[2025-08-12 23:42:43,162][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=64
[2025-08-12 23:42:45,702][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=128
[2025-08-12 23:42:48,653][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=256
[2025-08-12 23:42:51,936][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=192
[2025-08-12 23:42:55,591][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=224
[2025-08-12 23:42:58,615][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=208
[2025-08-12 23:43:02,452][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=216
[2025-08-12 23:43:06,307][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=220
[2025-08-12 23:43:10,228][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=222
[2025-08-12 23:43:13,163][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=221
[2025-08-12 23:43:17,335][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=221
[2025-08-12 23:43:18,449][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-12 23:43:18,586][__main__][INFO] - Found optimal batch size 221
[2025-08-12 23:43:18,590][__main__][INFO] - Saved batch size 187 to file
[2025-08-12 23:43:18,590][__main__][INFO] - Optimal per-GPU batch size found: 187
[2025-08-12 23:43:18,590][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 187
[2025-08-12 23:43:18,595][__main__][INFO] - Saved metadata: {'timestamp': 1755056598.5910676, 'slurm_job_id': '29925203', 'batch_size': 187, 'num_devices': 1, 'effective_batch_size': 187}
[2025-08-12 23:43:18,695][__main__][INFO] - === STARTING TRAINING ===
[2025-08-12 23:43:18,718][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=187
[2025-08-13 02:49:34,252][__main__][INFO] - === STARTING EXPERIMENT: d13-schedulefree ===
[2025-08-13 02:49:34,253][__main__][INFO] - PID: 3859659
[2025-08-13 02:49:34,253][__main__][INFO] - SLURM_JOB_ID: 29925212
[2025-08-13 02:49:34,253][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 02:49:34,253][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 02:49:34,253][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 02:49:34,253][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 02:49:34,253][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 02:49:34,253][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 02:49:34,253][__main__][INFO] - SLURM_NODELIST: holygpu8a16403
[2025-08-13 02:49:34,253][__main__][INFO] - Architecture: resnet50
[2025-08-13 02:49:34,253][__main__][INFO] - Embedding Dim: 64
[2025-08-13 02:49:34,253][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 02:49:34,253][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 02:49:34,254][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 02:49:34,254][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 02:49:34,254][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 02:49:34,254][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 02:49:34,254][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 02:49:34,254][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 02:49:34,254][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 02:49:34,254][__main__][INFO] - Use LSTM: False
[2025-08-13 02:49:34,254][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 02:49:34,254][__main__][INFO] - Dataset: code_type=surface_code, d=13, rounds_max=13, p=2.1
[2025-08-13 02:49:34,254][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 02:49:34,254][__main__][INFO] - Accelerator: auto
[2025-08-13 02:49:34,255][__main__][INFO] - Devices per node: 1
[2025-08-13 02:49:34,255][__main__][INFO] - Num Nodes: 1
[2025-08-13 02:49:34,255][__main__][INFO] - Total Devices: 1
[2025-08-13 02:49:34,255][__main__][INFO] - Strategy: auto
[2025-08-13 02:49:34,255][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 02:49:34,255][__main__][INFO] - MWPM filtering: False
[2025-08-13 02:49:34,255][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 02:49:34,255][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 02:49:34,255][__main__][INFO] - Max Steps: 50000
[2025-08-13 02:49:34,255][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 02:49:34,255][__main__][INFO] - Log every 100 steps
[2025-08-13 02:49:34,255][__main__][INFO] - Num Workers: 8
[2025-08-13 02:49:34,255][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 02:49:34,256][__main__][INFO] - Persistent Workers: True
[2025-08-13 02:49:34,256][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-schedulefree
[2025-08-13 02:49:34,267][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-schedulefree/checkpoints/d13-schedulefree-step=40702.ckpt
[2025-08-13 02:49:34,268][__main__][INFO] - === STARTING EXPERIMENT: d13-adamw ===
[2025-08-13 02:49:34,269][__main__][INFO] - PID: 3859660
[2025-08-13 02:49:34,269][__main__][INFO] - Loaded W&B run ID from file: j326hyiv
[2025-08-13 02:49:34,269][__main__][INFO] - SLURM_JOB_ID: 29925203
[2025-08-13 02:49:34,270][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 02:49:34,270][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 02:49:34,270][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 02:49:34,270][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 02:49:34,270][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 02:49:34,270][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 02:49:34,270][__main__][INFO] - SLURM_NODELIST: holygpu8a16403
[2025-08-13 02:49:34,270][__main__][INFO] - Architecture: resnet50
[2025-08-13 02:49:34,270][__main__][INFO] - Setting up W&B logger with existing run ID: j326hyiv
[2025-08-13 02:49:34,270][__main__][INFO] - Embedding Dim: 64
[2025-08-13 02:49:34,270][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 02:49:34,270][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 02:49:34,270][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 02:49:34,270][__main__][INFO] - Optimizer: adamw
[2025-08-13 02:49:34,270][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 02:49:34,270][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 02:49:34,271][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 02:49:34,271][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 02:49:34,271][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 02:49:34,271][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 02:49:34,271][__main__][INFO] - Use LSTM: False
[2025-08-13 02:49:34,271][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 02:49:34,271][__main__][INFO] - Dataset: code_type=surface_code, d=13, rounds_max=13, p=2.1
[2025-08-13 02:49:34,271][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 02:49:34,271][__main__][INFO] - Accelerator: auto
[2025-08-13 02:49:34,271][__main__][INFO] - Devices per node: 1
[2025-08-13 02:49:34,271][__main__][INFO] - Num Nodes: 1
[2025-08-13 02:49:34,272][__main__][INFO] - Total Devices: 1
[2025-08-13 02:49:34,272][__main__][INFO] - Strategy: auto
[2025-08-13 02:49:34,272][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 02:49:34,272][__main__][INFO] - MWPM filtering: False
[2025-08-13 02:49:34,272][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 02:49:34,272][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 02:49:34,272][__main__][INFO] - Max Steps: 50000
[2025-08-13 02:49:34,272][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 02:49:34,272][__main__][INFO] - Log every 100 steps
[2025-08-13 02:49:34,272][__main__][INFO] - Num Workers: 8
[2025-08-13 02:49:34,272][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 02:49:34,272][__main__][INFO] - Persistent Workers: True
[2025-08-13 02:49:34,272][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-adamw
[2025-08-13 02:49:34,284][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-adamw/checkpoints/d13-adamw-step=40821.ckpt
[2025-08-13 02:49:34,286][__main__][INFO] - Loaded W&B run ID from file: epz53cs3
[2025-08-13 02:49:34,287][__main__][INFO] - Setting up W&B logger with existing run ID: epz53cs3
[2025-08-13 02:49:34,287][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 02:49:34,455][__main__][INFO] - Loaded batch size 187 from file
[2025-08-13 02:49:34,455][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 187
[2025-08-13 02:49:34,456][__main__][INFO] - Loaded batch size 187 from file
[2025-08-13 02:49:34,456][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 187
[2025-08-13 02:49:34,461][__main__][INFO] - Saved metadata: {'timestamp': 1755067774.4560575, 'slurm_job_id': '29925212', 'batch_size': 187, 'num_devices': 1, 'effective_batch_size': 187}
[2025-08-13 02:49:34,464][__main__][INFO] - Saved metadata: {'timestamp': 1755067774.456531, 'slurm_job_id': '29925203', 'batch_size': 187, 'num_devices': 1, 'effective_batch_size': 187}
[2025-08-13 02:49:44,250][data_module][INFO] - Set DataModule global_step_offset to 40821 (will apply when dataset is created)
[2025-08-13 02:49:44,253][__main__][INFO] - Updated DataModule global_step_offset to 40821 for resume
[2025-08-13 02:49:44,277][data_module][INFO] - Set DataModule global_step_offset to 40702 (will apply when dataset is created)
[2025-08-13 02:49:44,277][__main__][INFO] - Updated DataModule global_step_offset to 40702 for resume
[2025-08-13 02:49:44,404][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 02:49:44,405][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-schedulefree/checkpoints/d13-schedulefree-step=40702.ckpt
[2025-08-13 02:49:44,404][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 02:49:44,405][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d13-adamw/checkpoints/d13-adamw-step=40821.ckpt
[2025-08-13 02:49:44,559][__main__][INFO] - Model loaded from checkpoint at global step 40702
[2025-08-13 02:49:44,565][__main__][INFO] - Model loaded from checkpoint at global step 40821
[2025-08-13 02:49:45,052][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=187
[2025-08-13 02:49:45,053][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=13, rounds_max=13, p=2.1, batch_size=187
[2025-08-13 03:31:15,157][__main__][INFO] - === TRAINING COMPLETED SUCCESSFULLY ===
[2025-08-13 03:31:40,061][__main__][INFO] - === TRAINING COMPLETED SUCCESSFULLY ===
[2025-08-13 19:20:31,559][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 19:20:31,559][__main__][INFO] - PID: 2928960
[2025-08-13 19:20:31,559][__main__][INFO] - SLURM_JOB_ID: 30034718
[2025-08-13 19:20:31,559][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 19:20:31,560][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 19:20:31,560][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 19:20:31,560][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 19:20:31,560][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 19:20:31,560][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 19:20:31,560][__main__][INFO] - SLURM_NODELIST: holygpu8a26505
[2025-08-13 19:20:31,560][__main__][INFO] - Architecture: resnet50
[2025-08-13 19:20:31,560][__main__][INFO] - Embedding Dim: 128
[2025-08-13 19:20:31,560][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 19:20:31,560][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 19:20:31,560][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 19:20:31,560][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 19:20:31,561][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 19:20:31,561][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 19:20:31,561][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 19:20:31,561][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 19:20:31,561][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 19:20:31,561][__main__][INFO] - Use LSTM: False
[2025-08-13 19:20:31,561][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 19:20:31,561][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 19:20:31,561][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 19:20:31,562][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:20:31,562][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:20:31,562][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:20:31,562][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 19:20:31,562][__main__][INFO] - Accelerator: auto
[2025-08-13 19:20:31,562][__main__][INFO] - Devices per node: 4
[2025-08-13 19:20:31,562][__main__][INFO] - Num Nodes: 1
[2025-08-13 19:20:31,562][__main__][INFO] - Total Devices: 4
[2025-08-13 19:20:31,562][__main__][INFO] - Strategy: auto
[2025-08-13 19:20:31,562][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 19:20:31,563][__main__][INFO] - MWPM filtering: False
[2025-08-13 19:20:31,563][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 19:20:31,563][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 19:20:31,563][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 19:20:31,563][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 19:20:31,563][__main__][INFO] - Log every 100 steps
[2025-08-13 19:20:31,563][__main__][INFO] - Num Workers: 6
[2025-08-13 19:20:31,563][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 19:20:31,563][__main__][INFO] - Persistent Workers: True
[2025-08-13 19:20:31,563][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 19:20:31,574][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 19:20:31,574][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 19:20:33,947][__main__][INFO] - Saved new W&B run ID to file: 437425ju
[2025-08-13 19:20:33,948][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 19:20:33,948][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:20:33,948][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:20:33,948][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:20:33,949][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 19:20:34,034][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 19:20:35,050][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=2
[2025-08-13 19:20:35,050][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:37,516][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=4
[2025-08-13 19:20:37,516][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:38,906][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=8
[2025-08-13 19:20:38,907][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:40,313][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=16
[2025-08-13 19:20:40,313][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:41,765][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=32
[2025-08-13 19:20:41,765][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:43,345][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=64
[2025-08-13 19:20:43,346][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:45,020][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=128
[2025-08-13 19:20:45,021][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:47,033][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=256
[2025-08-13 19:20:47,033][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:49,743][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=512
[2025-08-13 19:20:49,744][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:53,938][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=1024
[2025-08-13 19:20:53,938][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:20:55,624][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=768
[2025-08-13 19:20:55,624][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:01,314][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=896
[2025-08-13 19:21:01,315][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:03,455][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=832
[2025-08-13 19:21:03,455][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:09,277][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=864
[2025-08-13 19:21:09,277][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:11,797][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=848
[2025-08-13 19:21:11,797][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:14,481][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=840
[2025-08-13 19:21:14,482][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:20,342][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=844
[2025-08-13 19:21:20,343][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:22,447][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=842
[2025-08-13 19:21:22,448][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:28,284][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=843
[2025-08-13 19:21:28,284][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:34,526][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=843
[2025-08-13 19:21:34,529][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:21:35,362][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 19:21:35,542][__main__][INFO] - Found optimal batch size 843
[2025-08-13 19:21:35,550][__main__][INFO] - Saved batch size 716 to file
[2025-08-13 19:21:35,550][__main__][INFO] - Optimal per-GPU batch size found: 716
[2025-08-13 19:21:35,551][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 2864
[2025-08-13 19:21:35,554][__main__][INFO] - Saved metadata: {'timestamp': 1755127295.551162, 'slurm_job_id': '30034718', 'batch_size': 716, 'num_devices': 4, 'effective_batch_size': 2864}
[2025-08-13 19:21:36,006][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 19:22:41,532][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=716
[2025-08-13 19:22:41,532][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:35,210][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-13 19:34:35,212][__main__][INFO] - PID: 2934277
[2025-08-13 19:34:35,212][__main__][INFO] - SLURM_JOB_ID: 30034796
[2025-08-13 19:34:35,212][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 19:34:35,212][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 19:34:35,212][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 19:34:35,212][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 19:34:35,212][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 19:34:35,212][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 19:34:35,212][__main__][INFO] - SLURM_NODELIST: holygpu8a26505
[2025-08-13 19:34:35,212][__main__][INFO] - Architecture: resnet50
[2025-08-13 19:34:35,212][__main__][INFO] - Embedding Dim: 128
[2025-08-13 19:34:35,212][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 19:34:35,213][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 19:34:35,213][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 19:34:35,213][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 19:34:35,213][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 19:34:35,213][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 19:34:35,213][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 19:34:35,213][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 19:34:35,213][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 19:34:35,213][__main__][INFO] - Use LSTM: False
[2025-08-13 19:34:35,213][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 19:34:35,214][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-13 19:34:35,214][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 19:34:35,214][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-13 19:34:35,214][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:34:35,214][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-13 19:34:35,214][__main__][INFO] - Total curriculum steps: 300000
[2025-08-13 19:34:35,214][__main__][INFO] - Accelerator: auto
[2025-08-13 19:34:35,214][__main__][INFO] - Devices per node: 4
[2025-08-13 19:34:35,214][__main__][INFO] - Num Nodes: 1
[2025-08-13 19:34:35,214][__main__][INFO] - Total Devices: 4
[2025-08-13 19:34:35,215][__main__][INFO] - Strategy: auto
[2025-08-13 19:34:35,215][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 19:34:35,215][__main__][INFO] - MWPM filtering: False
[2025-08-13 19:34:35,215][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 19:34:35,215][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 19:34:35,215][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-13 19:34:35,215][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 19:34:35,215][__main__][INFO] - Log every 100 steps
[2025-08-13 19:34:35,215][__main__][INFO] - Num Workers: 7
[2025-08-13 19:34:35,215][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 19:34:35,216][__main__][INFO] - Persistent Workers: True
[2025-08-13 19:34:35,216][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-13 19:34:35,229][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 19:34:35,229][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 19:34:37,474][__main__][INFO] - Saved new W&B run ID to file: 9errihhl
[2025-08-13 19:34:37,475][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 19:34:37,475][stage_manager][INFO] -   Stage 1: p=0.5 for 50000 steps
[2025-08-13 19:34:37,476][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:34:37,476][stage_manager][INFO] -   Stage 3: p=2.1 for 200000 steps
[2025-08-13 19:34:37,476][stage_manager][INFO] -   Total steps: 300000
[2025-08-13 19:34:37,553][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 19:34:38,457][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=2
[2025-08-13 19:34:38,458][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:40,743][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=4
[2025-08-13 19:34:40,744][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:42,375][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=8
[2025-08-13 19:34:42,375][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:44,017][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=16
[2025-08-13 19:34:44,018][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:45,760][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=32
[2025-08-13 19:34:45,760][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:47,799][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=64
[2025-08-13 19:34:47,799][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:50,221][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=128
[2025-08-13 19:34:50,221][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:53,469][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=256
[2025-08-13 19:34:53,469][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:34:58,510][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=512
[2025-08-13 19:34:58,510][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:00,419][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=384
[2025-08-13 19:35:00,420][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:02,251][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=320
[2025-08-13 19:35:02,251][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:07,952][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=352
[2025-08-13 19:35:07,952][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:14,077][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=368
[2025-08-13 19:35:14,078][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:16,438][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=360
[2025-08-13 19:35:16,439][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:19,321][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=356
[2025-08-13 19:35:19,321][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:22,130][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=354
[2025-08-13 19:35:22,130][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:28,222][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=355
[2025-08-13 19:35:28,222][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:34,838][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=355
[2025-08-13 19:35:34,838][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:35:35,943][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 19:35:36,116][__main__][INFO] - Found optimal batch size 355
[2025-08-13 19:35:36,124][__main__][INFO] - Saved batch size 301 to file
[2025-08-13 19:35:36,124][__main__][INFO] - Optimal per-GPU batch size found: 301
[2025-08-13 19:35:36,124][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 1204
[2025-08-13 19:35:36,129][__main__][INFO] - Saved metadata: {'timestamp': 1755128136.1250432, 'slurm_job_id': '30034796', 'batch_size': 301, 'num_devices': 4, 'effective_batch_size': 1204}
[2025-08-13 19:35:36,578][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 19:36:40,759][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=301
[2025-08-13 19:36:40,761][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:07,784][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 19:38:07,785][__main__][INFO] - PID: 2778527
[2025-08-13 19:38:07,785][__main__][INFO] - SLURM_JOB_ID: 30051570
[2025-08-13 19:38:07,785][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 19:38:07,785][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 19:38:07,785][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 19:38:07,785][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 19:38:07,785][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 19:38:07,785][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 19:38:07,785][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 19:38:07,785][__main__][INFO] - Architecture: resnet50
[2025-08-13 19:38:07,785][__main__][INFO] - Embedding Dim: 128
[2025-08-13 19:38:07,785][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 19:38:07,785][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 19:38:07,785][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 19:38:07,786][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 19:38:07,786][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 19:38:07,786][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 19:38:07,786][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 19:38:07,786][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 19:38:07,786][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 19:38:07,786][__main__][INFO] - Use LSTM: False
[2025-08-13 19:38:07,786][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 19:38:07,786][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 19:38:07,786][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 19:38:07,786][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:38:07,786][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:38:07,787][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:38:07,787][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 19:38:07,787][__main__][INFO] - Accelerator: auto
[2025-08-13 19:38:07,787][__main__][INFO] - Devices per node: 4
[2025-08-13 19:38:07,787][__main__][INFO] - Num Nodes: 1
[2025-08-13 19:38:07,787][__main__][INFO] - Total Devices: 4
[2025-08-13 19:38:07,787][__main__][INFO] - Strategy: auto
[2025-08-13 19:38:07,787][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 19:38:07,787][__main__][INFO] - MWPM filtering: False
[2025-08-13 19:38:07,787][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 19:38:07,787][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 19:38:07,787][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 19:38:07,787][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 19:38:07,788][__main__][INFO] - Log every 100 steps
[2025-08-13 19:38:07,788][__main__][INFO] - Num Workers: 6
[2025-08-13 19:38:07,788][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 19:38:07,788][__main__][INFO] - Persistent Workers: True
[2025-08-13 19:38:07,788][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 19:38:07,800][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 19:38:07,801][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 19:38:16,229][__main__][INFO] - Saved new W&B run ID to file: uiuxvoj8
[2025-08-13 19:38:16,232][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 19:38:16,232][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:38:16,232][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:38:16,232][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:38:16,232][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 19:38:16,303][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 19:38:16,859][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=2
[2025-08-13 19:38:16,860][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:23,396][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=4
[2025-08-13 19:38:23,398][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:24,198][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=8
[2025-08-13 19:38:24,198][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:25,653][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=16
[2025-08-13 19:38:25,653][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:26,769][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=32
[2025-08-13 19:38:26,769][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:28,116][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=64
[2025-08-13 19:38:28,117][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:30,344][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=128
[2025-08-13 19:38:30,344][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:33,893][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=256
[2025-08-13 19:38:33,893][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:35,344][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=192
[2025-08-13 19:38:35,344][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:40,634][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=224
[2025-08-13 19:38:40,634][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:41,945][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=208
[2025-08-13 19:38:41,945][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:43,703][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=200
[2025-08-13 19:38:43,704][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:49,245][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=204
[2025-08-13 19:38:49,245][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:51,433][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=202
[2025-08-13 19:38:51,434][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:57,045][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=203
[2025-08-13 19:38:57,046][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:59,212][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=202
[2025-08-13 19:38:59,213][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:38:59,740][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=202
[2025-08-13 19:38:59,740][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:39:00,317][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 19:39:00,383][__main__][INFO] - Found optimal batch size 202
[2025-08-13 19:39:00,388][__main__][INFO] - Saved batch size 171 to file
[2025-08-13 19:39:00,388][__main__][INFO] - Optimal per-GPU batch size found: 171
[2025-08-13 19:39:00,388][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 684
[2025-08-13 19:39:00,393][__main__][INFO] - Saved metadata: {'timestamp': 1755128340.3886333, 'slurm_job_id': '30051570', 'batch_size': 171, 'num_devices': 4, 'effective_batch_size': 684}
[2025-08-13 19:40:18,748][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 19:40:18,749][__main__][INFO] - PID: 2779898
[2025-08-13 19:40:18,749][__main__][INFO] - SLURM_JOB_ID: 30051570
[2025-08-13 19:40:18,749][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 19:40:18,749][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 19:40:18,749][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 19:40:18,749][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 19:40:18,749][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 19:40:18,749][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 19:40:18,749][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 19:40:18,749][__main__][INFO] - Architecture: resnet50
[2025-08-13 19:40:18,749][__main__][INFO] - Embedding Dim: 128
[2025-08-13 19:40:18,749][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 19:40:18,749][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 19:40:18,749][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 19:40:18,750][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 19:40:18,750][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 19:40:18,750][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 19:40:18,750][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 19:40:18,750][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 19:40:18,750][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 19:40:18,750][__main__][INFO] - Use LSTM: False
[2025-08-13 19:40:18,750][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 19:40:18,750][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 19:40:18,750][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 19:40:18,750][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:40:18,750][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:40:18,751][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:40:18,751][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 19:40:18,751][__main__][INFO] - Accelerator: auto
[2025-08-13 19:40:18,751][__main__][INFO] - Devices per node: 1
[2025-08-13 19:40:18,751][__main__][INFO] - Num Nodes: 1
[2025-08-13 19:40:18,751][__main__][INFO] - Total Devices: 1
[2025-08-13 19:40:18,751][__main__][INFO] - Strategy: auto
[2025-08-13 19:40:18,751][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 19:40:18,751][__main__][INFO] - MWPM filtering: False
[2025-08-13 19:40:18,751][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 19:40:18,751][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 19:40:18,751][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 19:40:18,751][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 19:40:18,752][__main__][INFO] - Log every 100 steps
[2025-08-13 19:40:18,752][__main__][INFO] - Num Workers: 6
[2025-08-13 19:40:18,752][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 19:40:18,752][__main__][INFO] - Persistent Workers: True
[2025-08-13 19:40:18,752][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 19:40:18,756][__main__][INFO] - Loaded W&B run ID from file: uiuxvoj8
[2025-08-13 19:40:18,757][__main__][INFO] - Setting up W&B logger with existing run ID: uiuxvoj8
[2025-08-13 19:40:18,757][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 19:40:18,760][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 19:40:18,760][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:40:18,760][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:40:18,760][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:40:18,760][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 19:40:18,818][__main__][INFO] - Loaded batch size 171 from file
[2025-08-13 19:40:18,818][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 171
[2025-08-13 19:40:18,823][__main__][INFO] - Saved metadata: {'timestamp': 1755128418.8190405, 'slurm_job_id': '30051570', 'batch_size': 171, 'num_devices': 1, 'effective_batch_size': 171}
[2025-08-13 19:40:20,786][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 19:40:20,958][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=171
[2025-08-13 19:40:20,958][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:42:09,680][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 19:42:09,680][__main__][INFO] - PID: 2780556
[2025-08-13 19:42:09,680][__main__][INFO] - SLURM_JOB_ID: 30051570
[2025-08-13 19:42:09,681][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 19:42:09,681][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 19:42:09,681][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 19:42:09,681][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 19:42:09,681][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 19:42:09,681][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 19:42:09,681][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 19:42:09,681][__main__][INFO] - Architecture: resnet50
[2025-08-13 19:42:09,681][__main__][INFO] - Embedding Dim: 128
[2025-08-13 19:42:09,681][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 19:42:09,681][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 19:42:09,681][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 19:42:09,681][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 19:42:09,681][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 19:42:09,681][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 19:42:09,681][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 19:42:09,682][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 19:42:09,682][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 19:42:09,682][__main__][INFO] - Use LSTM: False
[2025-08-13 19:42:09,682][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 19:42:09,682][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 19:42:09,682][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 19:42:09,682][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:42:09,682][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:42:09,682][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:42:09,682][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 19:42:09,682][__main__][INFO] - Accelerator: auto
[2025-08-13 19:42:09,683][__main__][INFO] - Devices per node: 1
[2025-08-13 19:42:09,683][__main__][INFO] - Num Nodes: 1
[2025-08-13 19:42:09,683][__main__][INFO] - Total Devices: 1
[2025-08-13 19:42:09,683][__main__][INFO] - Strategy: auto
[2025-08-13 19:42:09,683][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 19:42:09,683][__main__][INFO] - MWPM filtering: False
[2025-08-13 19:42:09,683][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 19:42:09,683][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 19:42:09,683][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 19:42:09,683][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 19:42:09,683][__main__][INFO] - Log every 100 steps
[2025-08-13 19:42:09,683][__main__][INFO] - Num Workers: 6
[2025-08-13 19:42:09,683][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 19:42:09,683][__main__][INFO] - Persistent Workers: True
[2025-08-13 19:42:09,684][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 19:42:09,686][__main__][INFO] - W&B logging disabled in config
[2025-08-13 19:42:09,687][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 19:42:09,687][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:42:09,687][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:42:09,687][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:42:09,687][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 19:42:09,744][__main__][INFO] - Loaded batch size 171 from file
[2025-08-13 19:42:09,744][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 171
[2025-08-13 19:42:09,747][__main__][INFO] - Saved metadata: {'timestamp': 1755128529.744556, 'slurm_job_id': '30051570', 'batch_size': 171, 'num_devices': 1, 'effective_batch_size': 171}
[2025-08-13 19:42:09,825][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 19:42:09,993][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=171
[2025-08-13 19:42:09,993][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 19:44:42,017][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 19:44:42,017][__main__][INFO] - PID: 2781808
[2025-08-13 19:44:42,017][__main__][INFO] - SLURM_JOB_ID: 30051570
[2025-08-13 19:44:42,017][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 19:44:42,017][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 19:44:42,017][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 19:44:42,017][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 19:44:42,017][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 19:44:42,017][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 19:44:42,017][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 19:44:42,017][__main__][INFO] - Architecture: resnet50
[2025-08-13 19:44:42,017][__main__][INFO] - Embedding Dim: 128
[2025-08-13 19:44:42,017][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 19:44:42,017][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 19:44:42,018][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 19:44:42,018][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 19:44:42,018][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 19:44:42,018][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 19:44:42,018][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 19:44:42,018][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 19:44:42,018][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 19:44:42,018][__main__][INFO] - Use LSTM: False
[2025-08-13 19:44:42,018][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 19:44:42,018][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 19:44:42,018][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 19:44:42,018][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:44:42,019][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:44:42,019][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:44:42,019][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 19:44:42,019][__main__][INFO] - Accelerator: auto
[2025-08-13 19:44:42,019][__main__][INFO] - Devices per node: 1
[2025-08-13 19:44:42,019][__main__][INFO] - Num Nodes: 1
[2025-08-13 19:44:42,019][__main__][INFO] - Total Devices: 1
[2025-08-13 19:44:42,019][__main__][INFO] - Strategy: auto
[2025-08-13 19:44:42,019][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 19:44:42,019][__main__][INFO] - MWPM filtering: False
[2025-08-13 19:44:42,019][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 19:44:42,019][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 19:44:42,019][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 19:44:42,020][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 19:44:42,020][__main__][INFO] - Log every 100 steps
[2025-08-13 19:44:42,020][__main__][INFO] - Num Workers: 6
[2025-08-13 19:44:42,020][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 19:44:42,020][__main__][INFO] - Persistent Workers: True
[2025-08-13 19:44:42,020][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 19:44:42,023][__main__][INFO] - W&B logging disabled in config
[2025-08-13 19:44:42,024][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 19:44:42,024][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 19:44:42,024][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 19:44:42,024][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 19:44:42,024][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 19:44:42,079][__main__][INFO] - Loaded batch size 171 from file
[2025-08-13 19:44:42,079][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 171
[2025-08-13 19:44:42,084][__main__][INFO] - Saved metadata: {'timestamp': 1755128682.0798845, 'slurm_job_id': '30051570', 'batch_size': 171, 'num_devices': 1, 'effective_batch_size': 171}
[2025-08-13 19:44:42,161][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 19:44:42,327][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=171
[2025-08-13 19:44:42,327][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:03:51,532][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:03:51,532][__main__][INFO] - PID: 543545
[2025-08-13 22:03:51,532][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:03:51,532][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:03:51,532][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:03:51,532][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:03:51,532][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:03:51,532][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:03:51,532][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:03:51,532][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:03:51,533][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:03:51,533][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:03:51,533][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:03:51,533][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:03:51,533][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:03:51,533][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:03:51,533][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:03:51,533][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:03:51,533][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:05:05,477][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:05:05,477][__main__][INFO] - PID: 544479
[2025-08-13 22:05:05,477][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:05:05,477][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:05:05,477][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:05:05,477][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:05:05,477][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:05:05,477][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:05:05,477][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:05:05,477][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:05:05,477][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:05:05,477][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:05:05,478][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:05:05,478][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:05:05,478][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:05:05,478][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:05:05,478][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:05:05,478][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:05:05,478][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:06:17,702][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:06:17,702][__main__][INFO] - PID: 544906
[2025-08-13 22:06:17,702][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:06:17,702][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:06:17,702][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:06:17,702][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:06:17,702][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:06:17,702][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:06:17,702][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:06:17,702][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:06:17,702][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:06:17,702][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:06:17,702][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:06:17,703][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:06:17,703][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:06:17,703][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:06:17,703][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:06:17,703][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:06:17,703][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:06:18,387][__main__][INFO] - Num Relations: 66
[2025-08-13 22:06:18,387][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:06:18,387][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[6], p=0.5
[2025-08-13 22:06:18,387][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:06:18,387][__main__][INFO] - Accelerator: auto
[2025-08-13 22:06:18,387][__main__][INFO] - Devices per node: auto
[2025-08-13 22:06:18,388][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:06:18,388][__main__][INFO] - Total Devices: 1
[2025-08-13 22:06:18,388][__main__][INFO] - Strategy: auto
[2025-08-13 22:06:18,388][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:06:18,388][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:06:18,388][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:06:18,388][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:06:18,388][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:06:18,388][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:06:18,388][__main__][INFO] - Log every 100 steps
[2025-08-13 22:06:18,388][__main__][INFO] - Num Workers: 8
[2025-08-13 22:06:18,388][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:06:18,388][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:06:18,389][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:06:18,399][__main__][INFO] - W&B logging disabled in config
[2025-08-13 22:06:19,023][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:06:21,523][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=2
[2025-08-13 22:07:47,719][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:07:47,720][__main__][INFO] - PID: 545135
[2025-08-13 22:07:47,720][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:07:47,720][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:07:47,720][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:07:47,720][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:07:47,720][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:07:47,720][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:07:47,720][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:07:47,720][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:07:47,720][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:07:47,720][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:07:47,720][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:07:47,720][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:07:47,720][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:07:47,721][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:07:47,721][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:07:47,721][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:07:47,721][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:07:48,348][__main__][INFO] - Num Relations: 66
[2025-08-13 22:07:48,348][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:07:48,348][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[6], p=0.5
[2025-08-13 22:07:48,348][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:07:48,348][__main__][INFO] - Accelerator: auto
[2025-08-13 22:07:48,349][__main__][INFO] - Devices per node: auto
[2025-08-13 22:07:48,349][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:07:48,349][__main__][INFO] - Total Devices: 1
[2025-08-13 22:07:48,349][__main__][INFO] - Strategy: auto
[2025-08-13 22:07:48,349][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:07:48,349][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:07:48,349][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:07:48,349][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:07:48,349][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:07:48,349][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:07:48,349][__main__][INFO] - Log every 100 steps
[2025-08-13 22:07:48,349][__main__][INFO] - Num Workers: 8
[2025-08-13 22:07:48,349][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:07:48,350][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:07:48,350][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:07:48,353][__main__][INFO] - W&B logging disabled in config
[2025-08-13 22:07:48,972][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:07:50,643][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=2
[2025-08-13 22:09:16,531][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:09:16,531][__main__][INFO] - PID: 545417
[2025-08-13 22:09:16,531][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:09:16,531][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:09:16,531][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:09:16,531][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:09:16,531][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:09:16,531][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:09:16,531][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:09:16,532][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:09:16,532][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:09:16,532][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:09:16,532][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:09:16,532][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:09:16,532][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:09:16,532][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:09:16,532][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:09:16,532][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:09:16,532][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:09:17,154][__main__][INFO] - Num Relations: 66
[2025-08-13 22:09:17,154][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:09:17,155][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[6], p=0.5
[2025-08-13 22:09:17,155][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:09:17,155][__main__][INFO] - Accelerator: auto
[2025-08-13 22:09:17,155][__main__][INFO] - Devices per node: auto
[2025-08-13 22:09:17,155][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:09:17,155][__main__][INFO] - Total Devices: 1
[2025-08-13 22:09:17,155][__main__][INFO] - Strategy: auto
[2025-08-13 22:09:17,155][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:09:17,155][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:09:17,155][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:09:17,156][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:09:17,156][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:09:17,156][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:09:17,156][__main__][INFO] - Log every 100 steps
[2025-08-13 22:09:17,156][__main__][INFO] - Num Workers: 8
[2025-08-13 22:09:17,156][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:09:17,156][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:09:17,156][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:09:17,160][__main__][INFO] - W&B logging disabled in config
[2025-08-13 22:09:17,772][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:09:19,435][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=2
[2025-08-13 22:10:41,397][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:10:41,397][__main__][INFO] - PID: 545589
[2025-08-13 22:10:41,397][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:10:41,397][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:10:41,398][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:10:41,398][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:10:41,398][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:10:41,398][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:10:41,398][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:10:41,398][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:10:41,398][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:10:41,398][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:10:41,398][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:10:41,398][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:10:41,398][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:10:41,398][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:10:41,398][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:10:41,398][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:10:41,398][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:10:42,019][__main__][INFO] - Num Relations: 66
[2025-08-13 22:10:42,019][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:10:42,019][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[6], p=0.5
[2025-08-13 22:10:42,019][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:10:42,019][__main__][INFO] - Accelerator: auto
[2025-08-13 22:10:42,020][__main__][INFO] - Devices per node: auto
[2025-08-13 22:10:42,020][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:10:42,020][__main__][INFO] - Total Devices: 1
[2025-08-13 22:10:42,020][__main__][INFO] - Strategy: auto
[2025-08-13 22:10:42,020][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:10:42,020][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:10:42,020][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:10:42,020][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:10:42,020][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:10:42,020][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:10:42,020][__main__][INFO] - Log every 100 steps
[2025-08-13 22:10:42,020][__main__][INFO] - Num Workers: 8
[2025-08-13 22:10:42,020][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:10:42,021][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:10:42,021][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:10:42,029][__main__][INFO] - W&B logging disabled in config
[2025-08-13 22:10:42,641][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:10:44,321][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=2
[2025-08-13 22:13:12,755][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:13:12,755][__main__][INFO] - PID: 546092
[2025-08-13 22:13:12,755][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:13:12,755][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:13:12,755][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:13:12,755][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:13:12,755][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:13:12,755][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:13:12,755][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:13:12,755][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:13:12,756][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:13:12,756][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:13:12,756][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:13:12,756][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:13:12,756][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:13:12,756][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:13:12,756][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:13:12,756][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:13:12,756][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:13:13,388][__main__][INFO] - Num Relations: 66
[2025-08-13 22:13:13,388][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:13:13,388][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[6], p=0.5
[2025-08-13 22:13:13,388][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:13:13,388][__main__][INFO] - Accelerator: auto
[2025-08-13 22:13:13,389][__main__][INFO] - Devices per node: auto
[2025-08-13 22:13:13,389][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:13:13,389][__main__][INFO] - Total Devices: 1
[2025-08-13 22:13:13,389][__main__][INFO] - Strategy: auto
[2025-08-13 22:13:13,389][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:13:13,389][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:13:13,389][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:13:13,389][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:13:13,389][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:13:13,389][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:13:13,389][__main__][INFO] - Log every 100 steps
[2025-08-13 22:13:13,389][__main__][INFO] - Num Workers: 8
[2025-08-13 22:13:13,389][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:13:13,389][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:13:13,390][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:13:13,394][__main__][INFO] - W&B logging disabled in config
[2025-08-13 22:13:14,004][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:13:15,677][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=2
[2025-08-13 22:14:50,286][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:14:50,286][__main__][INFO] - PID: 547047
[2025-08-13 22:14:50,286][__main__][INFO] - SLURM_JOB_ID: 30057267
[2025-08-13 22:14:50,286][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:14:50,287][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:14:50,287][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:14:50,287][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:14:50,287][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:14:50,287][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:14:50,287][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-13 22:14:50,287][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:14:50,287][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:14:50,287][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:14:50,287][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:14:50,287][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:14:50,287][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:14:50,287][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:14:50,287][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:14:50,288][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:14:50,906][__main__][INFO] - Num Relations: 66
[2025-08-13 22:14:50,906][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:14:50,906][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[6], p=0.5
[2025-08-13 22:14:50,906][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:14:50,906][__main__][INFO] - Accelerator: auto
[2025-08-13 22:14:50,907][__main__][INFO] - Devices per node: auto
[2025-08-13 22:14:50,907][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:14:50,907][__main__][INFO] - Total Devices: 1
[2025-08-13 22:14:50,907][__main__][INFO] - Strategy: auto
[2025-08-13 22:14:50,907][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:14:50,907][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:14:50,907][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:14:50,907][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:14:50,907][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:14:50,907][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:14:50,907][__main__][INFO] - Log every 100 steps
[2025-08-13 22:14:50,907][__main__][INFO] - Num Workers: 8
[2025-08-13 22:14:50,907][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:14:50,908][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:14:50,908][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:14:50,911][__main__][INFO] - W&B logging disabled in config
[2025-08-13 22:14:51,526][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:14:53,198][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=2
[2025-08-13 22:14:56,348][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=4
[2025-08-13 22:14:58,024][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=8
[2025-08-13 22:14:59,841][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=16
[2025-08-13 22:15:01,907][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=32
[2025-08-13 22:15:04,514][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=64
[2025-08-13 22:15:08,222][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=128
[2025-08-13 22:15:09,717][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=96
[2025-08-13 22:15:14,941][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=112
[2025-08-13 22:15:20,668][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=120
[2025-08-13 22:15:26,725][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=124
[2025-08-13 22:15:28,506][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=122
[2025-08-13 22:15:34,720][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=123
[2025-08-13 22:15:41,120][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=123
[2025-08-13 22:15:42,968][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 22:15:43,084][__main__][INFO] - Found optimal batch size 123
[2025-08-13 22:15:43,088][__main__][INFO] - Saved batch size 104 to file
[2025-08-13 22:15:43,088][__main__][INFO] - Optimal per-GPU batch size found: 104
[2025-08-13 22:15:43,088][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 104
[2025-08-13 22:15:43,092][__main__][INFO] - Saved metadata: {'timestamp': 1755137743.0889492, 'slurm_job_id': '30057267', 'batch_size': 104, 'num_devices': 1, 'effective_batch_size': 104}
[2025-08-13 22:15:43,511][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 22:15:43,910][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[6], p=0.5, batch_size=104
[2025-08-13 22:29:36,566][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 22:29:36,566][__main__][INFO] - PID: 2838233
[2025-08-13 22:29:36,566][__main__][INFO] - SLURM_JOB_ID: 30058757
[2025-08-13 22:29:36,566][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:29:36,566][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:29:36,566][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:29:36,566][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:29:36,566][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:29:36,566][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:29:36,566][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 22:29:36,566][__main__][INFO] - Architecture: rgcn50
[2025-08-13 22:29:36,566][__main__][INFO] - Embedding Dim: 64
[2025-08-13 22:29:36,566][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 22:29:36,566][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:29:36,567][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:29:36,567][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:29:36,567][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:29:36,567][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:29:36,567][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 22:29:37,225][__main__][INFO] - Num Relations: 66
[2025-08-13 22:29:37,225][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 22:29:37,226][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[2], p=0.5
[2025-08-13 22:29:37,226][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 22:29:37,226][__main__][INFO] - Accelerator: auto
[2025-08-13 22:29:37,226][__main__][INFO] - Devices per node: auto
[2025-08-13 22:29:37,226][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:29:37,226][__main__][INFO] - Total Devices: 1
[2025-08-13 22:29:37,226][__main__][INFO] - Strategy: auto
[2025-08-13 22:29:37,226][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:29:37,226][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:29:37,226][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:29:37,226][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:29:37,226][__main__][INFO] - Max Steps: 50000
[2025-08-13 22:29:37,227][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:29:37,227][__main__][INFO] - Log every 100 steps
[2025-08-13 22:29:37,227][__main__][INFO] - Num Workers: 8
[2025-08-13 22:29:37,227][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:29:37,227][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:29:37,227][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 22:29:37,241][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 22:29:37,241][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 22:29:39,367][__main__][INFO] - Saved new W&B run ID to file: wlcggjv8
[2025-08-13 22:29:39,997][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:29:41,670][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=2
[2025-08-13 22:29:43,756][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=4
[2025-08-13 22:29:45,358][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=8
[2025-08-13 22:29:46,999][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=16
[2025-08-13 22:29:48,676][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=32
[2025-08-13 22:29:50,550][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=64
[2025-08-13 22:29:52,847][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=128
[2025-08-13 22:29:55,990][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=256
[2025-08-13 22:30:00,810][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=512
[2025-08-13 22:30:02,353][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=384
[2025-08-13 22:30:03,904][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=320
[2025-08-13 22:30:10,071][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=352
[2025-08-13 22:30:11,666][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=336
[2025-08-13 22:30:13,309][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=328
[2025-08-13 22:30:14,918][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=324
[2025-08-13 22:30:16,960][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=322
[2025-08-13 22:30:19,035][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=321
[2025-08-13 22:30:21,147][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=320
[2025-08-13 22:30:22,020][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=320
[2025-08-13 22:30:23,775][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 22:30:23,874][__main__][INFO] - Found optimal batch size 320
[2025-08-13 22:30:23,879][__main__][INFO] - Saved batch size 272 to file
[2025-08-13 22:30:23,879][__main__][INFO] - Optimal per-GPU batch size found: 272
[2025-08-13 22:30:23,880][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 272
[2025-08-13 22:30:23,884][__main__][INFO] - Saved metadata: {'timestamp': 1755138623.8803046, 'slurm_job_id': '30058757', 'batch_size': 272, 'num_devices': 1, 'effective_batch_size': 272}
[2025-08-13 22:30:24,306][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 22:30:24,701][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=272
[2025-08-13 22:31:11,829][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 22:31:11,831][__main__][INFO] - PID: 2373204
[2025-08-13 22:31:11,831][__main__][INFO] - SLURM_JOB_ID: 30051868
[2025-08-13 22:31:11,831][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:31:11,831][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:31:11,831][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:31:11,831][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:31:11,831][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:31:11,831][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:31:11,831][__main__][INFO] - SLURM_NODELIST: holygpu8a26506
[2025-08-13 22:31:11,831][__main__][INFO] - Architecture: resnet50
[2025-08-13 22:31:11,831][__main__][INFO] - Embedding Dim: 128
[2025-08-13 22:31:11,832][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 22:31:11,832][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:31:11,832][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:31:11,832][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:31:11,832][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:31:11,832][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:31:11,832][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 22:31:11,832][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 22:31:11,832][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 22:31:11,832][__main__][INFO] - Use LSTM: False
[2025-08-13 22:31:11,833][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 22:31:11,833][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 22:31:11,833][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 22:31:11,833][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 22:31:11,833][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 22:31:11,833][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 22:31:11,833][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 22:31:11,833][__main__][INFO] - Accelerator: auto
[2025-08-13 22:31:11,834][__main__][INFO] - Devices per node: 2
[2025-08-13 22:31:11,834][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:31:11,834][__main__][INFO] - Total Devices: 2
[2025-08-13 22:31:11,834][__main__][INFO] - Strategy: auto
[2025-08-13 22:31:11,834][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:31:11,834][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:31:11,834][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:31:11,834][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:31:11,834][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 22:31:11,834][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:31:11,834][__main__][INFO] - Log every 100 steps
[2025-08-13 22:31:11,835][__main__][INFO] - Num Workers: 6
[2025-08-13 22:31:11,835][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:31:11,835][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:31:11,835][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 22:31:11,849][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 22:31:11,850][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 22:31:14,412][__main__][INFO] - Saved new W&B run ID to file: qg1y59ht
[2025-08-13 22:31:14,413][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 22:31:14,413][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 22:31:14,413][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 22:31:14,414][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 22:31:14,414][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 22:31:14,509][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 22:31:15,353][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=2
[2025-08-13 22:31:15,353][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:18,274][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=4
[2025-08-13 22:31:18,274][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:19,686][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=8
[2025-08-13 22:31:19,686][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:21,234][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=16
[2025-08-13 22:31:21,234][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:22,862][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=32
[2025-08-13 22:31:22,862][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:24,376][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=64
[2025-08-13 22:31:24,376][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:26,143][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=128
[2025-08-13 22:31:26,144][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:28,273][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=256
[2025-08-13 22:31:28,274][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:31,233][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=512
[2025-08-13 22:31:31,234][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:35,626][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=1024
[2025-08-13 22:31:35,627][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:38,073][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=768
[2025-08-13 22:31:38,073][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:43,723][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=896
[2025-08-13 22:31:43,723][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:46,508][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=832
[2025-08-13 22:31:46,508][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:52,556][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=864
[2025-08-13 22:31:52,557][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:55,092][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=848
[2025-08-13 22:31:55,092][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:31:57,916][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=840
[2025-08-13 22:31:57,916][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:32:04,066][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=844
[2025-08-13 22:32:04,067][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:32:06,373][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=842
[2025-08-13 22:32:06,373][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:32:12,551][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=843
[2025-08-13 22:32:12,552][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:32:19,445][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=843
[2025-08-13 22:32:19,448][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:32:20,489][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 22:32:20,734][__main__][INFO] - Found optimal batch size 843
[2025-08-13 22:32:20,744][__main__][INFO] - Saved batch size 716 to file
[2025-08-13 22:32:20,744][__main__][INFO] - Optimal per-GPU batch size found: 716
[2025-08-13 22:32:20,744][__main__][INFO] - Effective total batch size across 2 device(s) on 1 node(s) with 1 accumulation steps: 1432
[2025-08-13 22:32:20,749][__main__][INFO] - Saved metadata: {'timestamp': 1755138740.7448056, 'slurm_job_id': '30051868', 'batch_size': 716, 'num_devices': 2, 'effective_batch_size': 1432}
[2025-08-13 22:32:21,198][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 22:33:24,145][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=716
[2025-08-13 22:33:24,148][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-13 22:38:34,679][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-13 22:38:34,680][__main__][INFO] - PID: 2982101
[2025-08-13 22:38:34,680][__main__][INFO] - SLURM_JOB_ID: 30051885
[2025-08-13 22:38:34,680][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 22:38:34,680][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 22:38:34,680][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 22:38:34,680][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 22:38:34,681][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 22:38:34,681][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 22:38:34,681][__main__][INFO] - SLURM_NODELIST: holygpu8a26505
[2025-08-13 22:38:34,681][__main__][INFO] - Architecture: resnet50
[2025-08-13 22:38:34,681][__main__][INFO] - Embedding Dim: 128
[2025-08-13 22:38:34,681][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 22:38:34,681][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 22:38:34,681][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 22:38:34,681][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 22:38:34,681][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 22:38:34,681][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 22:38:34,682][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 22:38:34,682][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 22:38:34,682][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 22:38:34,682][__main__][INFO] - Use LSTM: False
[2025-08-13 22:38:34,682][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 22:38:34,682][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-13 22:38:34,682][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 22:38:34,682][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-13 22:38:34,682][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 22:38:34,683][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-13 22:38:34,683][__main__][INFO] - Total curriculum steps: 300000
[2025-08-13 22:38:34,683][__main__][INFO] - Accelerator: auto
[2025-08-13 22:38:34,683][__main__][INFO] - Devices per node: 4
[2025-08-13 22:38:34,683][__main__][INFO] - Num Nodes: 1
[2025-08-13 22:38:34,683][__main__][INFO] - Total Devices: 4
[2025-08-13 22:38:34,683][__main__][INFO] - Strategy: auto
[2025-08-13 22:38:34,683][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 22:38:34,683][__main__][INFO] - MWPM filtering: False
[2025-08-13 22:38:34,683][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 22:38:34,684][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 22:38:34,684][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-13 22:38:34,684][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 22:38:34,684][__main__][INFO] - Log every 100 steps
[2025-08-13 22:38:34,684][__main__][INFO] - Num Workers: 7
[2025-08-13 22:38:34,684][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 22:38:34,684][__main__][INFO] - Persistent Workers: True
[2025-08-13 22:38:34,684][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-13 22:38:34,694][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 22:38:34,695][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 23:36:10,887][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 23:36:10,887][__main__][INFO] - PID: 2860507
[2025-08-13 23:36:10,887][__main__][INFO] - SLURM_JOB_ID: 30058757
[2025-08-13 23:36:10,887][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 23:36:10,887][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 23:36:10,887][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 23:36:10,887][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 23:36:10,887][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 23:36:10,887][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 23:36:10,887][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 23:36:10,888][__main__][INFO] - Architecture: rgcn50
[2025-08-13 23:36:10,888][__main__][INFO] - Embedding Dim: 64
[2025-08-13 23:36:10,888][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 23:36:10,888][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 23:36:10,888][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 23:36:10,888][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 23:36:10,888][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 23:36:10,888][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 23:36:10,888][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 23:36:11,517][__main__][INFO] - Num Relations: 66
[2025-08-13 23:36:11,517][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 23:36:11,517][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[2], p=0.5
[2025-08-13 23:36:11,517][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 23:36:11,517][__main__][INFO] - Accelerator: auto
[2025-08-13 23:36:11,517][__main__][INFO] - Devices per node: auto
[2025-08-13 23:36:11,517][__main__][INFO] - Num Nodes: 1
[2025-08-13 23:36:11,517][__main__][INFO] - Total Devices: 1
[2025-08-13 23:36:11,518][__main__][INFO] - Strategy: auto
[2025-08-13 23:36:11,518][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 23:36:11,518][__main__][INFO] - MWPM filtering: False
[2025-08-13 23:36:11,518][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 23:36:11,518][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 23:36:11,518][__main__][INFO] - Max Steps: 50000
[2025-08-13 23:36:11,518][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 23:36:11,518][__main__][INFO] - Log every 100 steps
[2025-08-13 23:36:11,518][__main__][INFO] - Num Workers: 8
[2025-08-13 23:36:11,518][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 23:36:11,518][__main__][INFO] - Persistent Workers: True
[2025-08-13 23:36:11,518][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 23:36:11,533][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 23:36:11,533][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 23:36:13,635][__main__][INFO] - Saved new W&B run ID to file: mtyrf8p4
[2025-08-13 23:36:14,270][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 23:36:16,257][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=2
[2025-08-13 23:37:33,896][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 23:37:33,896][__main__][INFO] - PID: 2861057
[2025-08-13 23:37:33,896][__main__][INFO] - SLURM_JOB_ID: 30058757
[2025-08-13 23:37:33,896][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 23:37:33,896][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 23:37:33,896][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 23:37:33,896][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 23:37:33,897][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 23:37:33,897][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 23:37:33,897][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 23:37:33,897][__main__][INFO] - Architecture: rgcn50
[2025-08-13 23:37:33,897][__main__][INFO] - Embedding Dim: 64
[2025-08-13 23:37:33,897][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 23:37:33,897][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 23:37:33,897][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 23:37:33,897][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 23:37:33,897][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 23:37:33,897][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 23:37:33,897][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 23:37:34,513][__main__][INFO] - Num Relations: 66
[2025-08-13 23:37:34,513][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 23:37:34,513][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[2], p=0.5
[2025-08-13 23:37:34,513][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 23:37:34,513][__main__][INFO] - Accelerator: auto
[2025-08-13 23:37:34,513][__main__][INFO] - Devices per node: auto
[2025-08-13 23:37:34,513][__main__][INFO] - Num Nodes: 1
[2025-08-13 23:37:34,514][__main__][INFO] - Total Devices: 1
[2025-08-13 23:37:34,514][__main__][INFO] - Strategy: auto
[2025-08-13 23:37:34,514][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 23:37:34,514][__main__][INFO] - MWPM filtering: False
[2025-08-13 23:37:34,514][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 23:37:34,514][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 23:37:34,514][__main__][INFO] - Max Steps: 50000
[2025-08-13 23:37:34,514][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 23:37:34,514][__main__][INFO] - Log every 100 steps
[2025-08-13 23:37:34,514][__main__][INFO] - Num Workers: 8
[2025-08-13 23:37:34,514][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 23:37:34,514][__main__][INFO] - Persistent Workers: True
[2025-08-13 23:37:34,514][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 23:37:34,528][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 23:37:34,529][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 23:37:36,490][__main__][INFO] - Saved new W&B run ID to file: i1vbse2o
[2025-08-13 23:37:37,106][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 23:37:38,780][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=2
[2025-08-13 23:38:58,868][__main__][INFO] - === STARTING EXPERIMENT: bb ===
[2025-08-13 23:38:58,869][__main__][INFO] - PID: 2861450
[2025-08-13 23:38:58,869][__main__][INFO] - SLURM_JOB_ID: 30058757
[2025-08-13 23:38:58,869][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 23:38:58,869][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 23:38:58,869][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 23:38:58,869][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 23:38:58,869][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 23:38:58,869][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 23:38:58,869][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-13 23:38:58,869][__main__][INFO] - Architecture: rgcn50
[2025-08-13 23:38:58,869][__main__][INFO] - Embedding Dim: 64
[2025-08-13 23:38:58,869][__main__][INFO] - Learning Rate: 0.0003
[2025-08-13 23:38:58,869][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 23:38:58,869][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 23:38:58,869][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 23:38:58,870][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 23:38:58,870][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 23:38:58,870][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-13 23:38:59,497][__main__][INFO] - Num Relations: 66
[2025-08-13 23:38:59,497][__main__][INFO] - Num Logical Qubits: 12
[2025-08-13 23:38:59,497][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[2], p=0.5
[2025-08-13 23:38:59,497][__main__][INFO] - Standard training (no curriculum)
[2025-08-13 23:38:59,498][__main__][INFO] - Accelerator: auto
[2025-08-13 23:38:59,498][__main__][INFO] - Devices per node: auto
[2025-08-13 23:38:59,498][__main__][INFO] - Num Nodes: 1
[2025-08-13 23:38:59,498][__main__][INFO] - Total Devices: 1
[2025-08-13 23:38:59,498][__main__][INFO] - Strategy: auto
[2025-08-13 23:38:59,498][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 23:38:59,498][__main__][INFO] - MWPM filtering: False
[2025-08-13 23:38:59,498][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 23:38:59,498][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 23:38:59,498][__main__][INFO] - Max Steps: 50000
[2025-08-13 23:38:59,498][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 23:38:59,498][__main__][INFO] - Log every 100 steps
[2025-08-13 23:38:59,498][__main__][INFO] - Num Workers: 8
[2025-08-13 23:38:59,498][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 23:38:59,499][__main__][INFO] - Persistent Workers: True
[2025-08-13 23:38:59,499][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb
[2025-08-13 23:38:59,515][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-13 23:38:59,516][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 23:39:01,649][__main__][INFO] - Saved new W&B run ID to file: ujqw5xjf
[2025-08-13 23:39:02,267][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-13 23:39:03,951][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=2
[2025-08-13 23:39:05,902][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=4
[2025-08-13 23:39:07,471][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=8
[2025-08-13 23:39:09,077][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=16
[2025-08-13 23:39:10,777][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=32
[2025-08-13 23:39:12,668][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=64
[2025-08-13 23:39:14,982][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=128
[2025-08-13 23:39:18,112][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=256
[2025-08-13 23:39:22,969][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=512
[2025-08-13 23:39:24,534][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=384
[2025-08-13 23:39:26,044][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=320
[2025-08-13 23:39:32,163][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=352
[2025-08-13 23:39:33,810][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=336
[2025-08-13 23:39:35,463][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=328
[2025-08-13 23:39:37,075][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=324
[2025-08-13 23:39:39,165][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=322
[2025-08-13 23:39:41,269][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=321
[2025-08-13 23:39:43,362][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=320
[2025-08-13 23:39:44,262][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=320
[2025-08-13 23:39:46,025][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-13 23:39:46,131][__main__][INFO] - Found optimal batch size 320
[2025-08-13 23:39:46,136][__main__][INFO] - Saved batch size 272 to file
[2025-08-13 23:39:46,137][__main__][INFO] - Optimal per-GPU batch size found: 272
[2025-08-13 23:39:46,137][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 272
[2025-08-13 23:39:46,142][__main__][INFO] - Saved metadata: {'timestamp': 1755142786.1374044, 'slurm_job_id': '30058757', 'batch_size': 272, 'num_devices': 1, 'effective_batch_size': 272}
[2025-08-13 23:39:46,563][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 23:39:46,954][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[2], p=0.5, batch_size=272
[2025-08-13 23:58:40,626][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-13 23:58:40,626][__main__][INFO] - PID: 484976
[2025-08-13 23:58:40,626][__main__][INFO] - SLURM_JOB_ID: 30051868
[2025-08-13 23:58:40,626][__main__][INFO] - NODE_RANK: unknown
[2025-08-13 23:58:40,626][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-13 23:58:40,626][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-13 23:58:40,626][__main__][INFO] - MASTER_PORT: unknown
[2025-08-13 23:58:40,627][__main__][INFO] - SLURM_NODEID: 0
[2025-08-13 23:58:40,627][__main__][INFO] - SLURM_NNODES: 1
[2025-08-13 23:58:40,627][__main__][INFO] - SLURM_NODELIST: holygpu8a17202
[2025-08-13 23:58:40,627][__main__][INFO] - Architecture: resnet50
[2025-08-13 23:58:40,627][__main__][INFO] - Embedding Dim: 128
[2025-08-13 23:58:40,627][__main__][INFO] - Learning Rate: 0.0004
[2025-08-13 23:58:40,627][__main__][INFO] - Weight Decay: 0.0
[2025-08-13 23:58:40,627][__main__][INFO] - Optimizer: schedulefree
[2025-08-13 23:58:40,627][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-13 23:58:40,627][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-13 23:58:40,627][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-13 23:58:40,627][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-13 23:58:40,627][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-13 23:58:40,627][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-13 23:58:40,627][__main__][INFO] - Use LSTM: False
[2025-08-13 23:58:40,627][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-13 23:58:40,627][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-13 23:58:40,627][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-13 23:58:40,627][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-13 23:58:40,628][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 23:58:40,628][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-13 23:58:40,628][__main__][INFO] - Total curriculum steps: 110000
[2025-08-13 23:58:40,628][__main__][INFO] - Accelerator: auto
[2025-08-13 23:58:40,628][__main__][INFO] - Devices per node: 2
[2025-08-13 23:58:40,628][__main__][INFO] - Num Nodes: 1
[2025-08-13 23:58:40,628][__main__][INFO] - Total Devices: 2
[2025-08-13 23:58:40,628][__main__][INFO] - Strategy: auto
[2025-08-13 23:58:40,628][__main__][INFO] - Sync BatchNorm: True
[2025-08-13 23:58:40,628][__main__][INFO] - MWPM filtering: False
[2025-08-13 23:58:40,628][__main__][INFO] - Batch Size: auto-tuned
[2025-08-13 23:58:40,628][__main__][INFO] - Precision: bf16-mixed
[2025-08-13 23:58:40,628][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-13 23:58:40,628][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-13 23:58:40,628][__main__][INFO] - Log every 100 steps
[2025-08-13 23:58:40,628][__main__][INFO] - Num Workers: 6
[2025-08-13 23:58:40,628][__main__][INFO] - Prefetch Factor: 4
[2025-08-13 23:58:40,628][__main__][INFO] - Persistent Workers: True
[2025-08-13 23:58:40,628][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-13 23:58:40,642][__main__][INFO] - Loaded W&B run ID from file: qg1y59ht
[2025-08-13 23:58:40,643][__main__][INFO] - Setting up W&B logger with existing run ID: qg1y59ht
[2025-08-13 23:58:40,643][__main__][INFO] - Initializing wandb logger with params
[2025-08-13 23:58:40,651][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-13 23:58:40,651][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-13 23:58:40,651][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-13 23:58:40,651][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-13 23:58:40,651][stage_manager][INFO] -   Total steps: 110000
[2025-08-13 23:58:40,775][__main__][INFO] - Loaded batch size 716 from file
[2025-08-13 23:58:40,775][__main__][INFO] - Effective total batch size across 2 device(s) on 1 node(s) with 1 accumulation steps: 1432
[2025-08-13 23:58:40,781][__main__][INFO] - Saved metadata: {'timestamp': 1755143920.77585, 'slurm_job_id': '30051868', 'batch_size': 716, 'num_devices': 2, 'effective_batch_size': 1432}
[2025-08-13 23:58:48,574][__main__][INFO] - === STARTING TRAINING ===
[2025-08-13 23:59:45,519][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=716
[2025-08-13 23:59:45,521][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 00:46:37,641][__main__][INFO] - === STARTING EXPERIMENT: bb6-full ===
[2025-08-14 00:46:37,641][__main__][INFO] - PID: 592225
[2025-08-14 00:46:37,641][__main__][INFO] - SLURM_JOB_ID: 30091639
[2025-08-14 00:46:37,641][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 00:46:37,641][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 00:46:37,641][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 00:46:37,641][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 00:46:37,641][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 00:46:37,641][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 00:46:37,641][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-14 00:46:37,641][__main__][INFO] - Architecture: rgcn50
[2025-08-14 00:46:37,641][__main__][INFO] - Embedding Dim: 64
[2025-08-14 00:46:37,641][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 00:46:37,641][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 00:46:37,642][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 00:46:37,642][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 00:46:37,642][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 00:46:37,642][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 00:46:37,642][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 00:46:38,263][__main__][INFO] - Num Relations: 66
[2025-08-14 00:46:38,263][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 00:46:38,263][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.75
[2025-08-14 00:46:38,264][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 00:46:38,264][__main__][INFO] - Accelerator: auto
[2025-08-14 00:46:38,264][__main__][INFO] - Devices per node: auto
[2025-08-14 00:46:38,264][__main__][INFO] - Num Nodes: 1
[2025-08-14 00:46:38,264][__main__][INFO] - Total Devices: 1
[2025-08-14 00:46:38,264][__main__][INFO] - Strategy: auto
[2025-08-14 00:46:38,264][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 00:46:38,264][__main__][INFO] - MWPM filtering: False
[2025-08-14 00:46:38,264][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 00:46:38,264][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 00:46:38,264][__main__][INFO] - Max Steps: 50000
[2025-08-14 00:46:38,264][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 00:46:38,265][__main__][INFO] - Log every 100 steps
[2025-08-14 00:46:38,265][__main__][INFO] - Num Workers: 8
[2025-08-14 00:46:38,265][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 00:46:38,265][__main__][INFO] - Persistent Workers: True
[2025-08-14 00:46:38,265][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full
[2025-08-14 00:46:38,278][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 00:46:38,278][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 00:46:46,379][__main__][INFO] - Saved new W&B run ID to file: vd946lqk
[2025-08-14 00:46:47,008][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 00:46:48,753][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=2
[2025-08-14 00:46:50,921][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=4
[2025-08-14 00:46:52,672][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=8
[2025-08-14 00:46:54,551][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=16
[2025-08-14 00:46:56,723][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=32
[2025-08-14 00:46:59,516][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=64
[2025-08-14 00:47:03,597][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=128
[2025-08-14 00:47:05,090][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=96
[2025-08-14 00:47:10,803][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=112
[2025-08-14 00:47:12,418][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=104
[2025-08-14 00:47:18,501][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=108
[2025-08-14 00:47:20,136][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=106
[2025-08-14 00:47:26,282][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=107
[2025-08-14 00:47:32,643][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=107
[2025-08-14 00:49:14,253][__main__][INFO] - === STARTING EXPERIMENT: bb6-full ===
[2025-08-14 00:49:14,253][__main__][INFO] - PID: 593776
[2025-08-14 00:49:14,253][__main__][INFO] - SLURM_JOB_ID: 30091639
[2025-08-14 00:49:14,254][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 00:49:14,254][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 00:49:14,254][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 00:49:14,254][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 00:49:14,254][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 00:49:14,254][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 00:49:14,254][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-14 00:49:14,254][__main__][INFO] - Architecture: rgcn50
[2025-08-14 00:49:14,254][__main__][INFO] - Embedding Dim: 64
[2025-08-14 00:49:14,254][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 00:49:14,254][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 00:49:14,254][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 00:49:14,254][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 00:49:14,254][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 00:49:14,254][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 00:49:14,255][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 00:49:14,875][__main__][INFO] - Num Relations: 66
[2025-08-14 00:49:14,875][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 00:49:14,875][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.75
[2025-08-14 00:49:14,876][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 00:49:14,876][__main__][INFO] - Accelerator: auto
[2025-08-14 00:49:14,876][__main__][INFO] - Devices per node: auto
[2025-08-14 00:49:14,876][__main__][INFO] - Num Nodes: 1
[2025-08-14 00:49:14,876][__main__][INFO] - Total Devices: 1
[2025-08-14 00:49:14,876][__main__][INFO] - Strategy: auto
[2025-08-14 00:49:14,876][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 00:49:14,876][__main__][INFO] - MWPM filtering: False
[2025-08-14 00:49:14,876][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 00:49:14,876][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 00:49:14,876][__main__][INFO] - Max Steps: 50000
[2025-08-14 00:49:14,876][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 00:49:14,877][__main__][INFO] - Log every 100 steps
[2025-08-14 00:49:14,877][__main__][INFO] - Num Workers: 8
[2025-08-14 00:49:14,877][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 00:49:14,877][__main__][INFO] - Persistent Workers: True
[2025-08-14 00:49:14,877][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full
[2025-08-14 00:49:14,888][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 00:49:14,888][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 00:49:16,870][__main__][INFO] - Saved new W&B run ID to file: 98l7knbf
[2025-08-14 00:49:17,491][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 00:49:19,217][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=2
[2025-08-14 00:49:21,359][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=4
[2025-08-14 00:49:23,102][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=8
[2025-08-14 00:49:24,980][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=16
[2025-08-14 00:49:27,147][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=32
[2025-08-14 00:49:29,947][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=64
[2025-08-14 00:49:34,045][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=128
[2025-08-14 00:49:35,559][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=96
[2025-08-14 00:49:41,338][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=112
[2025-08-14 00:49:42,953][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=104
[2025-08-14 00:49:49,039][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=108
[2025-08-14 00:49:50,677][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=106
[2025-08-14 00:49:56,852][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=107
[2025-08-14 00:50:03,192][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=107
[2025-08-14 00:50:05,079][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 00:50:05,218][__main__][INFO] - Found optimal batch size 107
[2025-08-14 00:50:05,223][__main__][INFO] - Saved batch size 90 to file
[2025-08-14 00:50:05,223][__main__][INFO] - Optimal per-GPU batch size found: 90
[2025-08-14 00:50:05,223][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 90
[2025-08-14 00:50:05,226][__main__][INFO] - Saved metadata: {'timestamp': 1755147005.223565, 'slurm_job_id': '30091639', 'batch_size': 90, 'num_devices': 1, 'effective_batch_size': 90}
[2025-08-14 00:50:05,647][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 00:50:06,049][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.75, batch_size=90
[2025-08-14 00:59:09,762][__main__][INFO] - === STARTING EXPERIMENT: bb6-full ===
[2025-08-14 00:59:09,762][__main__][INFO] - PID: 597708
[2025-08-14 00:59:09,762][__main__][INFO] - SLURM_JOB_ID: 30091639
[2025-08-14 00:59:09,762][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 00:59:09,762][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 00:59:09,762][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 00:59:09,762][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 00:59:09,762][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 00:59:09,762][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 00:59:09,762][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-14 00:59:09,762][__main__][INFO] - Architecture: rgcn50
[2025-08-14 00:59:09,763][__main__][INFO] - Embedding Dim: 64
[2025-08-14 00:59:09,763][__main__][INFO] - Learning Rate: 0.0003
[2025-08-14 00:59:09,763][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 00:59:09,763][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 00:59:09,763][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 00:59:09,763][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 00:59:09,763][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 00:59:09,763][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 00:59:10,385][__main__][INFO] - Num Relations: 66
[2025-08-14 00:59:10,385][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 00:59:10,386][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.5
[2025-08-14 00:59:10,386][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 00:59:10,386][__main__][INFO] - Accelerator: auto
[2025-08-14 00:59:10,386][__main__][INFO] - Devices per node: auto
[2025-08-14 00:59:10,386][__main__][INFO] - Num Nodes: 1
[2025-08-14 00:59:10,386][__main__][INFO] - Total Devices: 1
[2025-08-14 00:59:10,386][__main__][INFO] - Strategy: auto
[2025-08-14 00:59:10,386][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 00:59:10,386][__main__][INFO] - MWPM filtering: False
[2025-08-14 00:59:10,386][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 00:59:10,386][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 00:59:10,386][__main__][INFO] - Max Steps: 50000
[2025-08-14 00:59:10,387][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 00:59:10,387][__main__][INFO] - Log every 100 steps
[2025-08-14 00:59:10,387][__main__][INFO] - Num Workers: 8
[2025-08-14 00:59:10,387][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 00:59:10,387][__main__][INFO] - Persistent Workers: True
[2025-08-14 00:59:10,387][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full
[2025-08-14 00:59:10,405][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 00:59:10,405][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 00:59:12,363][__main__][INFO] - Saved new W&B run ID to file: w3u0y4rx
[2025-08-14 00:59:12,987][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 00:59:14,710][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=2
[2025-08-14 00:59:16,819][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=4
[2025-08-14 00:59:18,582][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=8
[2025-08-14 00:59:20,451][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=16
[2025-08-14 00:59:22,609][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=32
[2025-08-14 00:59:25,424][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=64
[2025-08-14 00:59:29,497][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=128
[2025-08-14 00:59:30,972][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=96
[2025-08-14 00:59:36,696][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=112
[2025-08-14 00:59:38,331][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=104
[2025-08-14 00:59:44,419][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=108
[2025-08-14 00:59:46,059][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=106
[2025-08-14 00:59:52,230][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=107
[2025-08-14 00:59:58,584][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=107
[2025-08-14 01:00:00,575][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 01:00:00,729][__main__][INFO] - Found optimal batch size 107
[2025-08-14 01:00:00,734][__main__][INFO] - Saved batch size 90 to file
[2025-08-14 01:00:00,734][__main__][INFO] - Optimal per-GPU batch size found: 90
[2025-08-14 01:00:00,734][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 90
[2025-08-14 01:00:00,739][__main__][INFO] - Saved metadata: {'timestamp': 1755147600.7349572, 'slurm_job_id': '30091639', 'batch_size': 90, 'num_devices': 1, 'effective_batch_size': 90}
[2025-08-14 01:00:01,158][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 01:00:01,561][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=90
[2025-08-14 01:07:48,149][__main__][INFO] - === STARTING EXPERIMENT: bb6-full ===
[2025-08-14 01:07:48,149][__main__][INFO] - PID: 600611
[2025-08-14 01:07:48,149][__main__][INFO] - SLURM_JOB_ID: 30091639
[2025-08-14 01:07:48,149][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 01:07:48,149][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 01:07:48,149][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 01:07:48,149][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 01:07:48,149][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 01:07:48,149][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 01:07:48,149][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-14 01:07:48,149][__main__][INFO] - Architecture: rgcn50
[2025-08-14 01:07:48,149][__main__][INFO] - Embedding Dim: 64
[2025-08-14 01:07:48,149][__main__][INFO] - Learning Rate: 0.0003
[2025-08-14 01:07:48,149][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 01:07:48,150][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 01:07:48,150][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 01:07:48,150][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 01:07:48,150][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 01:07:48,150][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 01:07:48,776][__main__][INFO] - Num Relations: 66
[2025-08-14 01:07:48,776][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 01:07:48,777][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.5
[2025-08-14 01:07:48,777][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 01:07:48,777][__main__][INFO] - Accelerator: auto
[2025-08-14 01:07:48,777][__main__][INFO] - Devices per node: auto
[2025-08-14 01:07:48,777][__main__][INFO] - Num Nodes: 1
[2025-08-14 01:07:48,777][__main__][INFO] - Total Devices: 1
[2025-08-14 01:07:48,777][__main__][INFO] - Strategy: auto
[2025-08-14 01:07:48,777][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 01:07:48,778][__main__][INFO] - MWPM filtering: False
[2025-08-14 01:07:48,778][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 01:07:48,778][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 01:07:48,778][__main__][INFO] - Max Steps: 50000
[2025-08-14 01:07:48,778][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 01:07:48,778][__main__][INFO] - Log every 100 steps
[2025-08-14 01:07:48,778][__main__][INFO] - Num Workers: 8
[2025-08-14 01:07:48,778][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 01:07:48,778][__main__][INFO] - Persistent Workers: True
[2025-08-14 01:07:48,778][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full
[2025-08-14 01:07:48,792][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 01:07:48,793][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 01:07:50,739][__main__][INFO] - Saved new W&B run ID to file: l3kfr2uo
[2025-08-14 01:07:51,359][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 01:07:53,030][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=2
[2025-08-14 01:09:54,987][__main__][INFO] - === STARTING EXPERIMENT: d11-curriculum ===
[2025-08-14 01:09:54,988][__main__][INFO] - PID: 3952082
[2025-08-14 01:09:54,988][__main__][INFO] - SLURM_JOB_ID: 30051868
[2025-08-14 01:09:54,988][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 01:09:54,988][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 01:09:54,988][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 01:09:54,988][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 01:09:54,989][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 01:09:54,989][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 01:09:54,989][__main__][INFO] - SLURM_NODELIST: holygpu8a26504
[2025-08-14 01:09:54,989][__main__][INFO] - Architecture: resnet50
[2025-08-14 01:09:54,989][__main__][INFO] - Embedding Dim: 128
[2025-08-14 01:09:54,989][__main__][INFO] - Learning Rate: 0.0004
[2025-08-14 01:09:54,989][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 01:09:54,989][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 01:09:54,989][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 01:09:54,989][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 01:09:54,989][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 01:09:54,990][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-14 01:09:54,990][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 01:09:54,990][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 01:09:54,990][__main__][INFO] - Use LSTM: False
[2025-08-14 01:09:54,990][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-14 01:09:54,990][__main__][INFO] - Dataset: code_type=surface_code, d=11, rounds_list=[11], p=2.1
[2025-08-14 01:09:54,990][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-14 01:09:54,990][__main__][INFO] - Stage 1: p=0.5 for 40000 steps
[2025-08-14 01:09:54,990][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 01:09:54,991][__main__][INFO] - Stage 3: p=2.1 for 20000 steps
[2025-08-14 01:09:54,991][__main__][INFO] - Total curriculum steps: 110000
[2025-08-14 01:09:54,991][__main__][INFO] - Accelerator: auto
[2025-08-14 01:09:54,991][__main__][INFO] - Devices per node: 2
[2025-08-14 01:09:54,991][__main__][INFO] - Num Nodes: 1
[2025-08-14 01:09:54,991][__main__][INFO] - Total Devices: 2
[2025-08-14 01:09:54,991][__main__][INFO] - Strategy: auto
[2025-08-14 01:09:54,991][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 01:09:54,991][__main__][INFO] - MWPM filtering: False
[2025-08-14 01:09:54,991][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 01:09:54,991][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 01:09:54,992][__main__][INFO] - Max Steps: 110000 (curriculum override)
[2025-08-14 01:09:54,992][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 01:09:54,992][__main__][INFO] - Log every 100 steps
[2025-08-14 01:09:54,992][__main__][INFO] - Num Workers: 6
[2025-08-14 01:09:54,992][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 01:09:54,992][__main__][INFO] - Persistent Workers: True
[2025-08-14 01:09:54,992][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum
[2025-08-14 01:09:55,005][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum/checkpoints/d11-curriculum-step=2158.ckpt
[2025-08-14 01:09:55,008][__main__][INFO] - Loaded W&B run ID from file: qg1y59ht
[2025-08-14 01:09:55,008][__main__][INFO] - Setting up W&B logger with existing run ID: qg1y59ht
[2025-08-14 01:09:55,009][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 01:09:55,018][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-14 01:09:55,018][stage_manager][INFO] -   Stage 1: p=0.5 for 40000 steps
[2025-08-14 01:09:55,018][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 01:09:55,019][stage_manager][INFO] -   Stage 3: p=2.1 for 20000 steps
[2025-08-14 01:09:55,019][stage_manager][INFO] -   Total steps: 110000
[2025-08-14 01:09:55,184][__main__][INFO] - Loaded batch size 716 from file
[2025-08-14 01:09:55,185][__main__][INFO] - Effective total batch size across 2 device(s) on 1 node(s) with 1 accumulation steps: 1432
[2025-08-14 01:09:55,190][__main__][INFO] - Saved metadata: {'timestamp': 1755148195.1853776, 'slurm_job_id': '30051868', 'batch_size': 716, 'num_devices': 2, 'effective_batch_size': 1432}
[2025-08-14 01:10:03,958][data_module][INFO] - Set DataModule global_step_offset to 2158 (will apply when dataset is created)
[2025-08-14 01:10:03,961][__main__][INFO] - Updated DataModule global_step_offset to 2158 for resume
[2025-08-14 01:10:04,124][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 01:10:04,124][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d11-curriculum/checkpoints/d11-curriculum-step=2158.ckpt
[2025-08-14 01:10:05,350][__main__][INFO] - === STARTING EXPERIMENT: bb6-full ===
[2025-08-14 01:10:05,350][__main__][INFO] - PID: 600957
[2025-08-14 01:10:05,351][__main__][INFO] - SLURM_JOB_ID: 30091639
[2025-08-14 01:10:05,351][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 01:10:05,351][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 01:10:05,351][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 01:10:05,351][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 01:10:05,351][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 01:10:05,351][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 01:10:05,351][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-14 01:10:05,351][__main__][INFO] - Architecture: rgcn50
[2025-08-14 01:10:05,351][__main__][INFO] - Embedding Dim: 64
[2025-08-14 01:10:05,351][__main__][INFO] - Learning Rate: 0.0003
[2025-08-14 01:10:05,351][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 01:10:05,351][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 01:10:05,351][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 01:10:05,351][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 01:10:05,351][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 01:10:05,352][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 01:10:05,979][__main__][INFO] - Num Relations: 66
[2025-08-14 01:10:05,979][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 01:10:05,979][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.5
[2025-08-14 01:10:05,979][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 01:10:05,979][__main__][INFO] - Accelerator: auto
[2025-08-14 01:10:05,980][__main__][INFO] - Devices per node: auto
[2025-08-14 01:10:05,980][__main__][INFO] - Num Nodes: 1
[2025-08-14 01:10:05,980][__main__][INFO] - Total Devices: 1
[2025-08-14 01:10:05,980][__main__][INFO] - Strategy: auto
[2025-08-14 01:10:05,980][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 01:10:05,980][__main__][INFO] - MWPM filtering: False
[2025-08-14 01:10:05,980][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 01:10:05,980][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 01:10:05,980][__main__][INFO] - Max Steps: 50000
[2025-08-14 01:10:05,980][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 01:10:05,980][__main__][INFO] - Log every 100 steps
[2025-08-14 01:10:05,980][__main__][INFO] - Num Workers: 8
[2025-08-14 01:10:05,980][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 01:10:05,981][__main__][INFO] - Persistent Workers: True
[2025-08-14 01:10:05,981][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full
[2025-08-14 01:10:05,984][__main__][INFO] - Loaded W&B run ID from file: l3kfr2uo
[2025-08-14 01:10:05,984][__main__][INFO] - Setting up W&B logger with existing run ID: l3kfr2uo
[2025-08-14 01:10:05,984][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 01:10:06,606][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 01:10:08,289][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=2
[2025-08-14 01:10:10,322][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=4
[2025-08-14 01:10:12,032][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=8
[2025-08-14 01:10:13,903][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=16
[2025-08-14 01:10:16,061][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=32
[2025-08-14 01:10:18,873][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=64
[2025-08-14 01:10:22,946][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=128
[2025-08-14 01:10:24,474][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=96
[2025-08-14 01:10:30,210][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=112
[2025-08-14 01:10:31,801][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=104
[2025-08-14 01:10:37,924][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=108
[2025-08-14 01:10:39,544][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=106
[2025-08-14 01:10:45,725][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=107
[2025-08-14 01:10:47,342][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=106
[2025-08-14 01:10:48,302][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=106
[2025-08-14 01:10:50,093][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 01:10:50,201][__main__][INFO] - Found optimal batch size 106
[2025-08-14 01:10:50,207][__main__][INFO] - Saved batch size 90 to file
[2025-08-14 01:10:50,207][__main__][INFO] - Optimal per-GPU batch size found: 90
[2025-08-14 01:10:50,207][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 90
[2025-08-14 01:10:50,209][__main__][INFO] - Saved metadata: {'timestamp': 1755148250.2078617, 'slurm_job_id': '30091639', 'batch_size': 90, 'num_devices': 1, 'effective_batch_size': 90}
[2025-08-14 01:11:10,890][__main__][INFO] - Model loaded from checkpoint at global step 2158
[2025-08-14 01:11:11,230][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=11, rounds_list=[11], p=2.1, batch_size=716
[2025-08-14 01:11:11,230][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 01:28:55,600][__main__][INFO] - === STARTING EXPERIMENT: bb6-full ===
[2025-08-14 01:28:55,600][__main__][INFO] - PID: 607211
[2025-08-14 01:28:55,600][__main__][INFO] - SLURM_JOB_ID: 30091639
[2025-08-14 01:28:55,600][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 01:28:55,601][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 01:28:55,601][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 01:28:55,601][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 01:28:55,601][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 01:28:55,601][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 01:28:55,601][__main__][INFO] - SLURM_NODELIST: holygpu7c26106
[2025-08-14 01:28:55,601][__main__][INFO] - Architecture: rgcn50
[2025-08-14 01:28:55,601][__main__][INFO] - Embedding Dim: 64
[2025-08-14 01:28:55,601][__main__][INFO] - Learning Rate: 0.0005
[2025-08-14 01:28:55,601][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 01:28:55,601][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 01:28:55,601][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 01:28:55,601][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 01:28:55,601][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 01:28:55,601][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 01:28:56,229][__main__][INFO] - Num Relations: 66
[2025-08-14 01:28:56,229][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 01:28:56,229][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.5
[2025-08-14 01:28:56,229][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 01:28:56,230][__main__][INFO] - Accelerator: auto
[2025-08-14 01:28:56,230][__main__][INFO] - Devices per node: auto
[2025-08-14 01:28:56,230][__main__][INFO] - Num Nodes: 1
[2025-08-14 01:28:56,230][__main__][INFO] - Total Devices: 1
[2025-08-14 01:28:56,230][__main__][INFO] - Strategy: auto
[2025-08-14 01:28:56,230][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 01:28:56,230][__main__][INFO] - MWPM filtering: False
[2025-08-14 01:28:56,230][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 01:28:56,230][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 01:28:56,230][__main__][INFO] - Max Steps: 50000
[2025-08-14 01:28:56,230][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 01:28:56,230][__main__][INFO] - Log every 100 steps
[2025-08-14 01:28:56,231][__main__][INFO] - Num Workers: 8
[2025-08-14 01:28:56,231][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 01:28:56,231][__main__][INFO] - Persistent Workers: True
[2025-08-14 01:28:56,231][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full
[2025-08-14 01:28:56,243][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 01:28:56,244][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 01:28:58,195][__main__][INFO] - Saved new W&B run ID to file: salfbioy
[2025-08-14 01:28:58,815][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 01:29:00,484][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=2
[2025-08-14 01:29:02,450][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=4
[2025-08-14 01:29:04,184][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=8
[2025-08-14 01:29:06,046][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=16
[2025-08-14 01:29:08,215][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=32
[2025-08-14 01:29:11,024][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=64
[2025-08-14 01:29:15,096][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=128
[2025-08-14 01:29:16,591][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=96
[2025-08-14 01:29:22,343][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=112
[2025-08-14 01:29:23,944][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=104
[2025-08-14 01:29:29,998][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=108
[2025-08-14 01:29:31,636][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=106
[2025-08-14 01:29:37,874][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=107
[2025-08-14 01:29:44,246][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=107
[2025-08-14 01:29:46,040][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 01:29:46,181][__main__][INFO] - Found optimal batch size 107
[2025-08-14 01:29:46,184][__main__][INFO] - Saved batch size 90 to file
[2025-08-14 01:29:46,185][__main__][INFO] - Optimal per-GPU batch size found: 90
[2025-08-14 01:29:46,185][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 90
[2025-08-14 01:29:46,188][__main__][INFO] - Saved metadata: {'timestamp': 1755149386.1853416, 'slurm_job_id': '30091639', 'batch_size': 90, 'num_devices': 1, 'effective_batch_size': 90}
[2025-08-14 01:29:46,608][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 01:29:47,007][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=90
[2025-08-14 01:50:18,698][__main__][INFO] - === STARTING EXPERIMENT: bb6-full-lr-high ===
[2025-08-14 01:50:18,698][__main__][INFO] - PID: 129683
[2025-08-14 01:50:18,698][__main__][INFO] - SLURM_JOB_ID: 30099998
[2025-08-14 01:50:18,698][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 01:50:18,698][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 01:50:18,698][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 01:50:18,698][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 01:50:18,698][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 01:50:18,698][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 01:50:18,698][__main__][INFO] - SLURM_NODELIST: holygpu8a29505
[2025-08-14 01:50:18,698][__main__][INFO] - Architecture: rgcn50
[2025-08-14 01:50:18,698][__main__][INFO] - Embedding Dim: 64
[2025-08-14 01:50:18,698][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 01:50:18,698][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 01:50:18,699][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 01:50:18,699][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 01:50:18,699][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 01:50:18,699][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 01:50:18,699][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 01:50:19,579][__main__][INFO] - Num Relations: 66
[2025-08-14 01:50:19,580][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 01:50:19,580][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds_list=[7], p=0.5
[2025-08-14 01:50:19,580][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 01:50:19,605][__main__][INFO] - Accelerator: auto
[2025-08-14 01:50:19,605][__main__][INFO] - Devices per node: auto
[2025-08-14 01:50:19,605][__main__][INFO] - Num Nodes: 1
[2025-08-14 01:50:19,606][__main__][INFO] - Total Devices: 1
[2025-08-14 01:50:19,606][__main__][INFO] - Strategy: auto
[2025-08-14 01:50:19,606][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 01:50:19,606][__main__][INFO] - MWPM filtering: False
[2025-08-14 01:50:19,606][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 01:50:19,606][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 01:50:19,606][__main__][INFO] - Max Steps: 50000
[2025-08-14 01:50:19,606][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 01:50:19,606][__main__][INFO] - Log every 100 steps
[2025-08-14 01:50:19,606][__main__][INFO] - Num Workers: 8
[2025-08-14 01:50:19,606][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 01:50:19,606][__main__][INFO] - Persistent Workers: True
[2025-08-14 01:50:19,606][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-full-lr-high
[2025-08-14 01:50:19,620][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 01:50:19,621][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 01:50:27,262][__main__][INFO] - Saved new W&B run ID to file: 2153mtk3
[2025-08-14 01:50:27,946][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 01:50:29,883][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=2
[2025-08-14 01:50:37,999][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=4
[2025-08-14 01:50:39,917][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=8
[2025-08-14 01:50:41,878][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=16
[2025-08-14 01:50:43,905][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=32
[2025-08-14 01:50:46,188][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=64
[2025-08-14 01:50:49,169][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=128
[2025-08-14 01:50:53,534][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=256
[2025-08-14 01:50:55,885][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=192
[2025-08-14 01:51:02,513][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=224
[2025-08-14 01:51:05,083][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=208
[2025-08-14 01:51:12,071][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=216
[2025-08-14 01:51:19,006][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=220
[2025-08-14 01:51:26,195][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=222
[2025-08-14 01:51:29,092][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=221
[2025-08-14 01:51:37,493][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=221
[2025-08-14 01:51:39,603][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 01:51:39,756][__main__][INFO] - Found optimal batch size 221
[2025-08-14 01:51:39,761][__main__][INFO] - Saved batch size 187 to file
[2025-08-14 01:51:39,762][__main__][INFO] - Optimal per-GPU batch size found: 187
[2025-08-14 01:51:39,762][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 187
[2025-08-14 01:51:39,765][__main__][INFO] - Saved metadata: {'timestamp': 1755150699.7624433, 'slurm_job_id': '30099998', 'batch_size': 187, 'num_devices': 1, 'effective_batch_size': 187}
[2025-08-14 01:51:40,201][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 01:51:40,596][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds_list=[7], p=0.5, batch_size=187
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [2025-08-14 06:08:52,181][__main__][ERROR] - === TRAINING FAILED: DataLoader worker (pid 133926) is killed by signal: Terminated.  ===
[2025-08-14 07:19:13,961][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-14 07:19:13,961][__main__][INFO] - PID: 2988419
[2025-08-14 07:19:13,961][__main__][INFO] - SLURM_JOB_ID: 30051885
[2025-08-14 07:19:13,961][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 07:19:13,961][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 07:19:13,961][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 07:19:13,961][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 07:19:13,961][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 07:19:13,961][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 07:19:13,962][__main__][INFO] - SLURM_NODELIST: holygpu8a17503
[2025-08-14 07:19:13,962][__main__][INFO] - Architecture: resnet50
[2025-08-14 07:19:13,962][__main__][INFO] - Embedding Dim: 128
[2025-08-14 07:19:13,962][__main__][INFO] - Learning Rate: 0.0004
[2025-08-14 07:19:13,962][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 07:19:13,962][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 07:19:13,962][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 07:19:13,962][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 07:19:13,962][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 07:19:13,962][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-14 07:19:13,962][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 07:19:13,962][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 07:19:13,962][__main__][INFO] - Use LSTM: False
[2025-08-14 07:19:13,962][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-14 07:19:13,962][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-14 07:19:13,962][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-14 07:19:13,962][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-14 07:19:13,962][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 07:19:13,962][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-14 07:19:13,963][__main__][INFO] - Total curriculum steps: 300000
[2025-08-14 07:19:13,963][__main__][INFO] - Accelerator: auto
[2025-08-14 07:19:13,963][__main__][INFO] - Devices per node: 4
[2025-08-14 07:19:13,963][__main__][INFO] - Num Nodes: 1
[2025-08-14 07:19:13,963][__main__][INFO] - Total Devices: 4
[2025-08-14 07:19:13,963][__main__][INFO] - Strategy: auto
[2025-08-14 07:19:13,963][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 07:19:13,963][__main__][INFO] - MWPM filtering: False
[2025-08-14 07:19:13,963][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 07:19:13,963][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 07:19:13,963][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-14 07:19:13,963][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 07:19:13,963][__main__][INFO] - Log every 100 steps
[2025-08-14 07:19:13,963][__main__][INFO] - Num Workers: 7
[2025-08-14 07:19:13,963][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 07:19:13,963][__main__][INFO] - Persistent Workers: True
[2025-08-14 07:19:13,963][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-14 07:19:13,975][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 07:19:13,975][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 07:19:21,251][__main__][INFO] - Saved new W&B run ID to file: b3emqw4p
[2025-08-14 07:19:21,254][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-14 07:19:21,254][stage_manager][INFO] -   Stage 1: p=0.5 for 50000 steps
[2025-08-14 07:19:21,254][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 07:19:21,254][stage_manager][INFO] -   Stage 3: p=2.1 for 200000 steps
[2025-08-14 07:19:21,254][stage_manager][INFO] -   Total steps: 300000
[2025-08-14 07:19:21,363][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 07:19:22,414][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=2
[2025-08-14 07:19:22,414][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:33,065][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=4
[2025-08-14 07:19:33,066][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:34,093][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=8
[2025-08-14 07:19:34,093][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:35,212][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=16
[2025-08-14 07:19:35,212][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:36,652][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=32
[2025-08-14 07:19:36,652][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:38,250][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=64
[2025-08-14 07:19:38,250][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:40,072][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=128
[2025-08-14 07:19:40,072][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:42,777][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=256
[2025-08-14 07:19:42,777][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:47,207][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=512
[2025-08-14 07:19:47,208][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:48,954][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=384
[2025-08-14 07:19:48,954][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:50,449][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=320
[2025-08-14 07:19:50,449][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:19:55,748][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=352
[2025-08-14 07:19:55,748][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:01,554][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=368
[2025-08-14 07:20:01,554][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:03,339][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=360
[2025-08-14 07:20:03,339][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:05,602][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=356
[2025-08-14 07:20:05,602][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:07,836][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=354
[2025-08-14 07:20:07,836][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:13,603][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=355
[2025-08-14 07:20:13,603][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:19,715][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=355
[2025-08-14 07:20:19,715][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:20:20,460][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 07:20:20,565][__main__][INFO] - Found optimal batch size 355
[2025-08-14 07:20:20,572][__main__][INFO] - Saved batch size 301 to file
[2025-08-14 07:20:20,572][__main__][INFO] - Optimal per-GPU batch size found: 301
[2025-08-14 07:20:20,572][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 1204
[2025-08-14 07:20:20,578][__main__][INFO] - Saved metadata: {'timestamp': 1755170420.5727165, 'slurm_job_id': '30051885', 'batch_size': 301, 'num_devices': 4, 'effective_batch_size': 1204}
[2025-08-14 07:20:20,938][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 07:21:23,632][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=301
[2025-08-14 07:21:23,634][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 07:37:24,683][__main__][ERROR] - === TRAINING FAILED: DataLoader worker (pid 2989403) is killed by signal: Terminated.  ===
[2025-08-14 08:10:29,146][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-14 08:10:29,147][__main__][INFO] - PID: 3113056
[2025-08-14 08:10:29,147][__main__][INFO] - SLURM_JOB_ID: 30051885
[2025-08-14 08:10:29,147][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 08:10:29,147][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 08:10:29,147][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 08:10:29,147][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 08:10:29,147][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 08:10:29,147][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 08:10:29,147][__main__][INFO] - SLURM_NODELIST: holygpu8a17601
[2025-08-14 08:10:29,147][__main__][INFO] - Architecture: resnet50
[2025-08-14 08:10:29,147][__main__][INFO] - Embedding Dim: 128
[2025-08-14 08:10:29,148][__main__][INFO] - Learning Rate: 0.0004
[2025-08-14 08:10:29,148][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 08:10:29,148][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 08:10:29,148][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 08:10:29,148][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 08:10:29,148][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 08:10:29,148][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-14 08:10:29,148][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 08:10:29,148][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 08:10:29,148][__main__][INFO] - Use LSTM: False
[2025-08-14 08:10:29,148][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-14 08:10:29,148][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-14 08:10:29,149][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-14 08:10:29,149][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-14 08:10:29,149][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 08:10:29,149][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-14 08:10:29,149][__main__][INFO] - Total curriculum steps: 300000
[2025-08-14 08:10:29,149][__main__][INFO] - Accelerator: auto
[2025-08-14 08:10:29,149][__main__][INFO] - Devices per node: 4
[2025-08-14 08:10:29,149][__main__][INFO] - Num Nodes: 1
[2025-08-14 08:10:29,149][__main__][INFO] - Total Devices: 4
[2025-08-14 08:10:29,149][__main__][INFO] - Strategy: auto
[2025-08-14 08:10:29,149][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 08:10:29,150][__main__][INFO] - MWPM filtering: False
[2025-08-14 08:10:29,150][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 08:10:29,150][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 08:10:29,150][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-14 08:10:29,150][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 08:10:29,150][__main__][INFO] - Log every 100 steps
[2025-08-14 08:10:29,150][__main__][INFO] - Num Workers: 7
[2025-08-14 08:10:29,150][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 08:10:29,150][__main__][INFO] - Persistent Workers: True
[2025-08-14 08:10:29,150][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-14 08:10:29,165][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=2150.ckpt
[2025-08-14 08:10:29,168][__main__][INFO] - Loaded W&B run ID from file: b3emqw4p
[2025-08-14 08:10:29,168][__main__][INFO] - Setting up W&B logger with existing run ID: b3emqw4p
[2025-08-14 08:10:29,169][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 08:10:29,178][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-14 08:10:29,179][stage_manager][INFO] -   Stage 1: p=0.5 for 50000 steps
[2025-08-14 08:10:29,179][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 08:10:29,179][stage_manager][INFO] -   Stage 3: p=2.1 for 200000 steps
[2025-08-14 08:10:29,179][stage_manager][INFO] -   Total steps: 300000
[2025-08-14 08:10:29,322][__main__][INFO] - Loaded batch size 301 from file
[2025-08-14 08:10:29,322][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 1204
[2025-08-14 08:10:29,328][__main__][INFO] - Saved metadata: {'timestamp': 1755173429.3230577, 'slurm_job_id': '30051885', 'batch_size': 301, 'num_devices': 4, 'effective_batch_size': 1204}
[2025-08-14 08:10:36,659][data_module][INFO] - Set DataModule global_step_offset to 2150 (will apply when dataset is created)
[2025-08-14 08:10:36,662][__main__][INFO] - Updated DataModule global_step_offset to 2150 for resume
[2025-08-14 08:10:36,987][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 08:10:36,987][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=2150.ckpt
[2025-08-14 08:11:43,172][__main__][INFO] - Model loaded from checkpoint at global step 2150
[2025-08-14 08:11:43,423][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=301
[2025-08-14 08:11:43,423][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 10:37:07,717][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-14 10:37:07,718][__main__][INFO] - PID: 2564256
[2025-08-14 10:37:07,718][__main__][INFO] - SLURM_JOB_ID: 30051885
[2025-08-14 10:37:07,718][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 10:37:07,718][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 10:37:07,718][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 10:37:07,718][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 10:37:07,718][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 10:37:07,718][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 10:37:07,718][__main__][INFO] - SLURM_NODELIST: holygpu8a15202
[2025-08-14 10:37:07,718][__main__][INFO] - Architecture: resnet50
[2025-08-14 10:37:07,718][__main__][INFO] - Embedding Dim: 128
[2025-08-14 10:37:07,718][__main__][INFO] - Learning Rate: 0.0004
[2025-08-14 10:37:07,718][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 10:37:07,719][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 10:37:07,719][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 10:37:07,719][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 10:37:07,719][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 10:37:07,719][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-14 10:37:07,719][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 10:37:07,719][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 10:37:07,719][__main__][INFO] - Use LSTM: False
[2025-08-14 10:37:07,719][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-14 10:37:07,719][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-14 10:37:07,719][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-14 10:37:07,719][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-14 10:37:07,719][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 10:37:07,719][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-14 10:37:07,719][__main__][INFO] - Total curriculum steps: 300000
[2025-08-14 10:37:07,719][__main__][INFO] - Accelerator: auto
[2025-08-14 10:37:07,719][__main__][INFO] - Devices per node: 4
[2025-08-14 10:37:07,720][__main__][INFO] - Num Nodes: 1
[2025-08-14 10:37:07,720][__main__][INFO] - Total Devices: 4
[2025-08-14 10:37:07,720][__main__][INFO] - Strategy: auto
[2025-08-14 10:37:07,720][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 10:37:07,720][__main__][INFO] - MWPM filtering: False
[2025-08-14 10:37:07,720][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 10:37:07,720][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 10:37:07,720][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-14 10:37:07,720][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 10:37:07,720][__main__][INFO] - Log every 100 steps
[2025-08-14 10:37:07,720][__main__][INFO] - Num Workers: 7
[2025-08-14 10:37:07,720][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 10:37:07,720][__main__][INFO] - Persistent Workers: True
[2025-08-14 10:37:07,720][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-14 10:37:07,748][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=2150.ckpt
[2025-08-14 10:37:07,753][__main__][INFO] - Loaded W&B run ID from file: b3emqw4p
[2025-08-14 10:37:07,754][__main__][INFO] - Setting up W&B logger with existing run ID: b3emqw4p
[2025-08-14 10:37:07,754][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 10:37:07,763][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-14 10:37:07,763][stage_manager][INFO] -   Stage 1: p=0.5 for 50000 steps
[2025-08-14 10:37:07,763][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 10:37:07,763][stage_manager][INFO] -   Stage 3: p=2.1 for 200000 steps
[2025-08-14 10:37:07,763][stage_manager][INFO] -   Total steps: 300000
[2025-08-14 10:37:07,879][__main__][INFO] - Loaded batch size 301 from file
[2025-08-14 10:37:07,879][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 1204
[2025-08-14 10:37:07,885][__main__][INFO] - Saved metadata: {'timestamp': 1755182227.8800447, 'slurm_job_id': '30051885', 'batch_size': 301, 'num_devices': 4, 'effective_batch_size': 1204}
[2025-08-14 10:37:15,197][data_module][INFO] - Set DataModule global_step_offset to 2150 (will apply when dataset is created)
[2025-08-14 10:37:15,199][__main__][INFO] - Updated DataModule global_step_offset to 2150 for resume
[2025-08-14 10:37:15,507][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 10:37:15,507][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=2150.ckpt
[2025-08-14 10:38:19,644][__main__][INFO] - Model loaded from checkpoint at global step 2150
[2025-08-14 10:38:19,865][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=301
[2025-08-14 10:38:19,865][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 11:37:11,564][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-14 11:37:11,565][__main__][INFO] - PID: 2153660
[2025-08-14 11:37:11,565][__main__][INFO] - SLURM_JOB_ID: 30051885
[2025-08-14 11:37:11,566][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 11:37:11,566][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 11:37:11,566][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 11:37:11,566][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 11:37:11,566][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 11:37:11,566][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 11:37:11,566][__main__][INFO] - SLURM_NODELIST: holygpu8a11302
[2025-08-14 11:37:11,566][__main__][INFO] - Architecture: resnet50
[2025-08-14 11:37:11,566][__main__][INFO] - Embedding Dim: 128
[2025-08-14 11:37:11,566][__main__][INFO] - Learning Rate: 0.0004
[2025-08-14 11:37:11,566][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 11:37:11,566][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 11:37:11,566][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 11:37:11,566][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 11:37:11,566][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 11:37:11,566][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-14 11:37:11,566][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 11:37:11,566][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 11:37:11,566][__main__][INFO] - Use LSTM: False
[2025-08-14 11:37:11,566][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-14 11:37:11,567][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-14 11:37:11,567][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-14 11:37:11,567][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-14 11:37:11,567][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 11:37:11,567][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-14 11:37:11,567][__main__][INFO] - Total curriculum steps: 300000
[2025-08-14 11:37:11,567][__main__][INFO] - Accelerator: auto
[2025-08-14 11:37:11,567][__main__][INFO] - Devices per node: 4
[2025-08-14 11:37:11,567][__main__][INFO] - Num Nodes: 1
[2025-08-14 11:37:11,567][__main__][INFO] - Total Devices: 4
[2025-08-14 11:37:11,567][__main__][INFO] - Strategy: auto
[2025-08-14 11:37:11,567][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 11:37:11,567][__main__][INFO] - MWPM filtering: False
[2025-08-14 11:37:11,567][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 11:37:11,567][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 11:37:11,567][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-14 11:37:11,567][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 11:37:11,567][__main__][INFO] - Log every 100 steps
[2025-08-14 11:37:11,568][__main__][INFO] - Num Workers: 7
[2025-08-14 11:37:11,568][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 11:37:11,568][__main__][INFO] - Persistent Workers: True
[2025-08-14 11:37:11,568][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-14 11:37:11,651][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=4261.ckpt
[2025-08-14 11:37:11,657][__main__][INFO] - Loaded W&B run ID from file: b3emqw4p
[2025-08-14 11:37:11,657][__main__][INFO] - Setting up W&B logger with existing run ID: b3emqw4p
[2025-08-14 11:37:11,657][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 11:37:11,663][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-14 11:37:11,663][stage_manager][INFO] -   Stage 1: p=0.5 for 50000 steps
[2025-08-14 11:37:11,663][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 11:37:11,663][stage_manager][INFO] -   Stage 3: p=2.1 for 200000 steps
[2025-08-14 11:37:11,663][stage_manager][INFO] -   Total steps: 300000
[2025-08-14 11:37:11,770][__main__][INFO] - Loaded batch size 301 from file
[2025-08-14 11:37:11,770][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 1204
[2025-08-14 11:37:11,785][__main__][INFO] - Saved metadata: {'timestamp': 1755185831.770719, 'slurm_job_id': '30051885', 'batch_size': 301, 'num_devices': 4, 'effective_batch_size': 1204}
[2025-08-14 11:37:17,483][data_module][INFO] - Set DataModule global_step_offset to 4261 (will apply when dataset is created)
[2025-08-14 11:37:17,483][__main__][INFO] - Updated DataModule global_step_offset to 4261 for resume
[2025-08-14 11:37:17,787][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 11:37:17,787][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=4261.ckpt
[2025-08-14 11:38:15,118][__main__][INFO] - Model loaded from checkpoint at global step 4261
[2025-08-14 11:38:15,281][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=301
[2025-08-14 11:38:15,281][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 12:44:08,599][__main__][INFO] - === STARTING EXPERIMENT: d15-curriculum ===
[2025-08-14 12:44:08,601][__main__][INFO] - PID: 782179
[2025-08-14 12:44:08,601][__main__][INFO] - SLURM_JOB_ID: 30051885
[2025-08-14 12:44:08,601][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 12:44:08,602][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 12:44:08,602][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 12:44:08,602][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 12:44:08,602][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 12:44:08,602][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 12:44:08,602][__main__][INFO] - SLURM_NODELIST: holygpu8a26504
[2025-08-14 12:44:08,602][__main__][INFO] - Architecture: resnet50
[2025-08-14 12:44:08,602][__main__][INFO] - Embedding Dim: 128
[2025-08-14 12:44:08,602][__main__][INFO] - Learning Rate: 0.0004
[2025-08-14 12:44:08,602][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 12:44:08,602][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 12:44:08,602][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 12:44:08,602][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 12:44:08,603][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 12:44:08,603][__main__][INFO] - Channel Multipliers: [2, 2.5, 3, 3.5]
[2025-08-14 12:44:08,603][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 12:44:08,603][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 12:44:08,603][__main__][INFO] - Use LSTM: False
[2025-08-14 12:44:08,603][__main__][INFO] - Chunking: [1, 1, 1]
[2025-08-14 12:44:08,603][__main__][INFO] - Dataset: code_type=surface_code, d=15, rounds_list=[15], p=2.1
[2025-08-14 12:44:08,603][__main__][INFO] - === 3-STAGE CURRICULUM LEARNING ENABLED ===
[2025-08-14 12:44:08,603][__main__][INFO] - Stage 1: p=0.5 for 50000 steps
[2025-08-14 12:44:08,604][__main__][INFO] - Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 12:44:08,604][__main__][INFO] - Stage 3: p=2.1 for 200000 steps
[2025-08-14 12:44:08,604][__main__][INFO] - Total curriculum steps: 300000
[2025-08-14 12:44:08,604][__main__][INFO] - Accelerator: auto
[2025-08-14 12:44:08,604][__main__][INFO] - Devices per node: 4
[2025-08-14 12:44:08,604][__main__][INFO] - Num Nodes: 1
[2025-08-14 12:44:08,604][__main__][INFO] - Total Devices: 4
[2025-08-14 12:44:08,604][__main__][INFO] - Strategy: auto
[2025-08-14 12:44:08,604][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 12:44:08,604][__main__][INFO] - MWPM filtering: False
[2025-08-14 12:44:08,605][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 12:44:08,605][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 12:44:08,605][__main__][INFO] - Max Steps: 300000 (curriculum override)
[2025-08-14 12:44:08,605][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 12:44:08,605][__main__][INFO] - Log every 100 steps
[2025-08-14 12:44:08,605][__main__][INFO] - Num Workers: 7
[2025-08-14 12:44:08,605][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 12:44:08,605][__main__][INFO] - Persistent Workers: True
[2025-08-14 12:44:08,605][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum
[2025-08-14 12:44:08,641][__main__][INFO] - Found latest checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=4261.ckpt
[2025-08-14 12:44:08,647][__main__][INFO] - Loaded W&B run ID from file: b3emqw4p
[2025-08-14 12:44:08,648][__main__][INFO] - Setting up W&B logger with existing run ID: b3emqw4p
[2025-08-14 12:44:08,648][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 12:44:08,653][stage_manager][INFO] - Initialized 3-stage curriculum learning:
[2025-08-14 12:44:08,653][stage_manager][INFO] -   Stage 1: p=0.5 for 50000 steps
[2025-08-14 12:44:08,653][stage_manager][INFO] -   Stage 2: p=0.5→2.1 over 50000 steps
[2025-08-14 12:44:08,653][stage_manager][INFO] -   Stage 3: p=2.1 for 200000 steps
[2025-08-14 12:44:08,653][stage_manager][INFO] -   Total steps: 300000
[2025-08-14 12:44:08,746][__main__][INFO] - Loaded batch size 301 from file
[2025-08-14 12:44:08,746][__main__][INFO] - Effective total batch size across 4 device(s) on 1 node(s) with 1 accumulation steps: 1204
[2025-08-14 12:44:08,754][__main__][INFO] - Saved metadata: {'timestamp': 1755189848.747087, 'slurm_job_id': '30051885', 'batch_size': 301, 'num_devices': 4, 'effective_batch_size': 1204}
[2025-08-14 12:44:12,077][data_module][INFO] - Set DataModule global_step_offset to 4261 (will apply when dataset is created)
[2025-08-14 12:44:12,078][__main__][INFO] - Updated DataModule global_step_offset to 4261 for resume
[2025-08-14 12:44:12,393][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 12:44:12,393][__main__][INFO] - Resuming from checkpoint: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d15-curriculum/checkpoints/d15-curriculum-step=4261.ckpt
[2025-08-14 12:45:17,219][__main__][INFO] - Model loaded from checkpoint at global step 4261
[2025-08-14 12:45:17,345][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=15, rounds_list=[15], p=2.1, batch_size=301
[2025-08-14 12:45:17,346][data_module][INFO] - Dataset configured for curriculum learning
[2025-08-14 15:30:09,755][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:30:09,755][__main__][INFO] - PID: 1014851
[2025-08-14 15:30:09,755][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:30:09,756][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:30:09,756][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:30:09,756][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:30:09,756][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:30:09,756][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:30:09,756][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:30:09,756][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:30:09,756][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:30:09,756][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:30:09,756][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:30:09,756][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:30:09,756][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:30:09,756][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:30:09,756][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:30:09,756][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:30:09,756][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:31:34,503][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:31:34,503][__main__][INFO] - PID: 1015162
[2025-08-14 15:31:34,503][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:31:34,503][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:31:34,503][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:31:34,503][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:31:34,503][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:31:34,503][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:31:34,504][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:31:34,504][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:31:34,504][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:31:34,504][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:31:34,504][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:31:34,504][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:31:34,504][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:31:34,504][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:31:34,504][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:31:34,504][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:31:34,504][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:31:34,504][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 15:31:34,504][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 15:31:34,505][__main__][INFO] - Use LSTM: False
[2025-08-14 15:35:02,285][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:35:02,285][__main__][INFO] - PID: 1016779
[2025-08-14 15:35:02,285][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:35:02,285][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:35:02,285][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:35:02,285][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:35:02,285][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:35:02,285][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:35:02,285][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:35:02,286][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:35:02,286][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:35:02,286][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:35:02,286][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:35:02,286][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:35:02,286][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:35:02,286][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:35:02,286][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:35:02,286][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:35:02,286][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:35:02,286][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 15:35:02,286][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 15:35:02,286][__main__][INFO] - Use LSTM: False
[2025-08-14 15:36:52,978][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:36:52,978][__main__][INFO] - PID: 1017064
[2025-08-14 15:36:52,978][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:36:52,978][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:36:52,978][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:36:52,978][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:36:52,978][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:36:52,978][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:36:52,978][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:36:52,978][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:36:52,978][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:36:52,978][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:36:52,978][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:36:52,978][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:36:52,979][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:36:52,979][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:36:52,979][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:36:52,979][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:36:52,979][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:36:52,979][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 15:36:52,979][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 15:36:52,979][__main__][INFO] - Use LSTM: False
[2025-08-14 15:36:52,979][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 15:36:52,979][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 15:36:52,979][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 15:36:52,980][__main__][INFO] - Accelerator: auto
[2025-08-14 15:36:52,980][__main__][INFO] - Devices per node: auto
[2025-08-14 15:36:52,980][__main__][INFO] - Num Nodes: 1
[2025-08-14 15:36:52,980][__main__][INFO] - Total Devices: 1
[2025-08-14 15:36:52,980][__main__][INFO] - Strategy: auto
[2025-08-14 15:36:52,980][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 15:36:52,980][__main__][INFO] - MWPM filtering: False
[2025-08-14 15:36:52,980][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 15:36:52,980][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 15:36:52,980][__main__][INFO] - Max Steps: 50000
[2025-08-14 15:36:52,980][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 15:36:52,980][__main__][INFO] - Log every 100 steps
[2025-08-14 15:36:52,980][__main__][INFO] - Num Workers: 8
[2025-08-14 15:36:52,980][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 15:36:52,981][__main__][INFO] - Persistent Workers: True
[2025-08-14 15:36:52,981][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 15:36:53,028][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 15:36:53,029][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 15:36:55,657][__main__][INFO] - Saved new W&B run ID to file: 6axtsy8r
[2025-08-14 15:36:55,777][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 15:36:56,799][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 15:38:44,216][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:38:44,216][__main__][INFO] - PID: 1017333
[2025-08-14 15:38:44,216][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:38:44,216][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:38:44,216][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:38:44,216][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:38:44,216][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:38:44,216][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:38:44,216][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:38:44,216][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:38:44,216][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:38:44,216][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:38:44,217][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:38:44,217][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:38:44,217][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:38:44,217][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:38:44,217][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:38:44,217][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:38:44,217][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:38:44,217][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 15:38:44,217][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 15:38:44,217][__main__][INFO] - Use LSTM: False
[2025-08-14 15:38:44,217][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 15:38:44,217][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 15:38:44,217][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 15:38:44,218][__main__][INFO] - Accelerator: auto
[2025-08-14 15:38:44,218][__main__][INFO] - Devices per node: auto
[2025-08-14 15:38:44,218][__main__][INFO] - Num Nodes: 1
[2025-08-14 15:38:44,218][__main__][INFO] - Total Devices: 1
[2025-08-14 15:38:44,218][__main__][INFO] - Strategy: auto
[2025-08-14 15:38:44,218][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 15:38:44,218][__main__][INFO] - MWPM filtering: False
[2025-08-14 15:38:44,218][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 15:38:44,218][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 15:38:44,218][__main__][INFO] - Max Steps: 50000
[2025-08-14 15:38:44,218][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 15:38:44,218][__main__][INFO] - Log every 100 steps
[2025-08-14 15:38:44,218][__main__][INFO] - Num Workers: 8
[2025-08-14 15:38:44,219][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 15:38:44,219][__main__][INFO] - Persistent Workers: True
[2025-08-14 15:38:44,219][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 15:38:44,240][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 15:38:44,240][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 15:38:46,327][__main__][INFO] - Saved new W&B run ID to file: 9km2nf09
[2025-08-14 15:38:46,417][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 15:38:47,239][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 15:38:53,455][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 15:38:55,118][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 15:38:56,252][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 15:38:57,187][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 15:38:58,386][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 15:39:00,149][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 15:39:03,008][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 15:39:08,109][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 15:39:09,464][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 15:39:10,916][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=320
[2025-08-14 15:39:12,110][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=288
[2025-08-14 15:39:18,089][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=304
[2025-08-14 15:39:19,376][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=296
[2025-08-14 15:39:20,588][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=292
[2025-08-14 15:39:26,660][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=294
[2025-08-14 15:39:27,849][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=293
[2025-08-14 15:39:28,979][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=292
[2025-08-14 15:39:29,485][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=292
[2025-08-14 15:39:30,481][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 15:39:30,592][__main__][INFO] - Found optimal batch size 292
[2025-08-14 15:39:30,599][__main__][INFO] - Saved batch size 248 to file
[2025-08-14 15:39:30,599][__main__][INFO] - Optimal per-GPU batch size found: 248
[2025-08-14 15:39:30,599][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 248
[2025-08-14 15:39:30,605][__main__][INFO] - Saved metadata: {'timestamp': 1755200370.6000326, 'slurm_job_id': '30182809', 'batch_size': 248, 'num_devices': 1, 'effective_batch_size': 248}
[2025-08-14 15:39:31,021][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 15:39:31,054][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=248
[2025-08-14 15:49:49,768][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:49:49,768][__main__][INFO] - PID: 1020168
[2025-08-14 15:49:49,768][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:49:49,768][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:49:49,768][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:49:49,768][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:49:49,768][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:49:49,769][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:49:49,769][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:49:49,769][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:49:49,769][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:49:49,769][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:49:49,769][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:49:49,769][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:49:49,769][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:49:49,769][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:49:49,769][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:49:49,769][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:49:49,769][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:49:49,769][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 15:49:49,770][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 15:49:49,770][__main__][INFO] - Use LSTM: False
[2025-08-14 15:49:49,770][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 15:49:49,770][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 15:49:49,770][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 15:49:49,770][__main__][INFO] - Accelerator: auto
[2025-08-14 15:49:49,770][__main__][INFO] - Devices per node: auto
[2025-08-14 15:49:49,770][__main__][INFO] - Num Nodes: 1
[2025-08-14 15:49:49,770][__main__][INFO] - Total Devices: 1
[2025-08-14 15:49:49,770][__main__][INFO] - Strategy: auto
[2025-08-14 15:49:49,770][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 15:49:49,770][__main__][INFO] - MWPM filtering: False
[2025-08-14 15:49:49,770][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 15:49:49,771][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 15:49:49,771][__main__][INFO] - Max Steps: 50000
[2025-08-14 15:49:49,771][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 15:49:49,771][__main__][INFO] - Log every 100 steps
[2025-08-14 15:49:49,771][__main__][INFO] - Num Workers: 8
[2025-08-14 15:49:49,771][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 15:49:49,771][__main__][INFO] - Persistent Workers: True
[2025-08-14 15:49:49,771][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 15:49:49,776][__main__][INFO] - Loaded W&B run ID from file: 9km2nf09
[2025-08-14 15:49:49,777][__main__][INFO] - Setting up W&B logger with existing run ID: 9km2nf09
[2025-08-14 15:49:49,777][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 15:49:49,851][__main__][INFO] - Compiling model with mode='default', fullgraph=False, dynamic=None
[2025-08-14 15:49:54,554][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 15:49:54,576][__main__][INFO] - Loaded batch size 248 from file
[2025-08-14 15:49:54,576][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 248
[2025-08-14 15:49:54,584][__main__][INFO] - Saved metadata: {'timestamp': 1755200994.5762625, 'slurm_job_id': '30182809', 'batch_size': 248, 'num_devices': 1, 'effective_batch_size': 248}
[2025-08-14 15:51:43,282][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 15:51:43,282][__main__][INFO] - PID: 1020617
[2025-08-14 15:51:43,282][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 15:51:43,282][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 15:51:43,282][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 15:51:43,282][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 15:51:43,282][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 15:51:43,282][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 15:51:43,282][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 15:51:43,282][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 15:51:43,283][__main__][INFO] - Architecture: resnet50
[2025-08-14 15:51:43,283][__main__][INFO] - Embedding Dim: 64
[2025-08-14 15:51:43,283][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 15:51:43,283][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 15:51:43,283][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 15:51:43,283][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 15:51:43,283][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 15:51:43,283][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 15:51:43,283][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 15:51:43,283][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 15:51:43,283][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 15:51:43,283][__main__][INFO] - Use LSTM: False
[2025-08-14 15:51:43,283][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 15:51:43,284][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 15:51:43,284][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 15:51:43,284][__main__][INFO] - Accelerator: auto
[2025-08-14 15:51:43,284][__main__][INFO] - Devices per node: auto
[2025-08-14 15:51:43,284][__main__][INFO] - Num Nodes: 1
[2025-08-14 15:51:43,284][__main__][INFO] - Total Devices: 1
[2025-08-14 15:51:43,284][__main__][INFO] - Strategy: auto
[2025-08-14 15:51:43,284][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 15:51:43,284][__main__][INFO] - MWPM filtering: False
[2025-08-14 15:51:43,284][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 15:51:43,284][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 15:51:43,284][__main__][INFO] - Max Steps: 50000
[2025-08-14 15:51:43,285][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 15:51:43,285][__main__][INFO] - Log every 100 steps
[2025-08-14 15:51:43,285][__main__][INFO] - Num Workers: 8
[2025-08-14 15:51:43,285][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 15:51:43,285][__main__][INFO] - Persistent Workers: True
[2025-08-14 15:51:43,285][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 15:51:43,299][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 15:51:43,299][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 15:51:45,502][__main__][INFO] - Saved new W&B run ID to file: 15lyjord
[2025-08-14 15:51:45,572][__main__][INFO] - Compiling model with mode='default', fullgraph=False, dynamic=None
[2025-08-14 15:51:47,218][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 15:51:47,238][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 15:51:48,064][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 15:52:44,775][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 15:53:21,647][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 15:53:23,180][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 15:53:24,714][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 15:53:26,517][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 15:53:28,836][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 15:53:32,213][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 15:53:37,764][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 15:53:40,099][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 15:53:48,173][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=448
[2025-08-14 15:53:50,867][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=416
[2025-08-14 15:53:53,631][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=400
[2025-08-14 15:53:56,177][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=392
[2025-08-14 15:53:59,466][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 15:54:07,623][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=390
[2025-08-14 15:54:10,854][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 15:54:19,860][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 15:54:20,935][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 15:54:21,061][__main__][INFO] - Found optimal batch size 389
[2025-08-14 15:54:21,069][__main__][INFO] - Saved batch size 330 to file
[2025-08-14 15:54:21,069][__main__][INFO] - Optimal per-GPU batch size found: 330
[2025-08-14 15:54:21,069][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 330
[2025-08-14 15:54:21,073][__main__][INFO] - Saved metadata: {'timestamp': 1755201261.069781, 'slurm_job_id': '30182809', 'batch_size': 330, 'num_devices': 1, 'effective_batch_size': 330}
[2025-08-14 15:54:21,518][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 15:54:21,554][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=330
[2025-08-14 16:00:21,804][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:00:21,805][__main__][INFO] - PID: 1026602
[2025-08-14 16:00:21,805][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:00:21,805][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:00:21,805][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:00:21,805][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:00:21,805][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:00:21,805][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:00:21,805][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:00:21,805][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:00:21,805][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:00:21,805][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:00:21,805][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:00:21,805][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:00:21,805][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:00:21,805][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:00:21,806][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:00:21,806][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:00:21,806][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:00:21,806][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:00:21,806][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:00:21,806][__main__][INFO] - Use LSTM: False
[2025-08-14 16:00:21,806][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:00:21,806][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:00:21,806][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:00:21,806][__main__][INFO] - Accelerator: auto
[2025-08-14 16:00:21,806][__main__][INFO] - Devices per node: auto
[2025-08-14 16:00:21,807][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:00:21,807][__main__][INFO] - Total Devices: 1
[2025-08-14 16:00:21,807][__main__][INFO] - Strategy: auto
[2025-08-14 16:00:21,807][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:00:21,807][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:00:21,807][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:00:21,807][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:00:21,807][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:00:21,807][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:00:21,807][__main__][INFO] - Log every 100 steps
[2025-08-14 16:00:21,807][__main__][INFO] - Num Workers: 8
[2025-08-14 16:00:21,807][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:00:21,807][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:00:21,807][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:00:21,819][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:00:21,819][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:00:23,755][__main__][INFO] - Saved new W&B run ID to file: 0nrik7qp
[2025-08-14 16:00:23,846][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:00:24,680][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:00:25,822][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:00:26,711][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:00:27,494][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:00:28,422][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:00:29,622][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:00:31,432][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:00:34,429][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:00:39,824][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:00:41,021][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 16:00:42,275][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=320
[2025-08-14 16:00:43,451][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=288
[2025-08-14 16:00:49,745][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=304
[2025-08-14 16:00:50,921][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=296
[2025-08-14 16:00:52,115][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=292
[2025-08-14 16:00:53,243][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=290
[2025-08-14 16:00:59,562][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=291
[2025-08-14 16:01:06,211][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=291
[2025-08-14 16:01:07,224][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 16:01:07,342][__main__][INFO] - Found optimal batch size 291
[2025-08-14 16:01:07,349][__main__][INFO] - Saved batch size 269 to file
[2025-08-14 16:01:07,349][__main__][INFO] - Optimal per-GPU batch size found: 269
[2025-08-14 16:01:07,349][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 269
[2025-08-14 16:01:07,353][__main__][INFO] - Saved metadata: {'timestamp': 1755201667.3498943, 'slurm_job_id': '30182809', 'batch_size': 269, 'num_devices': 1, 'effective_batch_size': 269}
[2025-08-14 16:01:07,796][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 16:01:07,831][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=269
[2025-08-14 16:05:01,454][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:05:01,455][__main__][INFO] - PID: 1028578
[2025-08-14 16:05:01,455][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:05:01,455][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:05:01,455][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:05:01,455][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:05:01,455][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:05:01,455][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:05:01,455][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:05:01,455][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:05:01,455][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:05:01,455][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:05:01,455][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:05:01,455][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:05:01,455][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:05:01,455][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:05:01,456][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:05:01,456][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:05:01,456][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:05:01,456][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:05:01,456][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:05:01,456][__main__][INFO] - Use LSTM: False
[2025-08-14 16:05:01,456][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:05:01,456][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:05:01,456][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:05:01,456][__main__][INFO] - Accelerator: auto
[2025-08-14 16:05:01,456][__main__][INFO] - Devices per node: auto
[2025-08-14 16:05:01,457][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:05:01,457][__main__][INFO] - Total Devices: 1
[2025-08-14 16:05:01,457][__main__][INFO] - Strategy: auto
[2025-08-14 16:05:01,457][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:05:01,457][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:05:01,457][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:05:01,457][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:05:01,457][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:05:01,457][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:05:01,457][__main__][INFO] - Log every 100 steps
[2025-08-14 16:05:01,457][__main__][INFO] - Num Workers: 8
[2025-08-14 16:05:01,457][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:05:01,457][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:05:01,458][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:05:01,473][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:05:01,473][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:05:03,546][__main__][INFO] - Saved new W&B run ID to file: bfz20xyz
[2025-08-14 16:05:03,617][__main__][INFO] - Compiling model with mode='default', fullgraph=False, dynamic=None
[2025-08-14 16:05:05,247][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:05:05,267][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:05:06,113][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:05:40,821][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:06:16,563][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:06:18,051][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:06:19,619][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:06:21,391][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:06:23,762][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:06:27,251][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:06:33,005][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:06:35,385][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 16:06:43,821][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=448
[2025-08-14 16:06:46,302][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=416
[2025-08-14 16:06:48,939][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=400
[2025-08-14 16:06:52,990][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=392
[2025-08-14 16:06:56,973][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:07:05,478][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=390
[2025-08-14 16:07:09,468][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 16:07:18,843][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 16:07:19,907][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 16:07:20,018][__main__][INFO] - Found optimal batch size 389
[2025-08-14 16:07:20,025][__main__][INFO] - Saved batch size 359 to file
[2025-08-14 16:07:20,025][__main__][INFO] - Optimal per-GPU batch size found: 359
[2025-08-14 16:07:20,026][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 359
[2025-08-14 16:07:20,030][__main__][INFO] - Saved metadata: {'timestamp': 1755202040.02628, 'slurm_job_id': '30182809', 'batch_size': 359, 'num_devices': 1, 'effective_batch_size': 359}
[2025-08-14 16:07:20,474][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 16:07:20,510][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=359
[2025-08-14 16:12:48,423][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:12:48,423][__main__][INFO] - PID: 1033358
[2025-08-14 16:12:48,423][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:12:48,423][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:12:48,423][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:12:48,423][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:12:48,423][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:12:48,423][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:12:48,423][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:12:48,423][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:12:48,423][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:12:48,423][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:12:48,424][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:12:48,424][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:12:48,424][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:12:48,424][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:12:48,424][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:12:48,424][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:12:48,424][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:12:48,424][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:12:48,424][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:12:48,424][__main__][INFO] - Use LSTM: False
[2025-08-14 16:12:48,424][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:12:48,424][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:12:48,425][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:12:48,425][__main__][INFO] - Accelerator: auto
[2025-08-14 16:12:48,425][__main__][INFO] - Devices per node: auto
[2025-08-14 16:12:48,425][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:12:48,425][__main__][INFO] - Total Devices: 1
[2025-08-14 16:12:48,425][__main__][INFO] - Strategy: auto
[2025-08-14 16:12:48,425][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:12:48,425][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:12:48,425][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:12:48,425][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:12:48,425][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:12:48,425][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:12:48,425][__main__][INFO] - Log every 100 steps
[2025-08-14 16:12:48,425][__main__][INFO] - Num Workers: 8
[2025-08-14 16:12:48,426][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:12:48,426][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:12:48,426][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:12:48,440][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:12:48,440][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:12:50,425][__main__][INFO] - Saved new W&B run ID to file: 3giogc9k
[2025-08-14 16:12:50,497][__main__][INFO] - Compiling model with mode='max-autotune', fullgraph=True, dynamic=False
[2025-08-14 16:12:50,587][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:12:50,608][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:12:51,439][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:16:39,095][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:16:39,096][__main__][INFO] - PID: 1040959
[2025-08-14 16:16:39,096][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:16:39,096][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:16:39,096][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:16:39,096][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:16:39,096][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:16:39,096][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:16:39,096][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:16:39,096][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:16:39,096][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:16:39,096][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:16:39,096][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:16:39,096][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:16:39,096][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:16:39,096][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:16:39,096][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:16:39,097][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:16:39,097][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:16:39,097][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:16:39,097][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:16:39,097][__main__][INFO] - Use LSTM: False
[2025-08-14 16:16:39,097][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:16:39,097][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:16:39,097][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:16:39,097][__main__][INFO] - Accelerator: auto
[2025-08-14 16:16:39,097][__main__][INFO] - Devices per node: auto
[2025-08-14 16:16:39,097][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:16:39,098][__main__][INFO] - Total Devices: 1
[2025-08-14 16:16:39,098][__main__][INFO] - Strategy: auto
[2025-08-14 16:16:39,098][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:16:39,098][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:16:39,098][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:16:39,098][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:16:39,098][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:16:39,098][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:16:39,098][__main__][INFO] - Log every 100 steps
[2025-08-14 16:16:39,098][__main__][INFO] - Num Workers: 8
[2025-08-14 16:16:39,098][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:16:39,098][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:16:39,098][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:16:39,104][__main__][INFO] - Loaded W&B run ID from file: 3giogc9k
[2025-08-14 16:16:39,105][__main__][INFO] - Setting up W&B logger with existing run ID: 3giogc9k
[2025-08-14 16:16:39,105][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:16:39,180][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False, cudagraphs=True
[2025-08-14 16:18:36,528][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:18:36,529][__main__][INFO] - PID: 1041984
[2025-08-14 16:18:36,529][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:18:36,529][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:18:36,529][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:18:36,529][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:18:36,529][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:18:36,529][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:18:36,529][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:18:36,529][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:18:36,529][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:18:36,529][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:18:36,529][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:18:36,529][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:18:36,529][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:18:36,529][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:18:36,530][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:18:36,530][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:18:36,530][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:18:36,530][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:18:36,530][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:18:36,530][__main__][INFO] - Use LSTM: False
[2025-08-14 16:18:36,530][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:18:36,530][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:18:36,530][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:18:36,530][__main__][INFO] - Accelerator: auto
[2025-08-14 16:18:36,530][__main__][INFO] - Devices per node: auto
[2025-08-14 16:18:36,530][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:18:36,531][__main__][INFO] - Total Devices: 1
[2025-08-14 16:18:36,531][__main__][INFO] - Strategy: auto
[2025-08-14 16:18:36,531][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:18:36,531][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:18:36,531][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:18:36,531][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:18:36,531][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:18:36,531][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:18:36,531][__main__][INFO] - Log every 100 steps
[2025-08-14 16:18:36,531][__main__][INFO] - Num Workers: 8
[2025-08-14 16:18:36,531][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:18:36,531][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:18:36,531][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:18:36,547][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:18:36,547][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:18:38,661][__main__][INFO] - Saved new W&B run ID to file: vk4jw3yi
[2025-08-14 16:18:38,733][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 16:18:38,823][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:18:38,843][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:18:39,677][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:18:55,526][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:19:18,939][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:19:43,702][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:20:08,438][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:20:34,222][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:21:02,042][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:21:32,351][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:22:06,037][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:24:17,380][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:24:17,380][__main__][INFO] - PID: 1051642
[2025-08-14 16:24:17,380][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:24:17,380][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:24:17,380][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:24:17,381][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:24:17,381][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:24:17,381][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:24:17,381][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:24:17,381][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:24:17,381][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:24:17,381][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:24:17,381][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:24:17,381][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:24:17,381][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:24:17,381][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:24:17,381][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:24:17,381][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:24:17,381][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:24:17,382][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:24:17,382][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:24:17,382][__main__][INFO] - Use LSTM: False
[2025-08-14 16:24:17,382][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:24:17,382][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:24:17,382][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:24:17,382][__main__][INFO] - Accelerator: auto
[2025-08-14 16:24:17,382][__main__][INFO] - Devices per node: auto
[2025-08-14 16:24:17,382][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:24:17,382][__main__][INFO] - Total Devices: 1
[2025-08-14 16:24:17,382][__main__][INFO] - Strategy: auto
[2025-08-14 16:24:17,382][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:24:17,383][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:24:17,383][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:24:17,383][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:24:17,383][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:24:17,383][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:24:17,383][__main__][INFO] - Log every 100 steps
[2025-08-14 16:24:17,383][__main__][INFO] - Num Workers: 8
[2025-08-14 16:24:17,383][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:24:17,383][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:24:17,383][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:24:17,403][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:24:17,403][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:24:19,420][__main__][INFO] - Saved new W&B run ID to file: zfwkz2ko
[2025-08-14 16:24:19,491][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=None
[2025-08-14 16:24:19,581][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:24:19,601][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:24:20,433][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:24:36,266][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:24:40,770][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:24:41,642][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:24:42,590][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:24:43,808][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:24:45,594][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:24:48,498][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:24:53,666][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:24:54,922][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 16:25:02,703][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=448
[2025-08-14 16:25:04,088][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=416
[2025-08-14 16:25:05,541][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=400
[2025-08-14 16:25:08,448][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=392
[2025-08-14 16:25:11,329][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:25:19,205][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=390
[2025-08-14 16:25:27,252][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=391
[2025-08-14 16:25:35,561][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=391
[2025-08-14 16:25:36,589][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 16:25:36,717][__main__][INFO] - Found optimal batch size 391
[2025-08-14 16:25:36,725][__main__][INFO] - Saved batch size 361 to file
[2025-08-14 16:25:36,725][__main__][INFO] - Optimal per-GPU batch size found: 361
[2025-08-14 16:25:36,725][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 361
[2025-08-14 16:25:36,731][__main__][INFO] - Saved metadata: {'timestamp': 1755203136.7257829, 'slurm_job_id': '30182809', 'batch_size': 361, 'num_devices': 1, 'effective_batch_size': 361}
[2025-08-14 16:25:37,175][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 16:25:37,208][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=361
[2025-08-14 16:25:38,231][__main__][ERROR] - === TRAINING FAILED: call_id with args (TupleVariable(length=1),)

from user code:
   File "/n/home07/andigu/scale/.venv/lib/python3.12/site-packages/wandb/integration/torch/wandb_torch.py", line 336, in after_forward_hook
    output_shape=nested_shape(output),
  File "/n/home07/andigu/scale/.venv/lib/python3.12/site-packages/wandb/integration/torch/wandb_torch.py", line 38, in nested_shape
    seen.add(id(array_or_tuple))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
 ===
[2025-08-14 16:29:20,131][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:29:20,131][__main__][INFO] - PID: 1052937
[2025-08-14 16:29:20,131][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:29:20,131][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:29:20,131][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:29:20,131][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:29:20,131][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:29:20,131][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:29:20,131][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:29:20,131][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:29:20,132][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:29:20,132][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:29:20,132][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:29:20,132][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:29:20,132][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:29:20,132][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:29:20,132][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:29:20,132][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:29:20,132][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:29:20,132][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:29:20,132][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:29:20,132][__main__][INFO] - Use LSTM: False
[2025-08-14 16:29:20,132][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:29:20,133][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:29:20,133][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:29:20,133][__main__][INFO] - Accelerator: auto
[2025-08-14 16:29:20,133][__main__][INFO] - Devices per node: auto
[2025-08-14 16:29:20,133][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:29:20,133][__main__][INFO] - Total Devices: 1
[2025-08-14 16:29:20,133][__main__][INFO] - Strategy: auto
[2025-08-14 16:29:20,133][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:29:20,133][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:29:20,133][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:29:20,133][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:29:20,133][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:29:20,133][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:29:20,134][__main__][INFO] - Log every 100 steps
[2025-08-14 16:29:20,134][__main__][INFO] - Num Workers: 8
[2025-08-14 16:29:20,134][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:29:20,134][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:29:20,134][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:29:20,147][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:29:20,147][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:29:22,346][__main__][INFO] - Saved new W&B run ID to file: o38dp722
[2025-08-14 16:29:22,416][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 16:29:22,417][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 16:29:22,521][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:29:22,549][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:29:23,375][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:29:39,810][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:29:42,516][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:29:46,065][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:29:49,373][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:29:52,468][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:29:56,077][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:30:00,640][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:30:07,503][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:30:25,690][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 16:30:59,106][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=448
[2025-08-14 16:31:27,705][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=416
[2025-08-14 16:31:58,822][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=400
[2025-08-14 16:32:30,877][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=392
[2025-08-14 16:32:59,784][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:33:35,136][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=390
[2025-08-14 16:34:04,659][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 16:34:35,578][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:34:39,087][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:34:40,368][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 16:34:40,509][__main__][INFO] - Found optimal batch size 388
[2025-08-14 16:34:40,517][__main__][INFO] - Saved batch size 358 to file
[2025-08-14 16:34:40,518][__main__][INFO] - Optimal per-GPU batch size found: 358
[2025-08-14 16:34:40,518][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 358
[2025-08-14 16:34:40,523][__main__][INFO] - Saved metadata: {'timestamp': 1755203680.5185406, 'slurm_job_id': '30182809', 'batch_size': 358, 'num_devices': 1, 'effective_batch_size': 358}
[2025-08-14 16:34:40,965][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 16:34:40,988][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=358
[2025-08-14 16:34:58,019][__main__][ERROR] - === TRAINING FAILED: call_id with args (TupleVariable(length=1),)

from user code:
   File "/n/home07/andigu/scale/.venv/lib/python3.12/site-packages/wandb/integration/torch/wandb_torch.py", line 336, in after_forward_hook
    output_shape=nested_shape(output),
  File "/n/home07/andigu/scale/.venv/lib/python3.12/site-packages/wandb/integration/torch/wandb_torch.py", line 38, in nested_shape
    seen.add(id(array_or_tuple))

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
 ===
[2025-08-14 16:37:43,341][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:37:43,342][__main__][INFO] - PID: 1065422
[2025-08-14 16:37:43,342][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:37:43,342][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:37:43,342][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:37:43,342][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:37:43,342][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:37:43,342][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:37:43,342][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:37:43,342][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:37:43,342][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:37:43,342][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:37:43,342][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:37:43,342][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:37:43,342][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:37:43,342][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:37:43,343][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:37:43,343][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:37:43,343][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:37:43,343][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:37:43,343][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:37:43,343][__main__][INFO] - Use LSTM: False
[2025-08-14 16:37:43,343][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:37:43,343][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:37:43,343][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:37:43,343][__main__][INFO] - Accelerator: auto
[2025-08-14 16:37:43,343][__main__][INFO] - Devices per node: auto
[2025-08-14 16:37:43,344][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:37:43,344][__main__][INFO] - Total Devices: 1
[2025-08-14 16:37:43,344][__main__][INFO] - Strategy: auto
[2025-08-14 16:37:43,344][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:37:43,344][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:37:43,344][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:37:43,344][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:37:43,344][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:37:43,344][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:37:43,344][__main__][INFO] - Log every 100 steps
[2025-08-14 16:37:43,344][__main__][INFO] - Num Workers: 8
[2025-08-14 16:37:43,344][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:37:43,344][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:37:43,344][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:37:43,359][__main__][INFO] - W&B logging disabled in config
[2025-08-14 16:37:43,432][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 16:37:43,432][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 16:37:43,521][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:37:43,542][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:37:44,419][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:38:00,352][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:38:03,353][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:38:06,399][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:38:09,602][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:38:13,053][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:38:17,011][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:38:21,896][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:38:28,717][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:38:36,835][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 16:38:45,716][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=448
[2025-08-14 16:38:49,502][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=416
[2025-08-14 16:38:53,844][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=400
[2025-08-14 16:38:58,772][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=392
[2025-08-14 16:39:02,584][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:39:11,759][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=390
[2025-08-14 16:39:15,793][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 16:39:19,721][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:39:20,649][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:39:21,786][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 16:39:21,904][__main__][INFO] - Found optimal batch size 388
[2025-08-14 16:39:21,912][__main__][INFO] - Saved batch size 358 to file
[2025-08-14 16:39:21,912][__main__][INFO] - Optimal per-GPU batch size found: 358
[2025-08-14 16:39:21,912][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 358
[2025-08-14 16:39:21,916][__main__][INFO] - Saved metadata: {'timestamp': 1755203961.9126444, 'slurm_job_id': '30182809', 'batch_size': 358, 'num_devices': 1, 'effective_batch_size': 358}
[2025-08-14 16:39:22,588][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 16:39:22,614][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=358
[2025-08-14 16:42:54,994][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 16:42:54,994][__main__][INFO] - PID: 1067651
[2025-08-14 16:42:54,994][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 16:42:54,994][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:42:54,994][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:42:54,995][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:42:54,995][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:42:54,995][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:42:54,995][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:42:54,995][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 16:42:54,995][__main__][INFO] - Architecture: resnet50
[2025-08-14 16:42:54,995][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:42:54,995][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:42:54,995][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:42:54,995][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:42:54,995][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:42:54,995][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:42:54,995][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:42:54,995][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:42:54,996][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 16:42:54,996][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 16:42:54,996][__main__][INFO] - Use LSTM: False
[2025-08-14 16:42:54,996][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 16:42:54,996][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=0.5
[2025-08-14 16:42:54,996][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:42:54,996][__main__][INFO] - Accelerator: auto
[2025-08-14 16:42:54,996][__main__][INFO] - Devices per node: auto
[2025-08-14 16:42:54,996][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:42:54,996][__main__][INFO] - Total Devices: 1
[2025-08-14 16:42:54,996][__main__][INFO] - Strategy: auto
[2025-08-14 16:42:54,996][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:42:54,996][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:42:54,997][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:42:54,997][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:42:54,997][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:42:54,997][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:42:54,997][__main__][INFO] - Log every 100 steps
[2025-08-14 16:42:54,997][__main__][INFO] - Num Workers: 8
[2025-08-14 16:42:54,997][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:42:54,997][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:42:54,997][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 16:42:55,014][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:42:55,014][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:42:57,282][__main__][INFO] - Saved new W&B run ID to file: p4566eqs
[2025-08-14 16:42:57,353][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 16:42:57,354][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 16:42:57,444][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:42:57,463][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:42:58,312][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=2
[2025-08-14 16:43:14,105][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=4
[2025-08-14 16:43:17,094][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=8
[2025-08-14 16:43:20,179][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=16
[2025-08-14 16:43:23,380][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=32
[2025-08-14 16:43:26,852][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=64
[2025-08-14 16:43:30,847][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=128
[2025-08-14 16:43:35,747][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=256
[2025-08-14 16:43:42,566][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=512
[2025-08-14 16:43:50,423][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=384
[2025-08-14 16:43:59,355][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=448
[2025-08-14 16:44:03,091][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=416
[2025-08-14 16:44:07,419][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=400
[2025-08-14 16:44:12,373][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=392
[2025-08-14 16:44:16,216][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:44:25,363][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=390
[2025-08-14 16:44:29,325][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=389
[2025-08-14 16:44:33,220][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:44:34,153][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=388
[2025-08-14 16:44:35,287][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 16:44:35,405][__main__][INFO] - Found optimal batch size 388
[2025-08-14 16:44:35,413][__main__][INFO] - Saved batch size 378 to file
[2025-08-14 16:44:35,413][__main__][INFO] - Optimal per-GPU batch size found: 378
[2025-08-14 16:44:35,414][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 378
[2025-08-14 16:44:35,420][__main__][INFO] - Saved metadata: {'timestamp': 1755204275.414286, 'slurm_job_id': '30182809', 'batch_size': 378, 'num_devices': 1, 'effective_batch_size': 378}
[2025-08-14 16:44:35,423][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 16:44:35,861][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 16:44:35,885][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=0.5, batch_size=378
[2025-08-14 16:47:27,819][__main__][INFO] - === STARTING EXPERIMENT: bb6-compiled ===
[2025-08-14 16:47:27,819][__main__][INFO] - PID: 3220860
[2025-08-14 16:47:27,819][__main__][INFO] - SLURM_JOB_ID: 30193913
[2025-08-14 16:47:27,819][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:47:27,819][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:47:27,819][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:47:27,819][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:47:27,819][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:47:27,819][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:47:27,819][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-14 16:47:27,819][__main__][INFO] - Architecture: rgcn50
[2025-08-14 16:47:27,819][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:47:27,820][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:47:27,820][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:47:27,820][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:47:27,820][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:47:27,820][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:47:27,820][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:47:27,820][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:47:28,452][__main__][INFO] - Num Relations: 66
[2025-08-14 16:47:28,453][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 16:48:38,834][__main__][INFO] - === STARTING EXPERIMENT: bb6-compiled ===
[2025-08-14 16:48:38,834][__main__][INFO] - PID: 3220885
[2025-08-14 16:48:38,834][__main__][INFO] - SLURM_JOB_ID: 30193913
[2025-08-14 16:48:38,834][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:48:38,834][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:48:38,834][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:48:38,834][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:48:38,834][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:48:38,834][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:48:38,834][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-14 16:48:38,834][__main__][INFO] - Architecture: rgcn50
[2025-08-14 16:48:38,834][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:48:38,834][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:48:38,835][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:48:38,835][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:48:38,835][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:48:38,835][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:48:38,835][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:48:38,835][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:48:39,468][__main__][INFO] - Num Relations: 66
[2025-08-14 16:48:39,468][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 16:48:39,545][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 16:48:39,545][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 16:48:39,545][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:48:39,545][__main__][INFO] - Accelerator: auto
[2025-08-14 16:48:39,545][__main__][INFO] - Devices per node: auto
[2025-08-14 16:48:39,545][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:48:39,545][__main__][INFO] - Total Devices: 1
[2025-08-14 16:48:39,546][__main__][INFO] - Strategy: auto
[2025-08-14 16:48:39,546][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:48:39,546][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:48:39,546][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:48:39,546][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:48:39,546][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:48:39,546][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:48:39,546][__main__][INFO] - Log every 100 steps
[2025-08-14 16:48:39,546][__main__][INFO] - Num Workers: 8
[2025-08-14 16:48:39,546][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:48:39,546][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:48:39,546][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-compiled
[2025-08-14 16:48:39,568][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:48:39,568][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:48:41,942][__main__][INFO] - Saved new W&B run ID to file: ih5b8gwb
[2025-08-14 16:48:42,610][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 16:48:42,611][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 16:48:42,885][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:48:42,913][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:48:45,386][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 16:59:51,708][__main__][INFO] - === STARTING EXPERIMENT: bb6-compiled ===
[2025-08-14 16:59:51,708][__main__][INFO] - PID: 3222567
[2025-08-14 16:59:51,708][__main__][INFO] - SLURM_JOB_ID: 30193913
[2025-08-14 16:59:51,708][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 16:59:51,708][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 16:59:51,708][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 16:59:51,708][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 16:59:51,708][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 16:59:51,708][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 16:59:51,708][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-14 16:59:51,708][__main__][INFO] - Architecture: rgcn50
[2025-08-14 16:59:51,708][__main__][INFO] - Embedding Dim: 64
[2025-08-14 16:59:51,708][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 16:59:51,709][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 16:59:51,709][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 16:59:51,709][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 16:59:51,709][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 16:59:51,709][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 16:59:51,709][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 16:59:52,333][__main__][INFO] - Num Relations: 66
[2025-08-14 16:59:52,333][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 16:59:52,408][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 16:59:52,409][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 16:59:52,409][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 16:59:52,409][__main__][INFO] - Accelerator: auto
[2025-08-14 16:59:52,409][__main__][INFO] - Devices per node: auto
[2025-08-14 16:59:52,409][__main__][INFO] - Num Nodes: 1
[2025-08-14 16:59:52,409][__main__][INFO] - Total Devices: 1
[2025-08-14 16:59:52,409][__main__][INFO] - Strategy: auto
[2025-08-14 16:59:52,409][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 16:59:52,409][__main__][INFO] - MWPM filtering: False
[2025-08-14 16:59:52,409][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 16:59:52,409][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 16:59:52,410][__main__][INFO] - Max Steps: 50000
[2025-08-14 16:59:52,410][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 16:59:52,410][__main__][INFO] - Log every 100 steps
[2025-08-14 16:59:52,410][__main__][INFO] - Num Workers: 8
[2025-08-14 16:59:52,410][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 16:59:52,410][__main__][INFO] - Persistent Workers: True
[2025-08-14 16:59:52,410][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-compiled
[2025-08-14 16:59:52,426][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 16:59:52,426][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 16:59:54,291][__main__][INFO] - Saved new W&B run ID to file: 808hhpfo
[2025-08-14 16:59:54,951][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 16:59:54,951][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 16:59:55,036][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 16:59:55,055][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 16:59:57,256][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 17:00:51,691][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
80
[2025-08-14 17:00:39,465][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 17:00:39,465][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 17:00:39,465][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 17:00:39,465][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 17:00:39,465][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 17:00:39,465][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 17:00:39,465][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 17:00:39,465][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 17:00:39,465][__main__][INFO] - Architecture: resnet50
[2025-08-14 17:00:39,465][__main__][INFO] - Embedding Dim: 64
[2025-08-14 17:00:39,465][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 17:00:39,465][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 17:00:39,465][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 17:00:39,465][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 17:00:39,466][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 17:00:39,466][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 17:00:39,466][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 17:00:39,466][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 17:00:39,466][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 17:00:39,466][__main__][INFO] - Use LSTM: False
[2025-08-14 17:00:39,466][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 17:00:39,466][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=2.1
[2025-08-14 17:00:39,466][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 17:00:39,466][__main__][INFO] - Accelerator: auto
[2025-08-14 17:00:39,466][__main__][INFO] - Devices per node: auto
[2025-08-14 17:00:39,467][__main__][INFO] - Num Nodes: 1
[2025-08-14 17:00:39,467][__main__][INFO] - Total Devices: 1
[2025-08-14 17:00:39,467][__main__][INFO] - Strategy: auto
[2025-08-14 17:00:39,467][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 17:00:39,467][__main__][INFO] - MWPM filtering: False
[2025-08-14 17:00:39,467][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 17:00:39,467][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 17:00:39,467][__main__][INFO] - Max Steps: 50000
[2025-08-14 17:00:39,467][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 17:00:39,467][__main__][INFO] - Log every 100 steps
[2025-08-14 17:00:39,467][__main__][INFO] - Num Workers: 8
[2025-08-14 17:00:39,467][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 17:00:39,467][__main__][INFO] - Persistent Workers: True
[2025-08-14 17:00:39,467][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 17:00:39,473][__main__][INFO] - Loaded W&B run ID from file: p4566eqs
[2025-08-14 17:00:39,474][__main__][INFO] - Setting up W&B logger with existing run ID: p4566eqs
[2025-08-14 17:00:39,474][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 17:00:39,549][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 17:00:39,549][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 17:00:39,647][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 17:00:39,668][__main__][INFO] - Loaded batch size 378 from file
[2025-08-14 17:00:39,668][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 378
[2025-08-14 17:00:39,676][__main__][INFO] - Saved metadata: {'timestamp': 1755205239.6683047, 'slurm_job_id': '30182809', 'batch_size': 378, 'num_devices': 1, 'effective_batch_size': 378}
[2025-08-14 17:00:39,676][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 17:00:41,802][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 17:00:41,982][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=2.1, batch_size=378
[2025-08-14 17:01:21,882][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 17:01:52,418][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 17:02:23,145][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
[2025-08-14 17:02:56,058][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=64
[2025-08-14 17:03:30,265][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=128
[2025-08-14 17:03:53,315][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=96
[2025-08-14 17:04:30,103][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=112
[2025-08-14 17:05:05,236][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=104
[2025-08-14 17:05:41,286][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=108
[2025-08-14 17:06:17,308][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=110
[2025-08-14 17:06:54,929][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=111
[2025-08-14 17:07:40,765][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=111
[2025-08-14 17:07:42,949][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 17:07:43,175][__main__][INFO] - Found optimal batch size 111
[2025-08-14 17:07:43,182][__main__][INFO] - Saved batch size 102 to file
[2025-08-14 17:07:43,183][__main__][INFO] - Optimal per-GPU batch size found: 102
[2025-08-14 17:07:43,183][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 102
[2025-08-14 17:07:43,190][__main__][INFO] - Saved metadata: {'timestamp': 1755205663.1835427, 'slurm_job_id': '30193913', 'batch_size': 102, 'num_devices': 1, 'effective_batch_size': 102}
[2025-08-14 17:07:43,193][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 17:07:43,607][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 17:07:44,028][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=102
[2025-08-14 17:11:02,079][__main__][INFO] - === STARTING EXPERIMENT: d9-test ===
[2025-08-14 17:11:02,079][__main__][INFO] - PID: 1077654
[2025-08-14 17:11:02,079][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 17:11:02,079][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 17:11:02,079][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 17:11:02,080][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 17:11:02,080][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 17:11:02,080][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 17:11:02,080][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 17:11:02,080][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 17:11:02,080][__main__][INFO] - Architecture: resnet50
[2025-08-14 17:11:02,080][__main__][INFO] - Embedding Dim: 64
[2025-08-14 17:11:02,080][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 17:11:02,080][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 17:11:02,080][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 17:11:02,080][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 17:11:02,080][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 17:11:02,080][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 17:11:02,080][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 17:11:02,081][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 17:11:02,081][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 17:11:02,081][__main__][INFO] - Use LSTM: False
[2025-08-14 17:11:02,081][__main__][INFO] - Num Embeddings: 1521
[2025-08-14 17:11:02,081][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=1.0
[2025-08-14 17:11:02,081][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 17:11:02,081][__main__][INFO] - Accelerator: auto
[2025-08-14 17:11:02,081][__main__][INFO] - Devices per node: auto
[2025-08-14 17:11:02,081][__main__][INFO] - Num Nodes: 1
[2025-08-14 17:11:02,081][__main__][INFO] - Total Devices: 1
[2025-08-14 17:11:02,081][__main__][INFO] - Strategy: auto
[2025-08-14 17:11:02,081][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 17:11:02,082][__main__][INFO] - MWPM filtering: False
[2025-08-14 17:11:02,082][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 17:11:02,082][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 17:11:02,082][__main__][INFO] - Max Steps: 50000
[2025-08-14 17:11:02,082][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 17:11:02,082][__main__][INFO] - Log every 100 steps
[2025-08-14 17:11:02,082][__main__][INFO] - Num Workers: 8
[2025-08-14 17:11:02,082][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 17:11:02,082][__main__][INFO] - Persistent Workers: True
[2025-08-14 17:11:02,082][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-test
[2025-08-14 17:11:02,100][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 17:11:02,100][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 17:11:04,058][__main__][INFO] - Saved new W&B run ID to file: 2hq7a74d
[2025-08-14 17:11:04,129][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 17:11:04,129][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 17:11:04,219][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 17:11:04,239][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 17:11:05,077][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=2
[2025-08-14 17:11:20,953][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=4
[2025-08-14 17:11:23,958][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=8
[2025-08-14 17:11:27,015][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=16
[2025-08-14 17:11:30,219][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=32
[2025-08-14 17:11:33,675][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=64
[2025-08-14 17:11:37,603][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=128
[2025-08-14 17:11:42,558][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=256
[2025-08-14 17:11:49,416][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=512
[2025-08-14 17:11:57,404][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=384
[2025-08-14 17:12:06,319][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=448
[2025-08-14 17:12:10,151][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=416
[2025-08-14 17:12:14,547][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=400
[2025-08-14 17:12:19,507][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=392
[2025-08-14 17:12:23,348][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 17:12:32,509][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=390
[2025-08-14 17:12:37,766][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=389
[2025-08-14 17:12:41,697][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 17:12:42,646][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 17:12:43,810][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 17:12:43,930][__main__][INFO] - Found optimal batch size 388
[2025-08-14 17:12:43,939][__main__][INFO] - Saved batch size 378 to file
[2025-08-14 17:12:43,939][__main__][INFO] - Optimal per-GPU batch size found: 378
[2025-08-14 17:12:43,939][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 378
[2025-08-14 17:12:43,945][__main__][INFO] - Saved metadata: {'timestamp': 1755205963.9397128, 'slurm_job_id': '30182809', 'batch_size': 378, 'num_devices': 1, 'effective_batch_size': 378}
[2025-08-14 17:12:43,947][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 17:12:44,385][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 17:12:44,411][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=378
[2025-08-14 17:17:06,997][__main__][INFO] - === STARTING EXPERIMENT: bb6-075 ===
[2025-08-14 17:17:06,997][__main__][INFO] - PID: 3768963
[2025-08-14 17:17:06,997][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 17:17:06,997][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 17:17:06,997][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 17:17:06,997][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 17:17:06,997][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 17:17:06,997][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 17:17:06,997][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 17:17:06,997][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 17:17:06,997][__main__][INFO] - Architecture: rgcn50
[2025-08-14 17:17:06,997][__main__][INFO] - Embedding Dim: 64
[2025-08-14 17:17:06,997][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 17:17:06,997][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 17:17:06,998][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 17:17:06,998][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 17:17:06,998][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 17:17:06,998][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 17:17:06,998][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 17:17:07,935][__main__][INFO] - Num Relations: 66
[2025-08-14 17:17:07,935][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 17:17:08,010][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 17:17:08,010][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.75
[2025-08-14 17:17:08,010][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 17:17:08,035][__main__][INFO] - Accelerator: auto
[2025-08-14 17:17:08,035][__main__][INFO] - Devices per node: auto
[2025-08-14 17:17:08,035][__main__][INFO] - Num Nodes: 1
[2025-08-14 17:17:08,035][__main__][INFO] - Total Devices: 1
[2025-08-14 17:17:08,035][__main__][INFO] - Strategy: auto
[2025-08-14 17:17:08,035][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 17:17:08,035][__main__][INFO] - MWPM filtering: False
[2025-08-14 17:17:08,035][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 17:17:08,035][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 17:17:08,036][__main__][INFO] - Max Steps: 50000
[2025-08-14 17:17:08,036][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 17:17:08,036][__main__][INFO] - Log every 100 steps
[2025-08-14 17:17:08,036][__main__][INFO] - Num Workers: 8
[2025-08-14 17:17:08,036][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 17:17:08,036][__main__][INFO] - Persistent Workers: True
[2025-08-14 17:17:08,036][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-075
[2025-08-14 17:17:08,073][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 17:17:08,073][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 17:17:14,050][__main__][INFO] - Saved new W&B run ID to file: oy79faxu
[2025-08-14 17:17:14,736][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 17:17:14,737][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 17:17:15,014][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 17:17:15,061][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 17:17:16,905][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=2
[2025-08-14 17:18:22,326][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=4
[2025-08-14 17:20:15,057][__main__][INFO] - === STARTING EXPERIMENT: bb6-075 ===
[2025-08-14 17:20:15,057][__main__][INFO] - PID: 3772884
[2025-08-14 17:20:15,057][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 17:20:15,057][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 17:20:15,057][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 17:20:15,057][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 17:20:15,057][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 17:20:15,057][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 17:20:15,058][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 17:20:15,058][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 17:20:15,058][__main__][INFO] - Architecture: rgcn50
[2025-08-14 17:20:15,058][__main__][INFO] - Embedding Dim: 64
[2025-08-14 17:20:15,058][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 17:20:15,058][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 17:20:15,058][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 17:20:15,058][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 17:20:15,058][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 17:20:15,058][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 17:20:15,058][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 17:20:15,681][__main__][INFO] - Num Relations: 66
[2025-08-14 17:20:15,681][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 17:20:15,756][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 17:20:15,756][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.75
[2025-08-14 17:20:15,756][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 17:20:15,786][__main__][INFO] - Accelerator: auto
[2025-08-14 17:20:15,786][__main__][INFO] - Devices per node: auto
[2025-08-14 17:20:15,786][__main__][INFO] - Num Nodes: 1
[2025-08-14 17:20:15,786][__main__][INFO] - Total Devices: 1
[2025-08-14 17:20:15,786][__main__][INFO] - Strategy: auto
[2025-08-14 17:20:15,786][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 17:20:15,787][__main__][INFO] - MWPM filtering: False
[2025-08-14 17:20:15,787][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 17:20:15,787][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 17:20:15,787][__main__][INFO] - Max Steps: 50000
[2025-08-14 17:20:15,787][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 17:20:15,787][__main__][INFO] - Log every 100 steps
[2025-08-14 17:20:15,787][__main__][INFO] - Num Workers: 6
[2025-08-14 17:20:15,787][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 17:20:15,787][__main__][INFO] - Persistent Workers: True
[2025-08-14 17:20:15,787][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-075
[2025-08-14 17:20:15,810][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 17:20:15,810][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 17:20:17,786][__main__][INFO] - Saved new W&B run ID to file: i089igk0
[2025-08-14 17:20:18,431][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 17:20:18,431][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 17:20:18,521][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 17:20:18,542][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 17:20:20,252][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=2
[2025-08-14 17:20:47,806][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=4
[2025-08-14 17:20:51,607][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=8
[2025-08-14 17:21:20,401][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=16
[2025-08-14 17:21:49,214][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=32
[2025-08-14 17:22:19,591][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=64
[2025-08-14 17:22:49,044][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=128
[2025-08-14 17:23:21,153][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=256
[2025-08-14 17:23:57,207][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=512
[2025-08-14 17:24:31,375][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=384
[2025-08-14 17:25:07,355][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=448
[2025-08-14 17:25:44,726][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=480
[2025-08-14 17:26:18,012][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=464
[2025-08-14 17:26:55,911][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=472
[2025-08-14 17:27:34,984][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=476
[2025-08-14 17:28:14,199][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=474
[2025-08-14 17:28:54,439][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=475
[2025-08-14 17:29:43,929][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=475
[2025-08-14 17:29:46,274][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 17:29:46,506][__main__][INFO] - Found optimal batch size 475
[2025-08-14 17:29:46,519][__main__][INFO] - Saved batch size 465 to file
[2025-08-14 17:29:46,519][__main__][INFO] - Optimal per-GPU batch size found: 465
[2025-08-14 17:29:46,519][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 465
[2025-08-14 17:29:46,526][__main__][INFO] - Saved metadata: {'timestamp': 1755206986.5199716, 'slurm_job_id': '30199015', 'batch_size': 465, 'num_devices': 1, 'effective_batch_size': 465}
[2025-08-14 17:29:46,529][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 17:29:46,971][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 17:29:47,384][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=465
[2025-08-14 17:30:22,855][__main__][ERROR] - === TRAINING FAILED: CUDA out of memory. Tried to allocate 7.90 GiB. GPU 0 has a total capacity of 79.25 GiB of which 2.13 GiB is free. Including non-PyTorch memory, this process has 77.11 GiB memory in use. Of the allocated memory 68.24 GiB is allocated by PyTorch, and 8.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) ===
[2025-08-14 17:33:24,729][__main__][INFO] - === STARTING EXPERIMENT: bb6-075 ===
[2025-08-14 17:33:24,729][__main__][INFO] - PID: 3802454
[2025-08-14 17:33:24,729][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 17:33:24,729][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 17:33:24,729][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 17:33:24,729][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 17:33:24,729][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 17:33:24,729][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 17:33:24,730][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 17:33:24,730][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 17:33:24,730][__main__][INFO] - Architecture: rgcn50
[2025-08-14 17:33:24,730][__main__][INFO] - Embedding Dim: 64
[2025-08-14 17:33:24,730][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 17:33:24,730][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 17:33:24,730][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 17:33:24,730][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 17:33:24,730][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 17:33:24,730][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 17:33:24,730][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 17:33:25,352][__main__][INFO] - Num Relations: 66
[2025-08-14 17:33:25,353][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 17:33:25,427][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 17:33:25,428][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.75
[2025-08-14 17:33:25,428][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 17:33:25,452][__main__][INFO] - Accelerator: auto
[2025-08-14 17:33:25,452][__main__][INFO] - Devices per node: auto
[2025-08-14 17:33:25,452][__main__][INFO] - Num Nodes: 1
[2025-08-14 17:33:25,452][__main__][INFO] - Total Devices: 1
[2025-08-14 17:33:25,452][__main__][INFO] - Strategy: auto
[2025-08-14 17:33:25,452][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 17:33:25,452][__main__][INFO] - MWPM filtering: False
[2025-08-14 17:33:25,452][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 17:33:25,453][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 17:33:25,453][__main__][INFO] - Max Steps: 50000
[2025-08-14 17:33:25,453][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 17:33:25,453][__main__][INFO] - Log every 100 steps
[2025-08-14 17:33:25,453][__main__][INFO] - Num Workers: 6
[2025-08-14 17:33:25,453][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 17:33:25,453][__main__][INFO] - Persistent Workers: True
[2025-08-14 17:33:25,453][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-075
[2025-08-14 17:33:25,510][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 17:33:25,511][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 17:33:27,479][__main__][INFO] - Saved new W&B run ID to file: pmunjt1i
[2025-08-14 17:33:28,123][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 17:33:28,123][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 17:33:28,213][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 17:33:28,250][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 17:33:29,961][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=2
[2025-08-14 17:33:46,908][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=4
[2025-08-14 17:33:50,735][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=8
[2025-08-14 17:33:54,612][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=16
[2025-08-14 17:33:58,677][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=32
[2025-08-14 17:34:02,882][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=64
[2025-08-14 17:34:07,522][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=128
[2025-08-14 17:34:12,722][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=256
[2025-08-14 17:34:19,639][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=512
[2025-08-14 17:34:23,735][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=384
[2025-08-14 17:34:31,981][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=448
[2025-08-14 17:34:36,565][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=416
[2025-08-14 17:35:13,246][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=432
[2025-08-14 17:35:46,248][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=424
[2025-08-14 17:36:21,998][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=428
[2025-08-14 17:36:59,617][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=430
[2025-08-14 17:37:38,871][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=431
[2025-08-14 17:38:24,856][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=431
[2025-08-14 17:38:27,217][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 17:38:27,404][__main__][INFO] - Found optimal batch size 431
[2025-08-14 17:38:27,415][__main__][INFO] - Saved batch size 401 to file
[2025-08-14 17:38:27,415][__main__][INFO] - Optimal per-GPU batch size found: 401
[2025-08-14 17:38:27,416][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 401
[2025-08-14 17:38:27,423][__main__][INFO] - Saved metadata: {'timestamp': 1755207507.416158, 'slurm_job_id': '30199015', 'batch_size': 401, 'num_devices': 1, 'effective_batch_size': 401}
[2025-08-14 17:38:27,426][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 17:38:27,863][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 17:38:28,284][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.75, batch_size=401
[2025-08-14 17:46:14,085][__main__][INFO] - === STARTING EXPERIMENT: bb6-05 ===
[2025-08-14 17:46:14,085][__main__][INFO] - PID: 3816748
[2025-08-14 17:46:14,085][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 17:46:14,086][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 17:46:14,086][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 17:46:14,086][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 17:46:14,086][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 17:46:14,086][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 17:46:14,086][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 17:46:14,086][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 17:46:14,086][__main__][INFO] - Architecture: rgcn50
[2025-08-14 17:46:14,086][__main__][INFO] - Embedding Dim: 64
[2025-08-14 17:46:14,086][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 17:46:14,086][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 17:46:14,086][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 17:46:14,086][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 17:46:14,086][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 17:46:14,086][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 17:46:14,087][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 17:46:14,712][__main__][INFO] - Num Relations: 66
[2025-08-14 17:46:14,712][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 17:46:14,787][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 17:46:14,788][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 17:46:14,788][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 17:46:14,812][__main__][INFO] - Accelerator: auto
[2025-08-14 17:46:14,812][__main__][INFO] - Devices per node: auto
[2025-08-14 17:46:14,812][__main__][INFO] - Num Nodes: 1
[2025-08-14 17:46:14,812][__main__][INFO] - Total Devices: 1
[2025-08-14 17:46:14,812][__main__][INFO] - Strategy: auto
[2025-08-14 17:46:14,812][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 17:46:14,812][__main__][INFO] - MWPM filtering: False
[2025-08-14 17:46:14,812][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 17:46:14,812][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 17:46:14,812][__main__][INFO] - Max Steps: 50000
[2025-08-14 17:46:14,812][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 17:46:14,813][__main__][INFO] - Log every 100 steps
[2025-08-14 17:46:14,813][__main__][INFO] - Num Workers: 6
[2025-08-14 17:46:14,813][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 17:46:14,813][__main__][INFO] - Persistent Workers: True
[2025-08-14 17:46:14,813][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05
[2025-08-14 17:46:14,837][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 17:46:14,838][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 17:46:16,762][__main__][INFO] - Saved new W&B run ID to file: 4i1pa40s
[2025-08-14 17:46:17,415][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 17:46:17,415][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 17:46:17,505][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 17:46:17,525][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 17:46:19,349][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 17:46:36,282][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
[2025-08-14 17:46:40,155][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 17:46:44,064][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 17:46:48,078][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
[2025-08-14 17:46:52,314][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=64
[2025-08-14 17:46:56,923][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=128
[2025-08-14 17:47:02,116][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=256
[2025-08-14 17:47:09,034][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=512
[2025-08-14 17:47:13,260][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=384
[2025-08-14 17:47:21,427][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=448
[2025-08-14 17:47:25,911][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=416
[2025-08-14 17:47:34,540][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=432
[2025-08-14 17:47:43,530][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=440
[2025-08-14 17:48:21,135][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=444
[2025-08-14 17:48:58,427][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=446
[2025-08-14 17:49:36,453][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=447
[2025-08-14 17:50:21,644][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=447
[2025-08-14 17:50:23,722][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 17:50:23,941][__main__][INFO] - Found optimal batch size 447
[2025-08-14 17:50:23,956][__main__][INFO] - Saved batch size 417 to file
[2025-08-14 17:50:23,956][__main__][INFO] - Optimal per-GPU batch size found: 417
[2025-08-14 17:50:23,956][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 417
[2025-08-14 17:50:23,963][__main__][INFO] - Saved metadata: {'timestamp': 1755208223.956795, 'slurm_job_id': '30199015', 'batch_size': 417, 'num_devices': 1, 'effective_batch_size': 417}
[2025-08-14 17:50:23,966][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 17:50:24,402][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 17:50:24,810][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=417
[2025-08-14 18:00:37,476][__main__][INFO] - === STARTING EXPERIMENT: bb6-05 ===
[2025-08-14 18:00:37,476][__main__][INFO] - PID: 3827496
[2025-08-14 18:00:37,476][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 18:00:37,477][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 18:00:37,477][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 18:00:37,477][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 18:00:37,477][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 18:00:37,477][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 18:00:37,477][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 18:00:37,477][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 18:00:37,477][__main__][INFO] - Architecture: rgcn50
[2025-08-14 18:00:37,477][__main__][INFO] - Embedding Dim: 64
[2025-08-14 18:00:37,477][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 18:00:37,477][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 18:00:37,477][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 18:00:37,477][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 18:00:37,477][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 18:00:37,477][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 18:00:37,477][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 18:00:38,103][__main__][INFO] - Num Relations: 66
[2025-08-14 18:00:38,104][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 18:02:33,589][__main__][INFO] - === STARTING EXPERIMENT: bb6-05 ===
[2025-08-14 18:02:33,589][__main__][INFO] - PID: 3827833
[2025-08-14 18:02:33,589][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 18:02:33,589][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 18:02:33,589][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 18:02:33,589][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 18:02:33,589][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 18:02:33,589][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 18:02:33,589][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 18:02:33,590][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 18:02:33,590][__main__][INFO] - Architecture: rgcn50
[2025-08-14 18:02:33,590][__main__][INFO] - Embedding Dim: 64
[2025-08-14 18:02:33,590][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 18:02:33,590][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 18:02:33,590][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 18:02:33,590][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 18:02:33,590][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 18:02:33,590][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 18:02:33,590][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 18:02:34,210][__main__][INFO] - Num Relations: 66
[2025-08-14 18:02:34,211][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 18:02:34,284][__main__][INFO] - Num Embeddings: 144
[2025-08-14 18:02:34,285][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 18:02:34,285][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 18:02:34,307][__main__][INFO] - Accelerator: auto
[2025-08-14 18:02:34,307][__main__][INFO] - Devices per node: auto
[2025-08-14 18:02:34,308][__main__][INFO] - Num Nodes: 1
[2025-08-14 18:02:34,308][__main__][INFO] - Total Devices: 1
[2025-08-14 18:02:34,308][__main__][INFO] - Strategy: auto
[2025-08-14 18:02:34,308][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 18:02:34,308][__main__][INFO] - MWPM filtering: False
[2025-08-14 18:02:34,308][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 18:02:34,308][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 18:02:34,308][__main__][INFO] - Max Steps: 50000
[2025-08-14 18:02:34,308][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 18:02:34,308][__main__][INFO] - Log every 100 steps
[2025-08-14 18:02:34,308][__main__][INFO] - Num Workers: 6
[2025-08-14 18:02:34,308][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 18:02:34,308][__main__][INFO] - Persistent Workers: True
[2025-08-14 18:02:34,309][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05
[2025-08-14 18:02:34,328][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 18:02:34,328][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 18:02:41,353][__main__][INFO] - Saved new W&B run ID to file: o6xs0erb
[2025-08-14 18:02:41,995][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 18:02:41,995][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 18:02:42,093][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 18:02:42,115][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 18:02:43,821][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 18:03:23,424][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
[2025-08-14 18:03:50,868][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 18:04:18,328][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 18:04:45,403][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
90653
[2025-08-14 18:04:19,660][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 18:04:19,660][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 18:04:19,660][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 18:04:19,660][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 18:04:19,660][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 18:04:19,660][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 18:04:19,660][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 18:04:19,660][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 18:04:19,660][__main__][INFO] - Architecture: resnet50
[2025-08-14 18:04:19,660][__main__][INFO] - Embedding Dim: 64
[2025-08-14 18:04:19,660][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 18:04:19,660][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 18:04:19,660][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 18:04:19,660][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 18:04:19,661][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 18:04:19,661][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 18:04:19,661][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 18:04:19,661][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 18:04:19,661][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 18:04:19,661][__main__][INFO] - Use LSTM: False
[2025-08-14 18:04:19,661][__main__][INFO] - Num Embeddings: 161
[2025-08-14 18:04:19,661][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=1.0
[2025-08-14 18:04:19,661][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 18:04:19,661][__main__][INFO] - Accelerator: auto
[2025-08-14 18:04:19,661][__main__][INFO] - Devices per node: auto
[2025-08-14 18:04:19,662][__main__][INFO] - Num Nodes: 1
[2025-08-14 18:04:19,662][__main__][INFO] - Total Devices: 1
[2025-08-14 18:04:19,662][__main__][INFO] - Strategy: auto
[2025-08-14 18:04:19,662][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 18:04:19,662][__main__][INFO] - MWPM filtering: False
[2025-08-14 18:04:19,662][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 18:04:19,662][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 18:04:19,662][__main__][INFO] - Max Steps: 50000
[2025-08-14 18:04:19,662][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 18:04:19,662][__main__][INFO] - Log every 100 steps
[2025-08-14 18:04:19,662][__main__][INFO] - Num Workers: 8
[2025-08-14 18:04:19,662][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 18:04:19,662][__main__][INFO] - Persistent Workers: True
[2025-08-14 18:04:19,662][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-time-sym
[2025-08-14 18:04:19,685][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 18:04:19,685][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 18:04:22,213][__main__][INFO] - Saved new W&B run ID to file: a4o8uu2p
[2025-08-14 18:04:22,284][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 18:04:22,284][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 18:04:22,400][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 18:04:22,448][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 18:04:23,291][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=2
[2025-08-14 18:05:00,377][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=4
[2025-08-14 18:05:21,663][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=8
                                                                                                                                                                                                                                                                                                                                                                                       [2025-08-14 18:05:45,704][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=16
[2025-08-14 18:06:07,973][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=32
[2025-08-14 18:06:31,865][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=64
[2025-08-14 18:06:57,756][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=128
[2025-08-14 18:07:25,372][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=256
[2025-08-14 18:07:52,788][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=512
[2025-08-14 18:08:12,000][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=384
[2025-08-14 18:08:43,360][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=448
[2025-08-14 18:09:13,033][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=416
[2025-08-14 18:09:42,381][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=400
[2025-08-14 18:10:13,330][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=392
[2025-08-14 18:10:42,704][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:11:25,948][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=390
[2025-08-14 18:11:47,489][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=389
[2025-08-14 18:12:21,184][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:12:26,897][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2025-08-14 18:12:28,288][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 18:12:28,459][__main__][INFO] - Found optimal batch size 388
[2025-08-14 18:12:28,466][__main__][INFO] - Saved batch size 358 to file
[2025-08-14 18:12:28,466][__main__][INFO] - Optimal per-GPU batch size found: 358
[2025-08-14 18:12:28,466][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 358
[2025-08-14 18:12:28,473][__main__][INFO] - Saved metadata: {'timestamp': 1755209548.4668524, 'slurm_job_id': '30182809', 'batch_size': 358, 'num_devices': 1, 'effective_batch_size': 358}
[2025-08-14 18:12:28,476][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 18:12:28,926][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 18:12:28,951][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=358
[2025-08-14 18:16:41,421][__main__][INFO] - === STARTING EXPERIMENT: d9-time-sym ===
[2025-08-14 18:16:41,421][__main__][INFO] - PID: 1096757
[2025-08-14 18:16:41,421][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 18:16:41,421][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 18:16:41,421][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 18:16:41,421][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 18:16:41,421][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 18:16:41,421][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 18:16:41,421][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 18:16:41,421][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 18:16:41,421][__main__][INFO] - Architecture: resnet50
[2025-08-14 18:16:41,422][__main__][INFO] - Embedding Dim: 64
[2025-08-14 18:16:41,422][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 18:16:41,422][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 18:16:41,422][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 18:16:41,422][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 18:16:41,422][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 18:16:41,422][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 18:16:41,422][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 18:16:41,422][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 18:16:41,422][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 18:16:41,422][__main__][INFO] - Use LSTM: False
[2025-08-14 18:16:41,422][__main__][INFO] - Num Embeddings: 161
[2025-08-14 18:16:41,423][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=1.0
[2025-08-14 18:16:41,423][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 18:16:41,423][__main__][INFO] - Accelerator: auto
[2025-08-14 18:16:41,423][__main__][INFO] - Devices per node: auto
[2025-08-14 18:16:41,423][__main__][INFO] - Num Nodes: 1
[2025-08-14 18:16:41,423][__main__][INFO] - Total Devices: 1
[2025-08-14 18:16:41,423][__main__][INFO] - Strategy: auto
[2025-08-14 18:16:41,423][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 18:16:41,423][__main__][INFO] - MWPM filtering: False
[2025-08-14 18:16:41,423][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 18:16:41,423][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 18:16:41,423][__main__][INFO] - Max Steps: 50000
[2025-08-14 18:16:41,423][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 18:16:41,423][__main__][INFO] - Log every 100 steps
[2025-08-14 18:16:41,424][__main__][INFO] - Num Workers: 8
[2025-08-14 18:16:41,424][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 18:16:41,424][__main__][INFO] - Persistent Workers: True
[2025-08-14 18:16:41,424][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-time-sym
[2025-08-14 18:16:41,442][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 18:16:41,442][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 18:16:43,340][__main__][INFO] - Saved new W&B run ID to file: jbvil1e8
[2025-08-14 18:16:43,410][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 18:16:43,410][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 18:16:43,500][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 18:16:43,521][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 18:16:45,014][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=2
[2025-08-14 18:17:00,506][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=4
[2025-08-14 18:17:03,469][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=8
[2025-08-14 18:17:06,492][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=16
[2025-08-14 18:17:09,705][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=32
[2025-08-14 18:17:13,178][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=64
[2025-08-14 18:17:17,118][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=128
[2025-08-14 18:17:22,009][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=256
[2025-08-14 18:17:28,816][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=512
[2025-08-14 18:17:36,890][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=384
[2025-08-14 18:17:45,797][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=448
[2025-08-14 18:17:49,533][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=416
[2025-08-14 18:17:53,869][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=400
[2025-08-14 18:17:58,846][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=392
[2025-08-14 18:18:02,678][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:18:11,772][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=390
[2025-08-14 18:18:15,776][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=389
[2025-08-14 18:18:19,711][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:18:20,626][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:18:21,759][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 18:18:21,877][__main__][INFO] - Found optimal batch size 388
[2025-08-14 18:18:21,889][__main__][INFO] - Saved batch size 358 to file
[2025-08-14 18:18:21,889][__main__][INFO] - Optimal per-GPU batch size found: 358
[2025-08-14 18:18:21,889][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 358
[2025-08-14 18:18:21,894][__main__][INFO] - Saved metadata: {'timestamp': 1755209901.8897915, 'slurm_job_id': '30182809', 'batch_size': 358, 'num_devices': 1, 'effective_batch_size': 358}
[2025-08-14 18:18:21,897][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 18:18:22,334][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 18:18:22,358][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=358
[2025-08-14 18:50:27,650][__main__][INFO] - === STARTING EXPERIMENT: d9-by-check-type ===
[2025-08-14 18:50:27,650][__main__][INFO] - PID: 1103567
[2025-08-14 18:50:27,650][__main__][INFO] - SLURM_JOB_ID: 30182809
[2025-08-14 18:50:27,650][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 18:50:27,650][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 18:50:27,650][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 18:50:27,651][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 18:50:27,651][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 18:50:27,651][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 18:50:27,651][__main__][INFO] - SLURM_NODELIST: holygpu7c26201
[2025-08-14 18:50:27,651][__main__][INFO] - Architecture: resnet50
[2025-08-14 18:50:27,651][__main__][INFO] - Embedding Dim: 64
[2025-08-14 18:50:27,651][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 18:50:27,651][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 18:50:27,651][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 18:50:27,651][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 18:50:27,651][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 18:50:27,651][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 18:50:27,651][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 18:50:27,652][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 18:50:27,652][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 18:50:27,652][__main__][INFO] - Use LSTM: False
[2025-08-14 18:50:27,652][__main__][INFO] - Num Embeddings: 5
[2025-08-14 18:50:27,652][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=1.0
[2025-08-14 18:50:27,652][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 18:50:27,652][__main__][INFO] - Accelerator: auto
[2025-08-14 18:50:27,652][__main__][INFO] - Devices per node: auto
[2025-08-14 18:50:27,652][__main__][INFO] - Num Nodes: 1
[2025-08-14 18:50:27,652][__main__][INFO] - Total Devices: 1
[2025-08-14 18:50:27,652][__main__][INFO] - Strategy: auto
[2025-08-14 18:50:27,652][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 18:50:27,652][__main__][INFO] - MWPM filtering: False
[2025-08-14 18:50:27,653][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 18:50:27,653][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 18:50:27,653][__main__][INFO] - Max Steps: 50000
[2025-08-14 18:50:27,653][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 18:50:27,653][__main__][INFO] - Log every 100 steps
[2025-08-14 18:50:27,653][__main__][INFO] - Num Workers: 8
[2025-08-14 18:50:27,653][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 18:50:27,653][__main__][INFO] - Persistent Workers: True
[2025-08-14 18:50:27,653][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-by-check-type
[2025-08-14 18:50:27,671][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 18:50:27,671][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 18:50:29,594][__main__][INFO] - Saved new W&B run ID to file: 8msgl1l3
[2025-08-14 18:50:29,665][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 18:50:29,666][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 18:50:29,758][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 18:50:29,778][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 18:50:30,615][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=2
[2025-08-14 18:51:05,967][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=4
[2025-08-14 18:51:27,403][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=8
[2025-08-14 18:51:51,316][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=16
[2025-08-14 18:52:13,502][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=32
[2025-08-14 18:52:37,473][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=64
[2025-08-14 18:53:03,111][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=128
[2025-08-14 18:53:30,685][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=256
[2025-08-14 18:53:58,087][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=512
[2025-08-14 18:54:17,074][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=384
[2025-08-14 18:54:48,019][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=448
[2025-08-14 18:55:17,392][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=416
[2025-08-14 18:55:46,435][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=400
[2025-08-14 18:56:16,530][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=392
[2025-08-14 18:56:46,024][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:57:17,664][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=390
[2025-08-14 18:57:49,368][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=389
[2025-08-14 18:58:22,691][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:58:28,308][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 18:58:29,737][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 18:58:29,918][__main__][INFO] - Found optimal batch size 388
[2025-08-14 18:58:29,931][__main__][INFO] - Saved batch size 358 to file
[2025-08-14 18:58:29,932][__main__][INFO] - Optimal per-GPU batch size found: 358
[2025-08-14 18:58:29,932][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 358
[2025-08-14 18:58:29,937][__main__][INFO] - Saved metadata: {'timestamp': 1755212309.9325268, 'slurm_job_id': '30182809', 'batch_size': 358, 'num_devices': 1, 'effective_batch_size': 358}
[2025-08-14 18:58:29,940][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 18:58:30,378][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 18:58:30,406][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=358
[2025-08-14 20:13:49,045][__main__][INFO] - === STARTING EXPERIMENT: d9-all-same ===
[2025-08-14 20:13:49,045][__main__][INFO] - PID: 3298350
[2025-08-14 20:13:49,045][__main__][INFO] - SLURM_JOB_ID: 30232335
[2025-08-14 20:13:49,045][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 20:13:49,045][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 20:13:49,045][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 20:13:49,046][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 20:13:49,046][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 20:13:49,046][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 20:13:49,046][__main__][INFO] - SLURM_NODELIST: holygpu7c26105
[2025-08-14 20:13:49,046][__main__][INFO] - Architecture: resnet50
[2025-08-14 20:13:49,046][__main__][INFO] - Embedding Dim: 64
[2025-08-14 20:13:49,046][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 20:13:49,046][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 20:13:49,046][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 20:13:49,046][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 20:13:49,046][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 20:13:49,046][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 20:13:49,046][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 20:13:49,046][__main__][INFO] - Stage3 Stride: [1, 1, 1]
[2025-08-14 20:13:49,047][__main__][INFO] - Stage4 Stride: [1, 1, 1]
[2025-08-14 20:13:49,047][__main__][INFO] - Use LSTM: False
[2025-08-14 20:13:49,047][__main__][INFO] - Num Embeddings: 3
[2025-08-14 20:13:49,047][__main__][INFO] - Dataset: code_type=surface_code, d=9, rounds=9, p=1.0
[2025-08-14 20:13:49,047][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 20:13:49,047][__main__][INFO] - Accelerator: auto
[2025-08-14 20:13:49,047][__main__][INFO] - Devices per node: auto
[2025-08-14 20:13:49,047][__main__][INFO] - Num Nodes: 1
[2025-08-14 20:13:49,047][__main__][INFO] - Total Devices: 1
[2025-08-14 20:13:49,047][__main__][INFO] - Strategy: auto
[2025-08-14 20:13:49,047][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 20:13:49,047][__main__][INFO] - MWPM filtering: False
[2025-08-14 20:13:49,047][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 20:13:49,048][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 20:13:49,048][__main__][INFO] - Max Steps: 50000
[2025-08-14 20:13:49,048][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 20:13:49,048][__main__][INFO] - Log every 100 steps
[2025-08-14 20:13:49,048][__main__][INFO] - Num Workers: 8
[2025-08-14 20:13:49,048][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 20:13:49,048][__main__][INFO] - Persistent Workers: True
[2025-08-14 20:13:49,048][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/d9-all-same
[2025-08-14 20:13:49,066][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 20:13:49,066][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 20:13:51,056][__main__][INFO] - Saved new W&B run ID to file: o1s3e4n4
[2025-08-14 20:13:51,126][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 20:13:51,126][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 20:13:51,224][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 20:13:51,244][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 20:13:52,188][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=2
[2025-08-14 20:14:29,398][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=4
[2025-08-14 20:14:52,381][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=8
[2025-08-14 20:15:17,917][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=16
[2025-08-14 20:15:41,910][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=32
[2025-08-14 20:16:08,415][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=64
[2025-08-14 20:16:36,620][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=128
[2025-08-14 20:17:07,258][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=256
[2025-08-14 20:17:39,092][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=512
[2025-08-14 20:18:00,017][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=384
[2025-08-14 20:18:34,826][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=448
[2025-08-14 20:19:06,560][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=416
[2025-08-14 20:19:41,502][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=400
[2025-08-14 20:20:16,643][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=392
[2025-08-14 20:20:48,449][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 20:21:24,221][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=390
[2025-08-14 20:21:58,815][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=389
[2025-08-14 20:22:34,633][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 20:22:40,417][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=388
[2025-08-14 20:22:41,816][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 20:22:41,981][__main__][INFO] - Found optimal batch size 388
[2025-08-14 20:22:41,989][__main__][INFO] - Saved batch size 358 to file
[2025-08-14 20:22:41,989][__main__][INFO] - Optimal per-GPU batch size found: 358
[2025-08-14 20:22:41,989][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 358
[2025-08-14 20:22:41,995][__main__][INFO] - Saved metadata: {'timestamp': 1755217361.9898193, 'slurm_job_id': '30232335', 'batch_size': 358, 'num_devices': 1, 'effective_batch_size': 358}
[2025-08-14 20:22:41,998][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 20:22:42,409][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 20:22:42,432][data_module][INFO] - Created dataset (TemporalSurfaceCodeDataset): l=6, m=6, d=9, rounds=9, p=1.0, batch_size=358
[2025-08-14 21:32:31,297][__main__][INFO] - === STARTING EXPERIMENT: bb6-05-all-same ===
[2025-08-14 21:32:31,297][__main__][INFO] - PID: 3873243
[2025-08-14 21:32:31,297][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 21:32:31,297][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 21:32:31,297][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 21:32:31,297][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 21:32:31,297][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 21:32:31,297][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 21:32:31,297][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 21:32:31,297][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 21:32:31,297][__main__][INFO] - Architecture: rgcn50
[2025-08-14 21:32:31,297][__main__][INFO] - Embedding Dim: 64
[2025-08-14 21:32:31,297][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 21:32:31,298][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 21:32:31,298][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 21:32:31,298][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 21:32:31,298][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 21:32:31,298][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 21:32:31,298][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 21:32:31,930][__main__][INFO] - Num Relations: 66
[2025-08-14 21:32:31,930][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 21:32:31,930][__main__][INFO] - Num Embeddings: 4
[2025-08-14 21:32:31,930][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 21:32:31,930][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 21:32:31,956][__main__][INFO] - Accelerator: auto
[2025-08-14 21:32:31,956][__main__][INFO] - Devices per node: auto
[2025-08-14 21:32:31,956][__main__][INFO] - Num Nodes: 1
[2025-08-14 21:32:31,956][__main__][INFO] - Total Devices: 1
[2025-08-14 21:32:31,956][__main__][INFO] - Strategy: auto
[2025-08-14 21:32:31,956][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 21:32:31,956][__main__][INFO] - MWPM filtering: False
[2025-08-14 21:32:31,956][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 21:32:31,957][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 21:32:31,957][__main__][INFO] - Max Steps: 50000
[2025-08-14 21:32:31,957][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 21:32:31,957][__main__][INFO] - Log every 100 steps
[2025-08-14 21:32:31,957][__main__][INFO] - Num Workers: 6
[2025-08-14 21:32:31,957][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 21:32:31,957][__main__][INFO] - Persistent Workers: True
[2025-08-14 21:32:31,957][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05-all-same
[2025-08-14 21:32:31,977][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 21:32:31,977][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 21:32:33,986][__main__][INFO] - Saved new W&B run ID to file: pkaemtm1
[2025-08-14 21:32:34,575][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 21:32:34,576][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 21:32:34,665][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 21:32:34,684][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 21:32:36,398][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 21:36:44,860][__main__][INFO] - === STARTING EXPERIMENT: bb6-05-all-same ===
[2025-08-14 21:36:44,860][__main__][INFO] - PID: 3874318
[2025-08-14 21:36:44,860][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 21:36:44,860][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 21:36:44,860][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 21:36:44,860][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 21:36:44,860][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 21:36:44,860][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 21:36:44,860][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 21:36:44,860][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 21:36:44,860][__main__][INFO] - Architecture: rgcn50
[2025-08-14 21:36:44,860][__main__][INFO] - Embedding Dim: 64
[2025-08-14 21:36:44,860][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 21:36:44,860][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 21:36:44,861][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 21:36:44,861][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 21:36:44,861][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 21:36:44,861][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 21:36:44,861][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 21:36:45,484][__main__][INFO] - Num Relations: 66
[2025-08-14 21:36:45,485][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 21:36:45,485][__main__][INFO] - Num Embeddings: 4
[2025-08-14 21:36:45,485][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 21:36:45,485][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 21:36:45,508][__main__][INFO] - Accelerator: auto
[2025-08-14 21:36:45,508][__main__][INFO] - Devices per node: auto
[2025-08-14 21:36:45,508][__main__][INFO] - Num Nodes: 1
[2025-08-14 21:36:45,508][__main__][INFO] - Total Devices: 1
[2025-08-14 21:36:45,508][__main__][INFO] - Strategy: auto
[2025-08-14 21:36:45,508][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 21:36:45,508][__main__][INFO] - MWPM filtering: False
[2025-08-14 21:36:45,508][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 21:36:45,509][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 21:36:45,509][__main__][INFO] - Max Steps: 50000
[2025-08-14 21:36:45,509][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 21:36:45,509][__main__][INFO] - Log every 100 steps
[2025-08-14 21:36:45,509][__main__][INFO] - Num Workers: 6
[2025-08-14 21:36:45,509][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 21:36:45,509][__main__][INFO] - Persistent Workers: True
[2025-08-14 21:36:45,509][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05-all-same
[2025-08-14 21:36:45,518][__main__][INFO] - Loaded W&B run ID from file: pkaemtm1
[2025-08-14 21:36:45,519][__main__][INFO] - Setting up W&B logger with existing run ID: pkaemtm1
[2025-08-14 21:36:45,519][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 21:36:46,093][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 21:36:46,093][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 21:36:46,183][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 21:36:46,204][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 21:36:47,913][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 21:37:26,897][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
[2025-08-14 21:37:54,402][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 21:38:22,043][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 21:38:49,309][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
[2025-08-14 21:39:17,658][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=64
[2025-08-14 21:39:46,260][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=128
[2025-08-14 21:40:16,340][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=256
[2025-08-14 21:40:46,570][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=512
[2025-08-14 21:41:17,199][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=384
[2025-08-14 21:41:49,727][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=448
[2025-08-14 21:42:23,239][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=480
[2025-08-14 21:42:55,637][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=464
[2025-08-14 21:43:28,828][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=456
[2025-08-14 21:44:03,567][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=452
[2025-08-14 21:44:44,721][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=454
[2025-08-14 21:45:26,584][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=455
[2025-08-14 21:46:19,394][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=455
[2025-08-14 21:46:21,898][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 21:46:22,124][__main__][INFO] - Found optimal batch size 455
[2025-08-14 21:46:22,137][__main__][INFO] - Saved batch size 425 to file
[2025-08-14 21:46:22,138][__main__][INFO] - Optimal per-GPU batch size found: 425
[2025-08-14 21:46:22,138][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 425
[2025-08-14 21:46:22,142][__main__][INFO] - Saved metadata: {'timestamp': 1755222382.1382387, 'slurm_job_id': '30199015', 'batch_size': 425, 'num_devices': 1, 'effective_batch_size': 425}
[2025-08-14 21:48:31,665][__main__][INFO] - === STARTING EXPERIMENT: bb6-05-all-same ===
[2025-08-14 21:48:31,665][__main__][INFO] - PID: 3883711
[2025-08-14 21:48:31,665][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 21:48:31,665][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 21:48:31,665][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 21:48:31,666][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 21:48:31,666][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 21:48:31,666][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 21:48:31,666][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 21:48:31,666][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 21:48:31,666][__main__][INFO] - Architecture: rgcn50
[2025-08-14 21:48:31,666][__main__][INFO] - Embedding Dim: 64
[2025-08-14 21:48:31,666][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 21:48:31,666][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 21:48:31,666][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 21:48:31,666][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 21:48:31,666][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 21:48:31,666][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 21:48:31,666][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 21:48:32,292][__main__][INFO] - Num Relations: 66
[2025-08-14 21:48:32,292][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 21:48:32,292][__main__][INFO] - Num Embeddings: 4
[2025-08-14 21:48:32,293][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 21:48:32,293][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 21:48:32,316][__main__][INFO] - Accelerator: auto
[2025-08-14 21:48:32,316][__main__][INFO] - Devices per node: auto
[2025-08-14 21:48:32,316][__main__][INFO] - Num Nodes: 1
[2025-08-14 21:48:32,316][__main__][INFO] - Total Devices: 1
[2025-08-14 21:48:32,316][__main__][INFO] - Strategy: auto
[2025-08-14 21:48:32,316][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 21:48:32,316][__main__][INFO] - MWPM filtering: False
[2025-08-14 21:48:32,316][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 21:48:32,317][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 21:48:32,317][__main__][INFO] - Max Steps: 50000
[2025-08-14 21:48:32,317][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 21:48:32,317][__main__][INFO] - Log every 100 steps
[2025-08-14 21:48:32,317][__main__][INFO] - Num Workers: 6
[2025-08-14 21:48:32,317][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 21:48:32,317][__main__][INFO] - Persistent Workers: True
[2025-08-14 21:48:32,317][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05-all-same
[2025-08-14 21:48:32,339][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 21:48:32,339][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 21:48:34,300][__main__][INFO] - Saved new W&B run ID to file: y7ardk52
[2025-08-14 21:48:34,883][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 21:48:34,884][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 21:48:34,973][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 21:48:34,994][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 21:48:36,745][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 21:48:53,716][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
[2025-08-14 21:48:57,641][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 21:49:01,618][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 21:49:05,720][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
[2025-08-14 21:49:10,082][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=64
[2025-08-14 21:49:14,832][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=128
[2025-08-14 21:49:20,339][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=256
[2025-08-14 21:49:27,307][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=512
[2025-08-14 21:49:31,379][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=384
[2025-08-14 21:49:39,736][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=448
[2025-08-14 21:49:44,414][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=416
[2025-08-14 21:50:16,427][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=432
[2025-08-14 21:50:48,288][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=440
[2025-08-14 21:51:16,854][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=436
[2025-08-14 21:51:54,755][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=438
[2025-08-14 21:52:34,194][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=439
[2025-08-14 21:53:21,568][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=439
[2025-08-14 21:53:23,878][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 21:53:24,098][__main__][INFO] - Found optimal batch size 439
[2025-08-14 21:53:24,111][__main__][INFO] - Saved batch size 409 to file
[2025-08-14 21:53:24,111][__main__][INFO] - Optimal per-GPU batch size found: 409
[2025-08-14 21:53:24,112][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 409
[2025-08-14 21:53:24,115][__main__][INFO] - Saved metadata: {'timestamp': 1755222804.1122553, 'slurm_job_id': '30199015', 'batch_size': 409, 'num_devices': 1, 'effective_batch_size': 409}
[2025-08-14 21:53:24,118][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 21:53:24,561][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 21:53:24,974][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=409
[2025-08-14 22:04:18,209][__main__][INFO] - === STARTING EXPERIMENT: bb6-05-all-diff ===
[2025-08-14 22:04:18,209][__main__][INFO] - PID: 3893634
[2025-08-14 22:04:18,209][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 22:04:18,209][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 22:04:18,209][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 22:04:18,209][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 22:04:18,209][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 22:04:18,209][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 22:04:18,209][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 22:04:18,209][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 22:04:18,209][__main__][INFO] - Architecture: rgcn50
[2025-08-14 22:04:18,210][__main__][INFO] - Embedding Dim: 64
[2025-08-14 22:04:18,210][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 22:04:18,210][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 22:04:18,210][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 22:04:18,210][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 22:04:18,210][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 22:04:18,210][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 22:04:18,210][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 22:04:18,834][__main__][INFO] - Num Relations: 66
[2025-08-14 22:04:18,835][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 22:04:18,910][__main__][INFO] - Num Embeddings: 1080
[2025-08-14 22:04:18,911][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 22:04:18,911][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 22:04:18,934][__main__][INFO] - Accelerator: auto
[2025-08-14 22:04:18,934][__main__][INFO] - Devices per node: auto
[2025-08-14 22:04:18,934][__main__][INFO] - Num Nodes: 1
[2025-08-14 22:04:18,934][__main__][INFO] - Total Devices: 1
[2025-08-14 22:04:18,934][__main__][INFO] - Strategy: auto
[2025-08-14 22:04:18,934][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 22:04:18,934][__main__][INFO] - MWPM filtering: False
[2025-08-14 22:04:18,934][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 22:04:18,935][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 22:04:18,935][__main__][INFO] - Max Steps: 50000
[2025-08-14 22:04:18,935][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 22:04:18,935][__main__][INFO] - Log every 100 steps
[2025-08-14 22:04:18,935][__main__][INFO] - Num Workers: 6
[2025-08-14 22:04:18,935][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 22:04:18,935][__main__][INFO] - Persistent Workers: True
[2025-08-14 22:04:18,935][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05-all-diff
[2025-08-14 22:04:18,966][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 22:04:18,966][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 22:04:20,957][__main__][INFO] - Saved new W&B run ID to file: 7gegzltm
[2025-08-14 22:04:21,608][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 22:04:21,608][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 22:04:21,698][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 22:04:21,720][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 22:04:23,430][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 22:04:40,688][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
[2025-08-14 22:04:44,515][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 22:04:48,423][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 22:04:52,445][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
[2025-08-14 22:04:56,926][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=64
[2025-08-14 22:05:01,545][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=128
[2025-08-14 22:05:06,891][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=256
[2025-08-14 22:05:13,803][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=512
[2025-08-14 22:05:17,883][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=384
[2025-08-14 22:05:26,148][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=448
[2025-08-14 22:05:30,723][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=416
[2025-08-14 22:05:39,370][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=432
[2025-08-14 22:05:48,322][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=440
[2025-08-14 22:05:52,804][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=436
[2025-08-14 22:06:25,933][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=438
[2025-08-14 22:06:59,173][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=439
[2025-08-14 22:07:33,727][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=439
[2025-08-14 22:07:35,918][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 22:07:36,098][__main__][INFO] - Found optimal batch size 439
[2025-08-14 22:07:36,118][__main__][INFO] - Saved batch size 409 to file
[2025-08-14 22:07:36,119][__main__][INFO] - Optimal per-GPU batch size found: 409
[2025-08-14 22:07:36,119][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 409
[2025-08-14 22:07:36,126][__main__][INFO] - Saved metadata: {'timestamp': 1755223656.1194742, 'slurm_job_id': '30199015', 'batch_size': 409, 'num_devices': 1, 'effective_batch_size': 409}
[2025-08-14 22:07:36,129][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 22:07:36,566][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 22:07:36,982][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=409
[2025-08-14 22:16:31,233][__main__][INFO] - === STARTING EXPERIMENT: bb6-05-space-diff ===
[2025-08-14 22:16:31,233][__main__][INFO] - PID: 3897309
[2025-08-14 22:16:31,233][__main__][INFO] - SLURM_JOB_ID: 30199015
[2025-08-14 22:16:31,233][__main__][INFO] - NODE_RANK: unknown
[2025-08-14 22:16:31,233][__main__][INFO] - WORLD_SIZE: unknown
[2025-08-14 22:16:31,233][__main__][INFO] - MASTER_ADDR: unknown
[2025-08-14 22:16:31,233][__main__][INFO] - MASTER_PORT: unknown
[2025-08-14 22:16:31,233][__main__][INFO] - SLURM_NODEID: 0
[2025-08-14 22:16:31,233][__main__][INFO] - SLURM_NNODES: 1
[2025-08-14 22:16:31,233][__main__][INFO] - SLURM_NODELIST: holygpu8a22601
[2025-08-14 22:16:31,234][__main__][INFO] - Architecture: rgcn50
[2025-08-14 22:16:31,234][__main__][INFO] - Embedding Dim: 64
[2025-08-14 22:16:31,234][__main__][INFO] - Learning Rate: 0.001
[2025-08-14 22:16:31,234][__main__][INFO] - Weight Decay: 0.0
[2025-08-14 22:16:31,234][__main__][INFO] - Optimizer: schedulefree
[2025-08-14 22:16:31,234][__main__][INFO] - Gradient Clip Val: 1.0
[2025-08-14 22:16:31,234][__main__][INFO] - Gradient Clip Algorithm: norm
[2025-08-14 22:16:31,234][__main__][INFO] - Accumulate Grad Batches: 1
[2025-08-14 22:16:31,234][__main__][INFO] - Channel Multipliers: [2, 4, 8, 16]
[2025-08-14 22:16:31,860][__main__][INFO] - Num Relations: 66
[2025-08-14 22:16:31,861][__main__][INFO] - Num Logical Qubits: 12
[2025-08-14 22:16:31,936][__main__][INFO] - Num Embeddings: 144
[2025-08-14 22:16:31,936][__main__][INFO] - Dataset: code_type=bivariate_bicycle, l=6, m=6, rounds=7, p=0.5
[2025-08-14 22:16:31,936][__main__][INFO] - Standard training (no curriculum)
[2025-08-14 22:16:31,950][__main__][INFO] - Accelerator: auto
[2025-08-14 22:16:31,950][__main__][INFO] - Devices per node: auto
[2025-08-14 22:16:31,950][__main__][INFO] - Num Nodes: 1
[2025-08-14 22:16:31,950][__main__][INFO] - Total Devices: 1
[2025-08-14 22:16:31,950][__main__][INFO] - Strategy: auto
[2025-08-14 22:16:31,950][__main__][INFO] - Sync BatchNorm: True
[2025-08-14 22:16:31,950][__main__][INFO] - MWPM filtering: False
[2025-08-14 22:16:31,950][__main__][INFO] - Batch Size: auto-tuned
[2025-08-14 22:16:31,951][__main__][INFO] - Precision: bf16-mixed
[2025-08-14 22:16:31,951][__main__][INFO] - Max Steps: 50000
[2025-08-14 22:16:31,951][__main__][INFO] - Checkpoint every 15 minutes
[2025-08-14 22:16:31,951][__main__][INFO] - Log every 100 steps
[2025-08-14 22:16:31,951][__main__][INFO] - Num Workers: 6
[2025-08-14 22:16:31,951][__main__][INFO] - Prefetch Factor: 4
[2025-08-14 22:16:31,951][__main__][INFO] - Persistent Workers: True
[2025-08-14 22:16:31,951][__main__][INFO] - Experiment directory: /n/netscratch/yelin_lab/Everyone/andigu/scaling/bb6-05-space-diff
[2025-08-14 22:16:31,970][__main__][INFO] - Setting up new W&B logger (W&B will assign run ID)
[2025-08-14 22:16:31,970][__main__][INFO] - Initializing wandb logger with params
[2025-08-14 22:16:33,910][__main__][INFO] - Saved new W&B run ID to file: a4notjzj
[2025-08-14 22:16:34,559][__main__][INFO] - Compiling model with mode='default', fullgraph=True, dynamic=False
[2025-08-14 22:16:34,560][__main__][INFO] - Set torch._dynamo.config.cache_size_limit=64 to handle batch size tuning recompilations
[2025-08-14 22:16:34,651][__main__][INFO] - Model compilation enabled - first batch will be slower due to compilation overhead
[2025-08-14 22:16:34,671][__main__][INFO] - === AUTO-TUNING BATCH SIZE (RANK 0) ===
[2025-08-14 22:16:36,377][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=2
[2025-08-14 22:16:53,625][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=4
[2025-08-14 22:16:57,449][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=8
[2025-08-14 22:17:01,380][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=16
[2025-08-14 22:17:05,402][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=32
[2025-08-14 22:17:09,647][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=64
[2025-08-14 22:17:14,259][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=128
[2025-08-14 22:17:19,556][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=256
[2025-08-14 22:17:26,502][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=512
[2025-08-14 22:17:30,460][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=384
[2025-08-14 22:17:38,679][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=448
[2025-08-14 22:17:43,284][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=416
[2025-08-14 22:18:15,430][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=432
[2025-08-14 22:18:47,427][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=440
[2025-08-14 22:19:19,274][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=444
[2025-08-14 22:19:52,412][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=446
[2025-08-14 22:20:27,476][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=447
[2025-08-14 22:21:05,572][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=447
[2025-08-14 22:21:07,777][__main__][INFO] - Model loaded from checkpoint at global step 0
[2025-08-14 22:21:07,965][__main__][INFO] - Found optimal batch size 447
[2025-08-14 22:21:07,979][__main__][INFO] - Saved batch size 417 to file
[2025-08-14 22:21:07,979][__main__][INFO] - Optimal per-GPU batch size found: 417
[2025-08-14 22:21:07,979][__main__][INFO] - Effective total batch size across 1 device(s) on 1 node(s) with 1 accumulation steps: 417
[2025-08-14 22:21:07,985][__main__][INFO] - Saved metadata: {'timestamp': 1755224467.979718, 'slurm_job_id': '30199015', 'batch_size': 417, 'num_devices': 1, 'effective_batch_size': 417}
[2025-08-14 22:21:07,988][__main__][INFO] - Skipping wandb.watch() due to torch.compile compatibility
[2025-08-14 22:21:08,427][__main__][INFO] - === STARTING TRAINING ===
[2025-08-14 22:21:08,847][data_module][INFO] - Created dataset (BivariateBicycleDataset): l=6, m=6, d=9, rounds=7, p=0.5, batch_size=417
